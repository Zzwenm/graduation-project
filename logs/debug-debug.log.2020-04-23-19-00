2020-04-23 18:59:15 [DEBUG](StandardServletEnvironment    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activating profiles []
2020-04-23 18:59:16 [DEBUG](logging                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Logging Provider: org.jboss.logging.Log4j2LoggerProvider
2020-04-23 18:59:16 [INFO ](Version                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000001: Hibernate Validator 6.0.18.Final
2020-04-23 18:59:16 [DEBUG](TraversableResolvers          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot find javax.persistence.Persistence on classpath. Assuming non JPA 2 environment. All properties will per default be traversable.
2020-04-23 18:59:16 [DEBUG](ValidationXmlParser           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml for XML based Validator configuration.
2020-04-23 18:59:16 [DEBUG](ResourceLoaderHelper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml via TCCL
2020-04-23 18:59:16 [DEBUG](ResourceLoaderHelper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml via Hibernate Validator's class loader
2020-04-23 18:59:16 [DEBUG](ValidationXmlParser           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No META-INF/validation.xml found. Using annotation based configuration only.
2020-04-23 18:59:16 [DEBUG](OriginTrackedYamlLoader       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading from YAML: class path resource [application.yml]
2020-04-23 18:59:16 [DEBUG](OriginTrackedYamlLoader       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Merging document (no matchers set): {spring={datasource={druid={username=root, password=123456, initial-size=1, min-idle=1, max-active=20, test-on-borrow=true, driver-class-name=com.mysql.cj.jdbc.Driver, url=jdbc:mysql://localhost:3306/graduation-project?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=false}}, redis={database=0, host=aliyun, port=6379, password=aliyun123, timeout=500}, kafka={bootstrap-servers=aliyun:9092, producer={key-serializer=org.apache.kafka.common.serialization.StringSerializer, value-serializer=org.apache.kafka.common.serialization.StringSerializer, batch-size=65536, buffer-memory=524288}, consumer={group-id=0, key-deserializer=org.apache.kafka.common.serialization.StringDeserializer, value-deserializer=org.apache.kafka.common.serialization.StringDeserializer}}}, mybatis={mapper-locations=classpath:mapper/*.xml, type-aliases-package=com.example.graduationproject.web.entity, configuration={map-underscore-to-camel-case=true}}, server={port=8082}}
2020-04-23 18:59:16 [DEBUG](OriginTrackedYamlLoader       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loaded 1 document from YAML resource: class path resource [application.yml]
2020-04-23 18:59:16 [DEBUG](StandardServletEnvironment    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activating profiles []
2020-04-23 18:59:16 [DEBUG](ClasspathLoggingApplicationListener) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Application started with classpath: [file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/charsets.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/deploy.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/access-bridge-64.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/cldrdata.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/dnsns.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/jaccess.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/jfxrt.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/localedata.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/nashorn.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/sunec.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/sunjce_provider.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/sunmscapi.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/sunpkcs11.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/ext/zipfs.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/javaws.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/jce.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/jfr.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/jfxswt.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/jsse.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/management-agent.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/plugin.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/resources.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/jre/lib/rt.jar, file:/F:/%e6%af%95%e4%b8%9a%e8%ae%be%e8%ae%a1/graduation-project/graduation-project-web/target/classes/, file:/F:/%e6%af%95%e4%b8%9a%e8%ae%be%e8%ae%a1/graduation-project/graduation-project-flink-task/target/classes/, file:/F:/Maven/maven-jar/org/apache/flink/flink-streaming-java_2.12/1.10.0/flink-streaming-java_2.12-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-core/1.10.0/flink-core-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-annotations/1.10.0/flink-annotations-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-metrics-core/1.10.0/flink-metrics-core-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-shaded-asm-7/7.1-9.0/flink-shaded-asm-7-7.1-9.0.jar, file:/F:/Maven/maven-jar/com/esotericsoftware/kryo/kryo/2.24.0/kryo-2.24.0.jar, file:/F:/Maven/maven-jar/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar, file:/F:/Maven/maven-jar/org/apache/commons/commons-compress/1.18/commons-compress-1.18.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-runtime_2.12/1.10.0/flink-runtime_2.12-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-java/1.10.0/flink-java-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-queryable-state-client-java/1.10.0/flink-queryable-state-client-java-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-hadoop-fs/1.10.0/flink-hadoop-fs-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-shaded-netty/4.1.39.Final-9.0/flink-shaded-netty-4.1.39.Final-9.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-shaded-jackson/2.10.1-9.0/flink-shaded-jackson-2.10.1-9.0.jar, file:/F:/Maven/maven-jar/org/javassist/javassist/3.24.0-GA/javassist-3.24.0-GA.jar, file:/F:/Maven/maven-jar/org/scala-lang/scala-library/2.12.7/scala-library-2.12.7.jar, file:/F:/Maven/maven-jar/com/typesafe/akka/akka-actor_2.12/2.5.21/akka-actor_2.12-2.5.21.jar, file:/F:/Maven/maven-jar/com/typesafe/config/1.3.3/config-1.3.3.jar, file:/F:/Maven/maven-jar/org/scala-lang/modules/scala-java8-compat_2.12/0.8.0/scala-java8-compat_2.12-0.8.0.jar, file:/F:/Maven/maven-jar/com/typesafe/akka/akka-stream_2.12/2.5.21/akka-stream_2.12-2.5.21.jar, file:/F:/Maven/maven-jar/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar, file:/F:/Maven/maven-jar/com/typesafe/ssl-config-core_2.12/0.3.7/ssl-config-core_2.12-0.3.7.jar, file:/F:/Maven/maven-jar/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.1/scala-parser-combinators_2.12-1.1.1.jar, file:/F:/Maven/maven-jar/com/typesafe/akka/akka-protobuf_2.12/2.5.21/akka-protobuf_2.12-2.5.21.jar, file:/F:/Maven/maven-jar/com/typesafe/akka/akka-slf4j_2.12/2.5.21/akka-slf4j_2.12-2.5.21.jar, file:/F:/Maven/maven-jar/org/clapper/grizzled-slf4j_2.12/1.3.2/grizzled-slf4j_2.12-1.3.2.jar, file:/F:/Maven/maven-jar/com/github/scopt/scopt_2.12/3.5.0/scopt_2.12-3.5.0.jar, file:/F:/Maven/maven-jar/com/twitter/chill_2.12/0.7.6/chill_2.12-0.7.6.jar, file:/F:/Maven/maven-jar/com/twitter/chill-java/0.7.6/chill-java-0.7.6.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-clients_2.12/1.10.0/flink-clients_2.12-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-optimizer_2.12/1.10.0/flink-optimizer_2.12-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-shaded-guava/18.0-9.0/flink-shaded-guava-18.0-9.0.jar, file:/F:/Maven/maven-jar/org/apache/commons/commons-math3/3.5/commons-math3-3.5.jar, file:/F:/Maven/maven-jar/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar, file:/F:/Maven/maven-jar/org/apache/flink/force-shading/1.10.0/force-shading-1.10.0.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-connector-kafka_2.11/1.7.1/flink-connector-kafka_2.11-1.7.1.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-connector-kafka-base_2.11/1.7.1/flink-connector-kafka-base_2.11-1.7.1.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-client/1.2.12/hbase-client-1.2.12.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-annotations/1.2.12/hbase-annotations-1.2.12.jar, file:/F:/Maven/maven-jar/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-common/1.2.12/hbase-common-1.2.12.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-protocol/1.2.12/hbase-protocol-1.2.12.jar, file:/F:/Maven/maven-jar/commons-codec/commons-codec/1.13/commons-codec-1.13.jar, file:/F:/Maven/maven-jar/commons-io/commons-io/2.4/commons-io-2.4.jar, file:/F:/Maven/maven-jar/commons-lang/commons-lang/2.6/commons-lang-2.6.jar, file:/F:/Maven/maven-jar/com/google/guava/guava/12.0.1/guava-12.0.1.jar, file:/F:/Maven/maven-jar/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar, file:/F:/Maven/maven-jar/io/netty/netty-all/4.1.48.Final/netty-all-4.1.48.Final.jar, file:/F:/Maven/maven-jar/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar, file:/F:/Maven/maven-jar/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar, file:/F:/Maven/maven-jar/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar, file:/F:/Maven/maven-jar/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar, file:/F:/Maven/maven-jar/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar, file:/F:/Maven/maven-jar/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/httpcomponents/httpclient/4.5.12/httpclient-4.5.12.jar, file:/F:/Maven/maven-jar/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar, file:/F:/Maven/maven-jar/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar, file:/F:/Maven/maven-jar/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar, file:/F:/Maven/maven-jar/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar, file:/F:/Maven/maven-jar/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar, file:/C:/Program%20Files/Java/jdk1.8.0_191/lib/tools.jar, file:/F:/Maven/maven-jar/xmlenc/xmlenc/0.52/xmlenc-0.52.jar, file:/F:/Maven/maven-jar/commons-net/commons-net/3.1/commons-net-3.1.jar, file:/F:/Maven/maven-jar/commons-el/commons-el/1.0/commons-el-1.0.jar, file:/F:/Maven/maven-jar/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar, file:/F:/Maven/maven-jar/commons-digester/commons-digester/1.8/commons-digester-1.8.jar, file:/F:/Maven/maven-jar/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar, file:/F:/Maven/maven-jar/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar, file:/F:/Maven/maven-jar/org/apache/avro/avro/1.7.4/avro-1.7.4.jar, file:/F:/Maven/maven-jar/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar, file:/F:/Maven/maven-jar/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar, file:/F:/Maven/maven-jar/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar, file:/F:/Maven/maven-jar/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar, file:/F:/Maven/maven-jar/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-server/1.2.12/hbase-server-1.2.12.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-procedure/1.2.12/hbase-procedure-1.2.12.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-common/1.2.12/hbase-common-1.2.12-tests.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-prefix-tree/1.2.12/hbase-prefix-tree-1.2.12.jar, file:/F:/Maven/maven-jar/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar, file:/F:/Maven/maven-jar/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-hadoop-compat/1.2.12/hbase-hadoop-compat-1.2.12.jar, file:/F:/Maven/maven-jar/org/apache/hbase/hbase-hadoop2-compat/1.2.12/hbase-hadoop2-compat-1.2.12.jar, file:/F:/Maven/maven-jar/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar, file:/F:/Maven/maven-jar/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar, file:/F:/Maven/maven-jar/asm/asm/3.1/asm-3.1.jar, file:/F:/Maven/maven-jar/commons-cli/commons-cli/1.2/commons-cli-1.2.jar, file:/F:/Maven/maven-jar/org/apache/commons/commons-math/2.2/commons-math-2.2.jar, file:/F:/Maven/maven-jar/log4j/log4j/1.2.17/log4j-1.2.17.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar, file:/F:/Maven/maven-jar/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar, file:/F:/Maven/maven-jar/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar, file:/F:/Maven/maven-jar/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar, file:/F:/Maven/maven-jar/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar, file:/F:/Maven/maven-jar/org/jamon/jamon-runtime/2.4.1/jamon-runtime-2.4.1.jar, file:/F:/Maven/maven-jar/com/lmax/disruptor/3.3.0/disruptor-3.3.0.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar, file:/F:/Maven/maven-jar/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar, file:/F:/Maven/maven-jar/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar, file:/F:/Maven/maven-jar/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar, file:/F:/Maven/maven-jar/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar, file:/F:/Maven/maven-jar/junit/junit/4.12/junit-4.12.jar, file:/F:/Maven/maven-jar/org/hamcrest/hamcrest-core/2.1/hamcrest-core-2.1.jar, file:/F:/Maven/maven-jar/org/apache/flink/flink-connector-redis_2.10/1.1.5/flink-connector-redis_2.10-1.1.5.jar, file:/F:/Maven/maven-jar/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar, file:/F:/Maven/maven-jar/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-web/2.2.6.RELEASE/spring-boot-starter-web-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter/2.2.6.RELEASE/spring-boot-starter-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot/2.2.6.RELEASE/spring-boot-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-logging/2.2.6.RELEASE/spring-boot-starter-logging-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/apache/logging/log4j/log4j-to-slf4j/2.12.1/log4j-to-slf4j-2.12.1.jar, file:/F:/Maven/maven-jar/org/apache/logging/log4j/log4j-api/2.12.1/log4j-api-2.12.1.jar, file:/F:/Maven/maven-jar/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar, file:/F:/Maven/maven-jar/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar, file:/F:/Maven/maven-jar/org/yaml/snakeyaml/1.25/snakeyaml-1.25.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-json/2.2.6.RELEASE/spring-boot-starter-json-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.10.3/jackson-datatype-jdk8-2.10.3.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.10.3/jackson-datatype-jsr310-2.10.3.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/module/jackson-module-parameter-names/2.10.3/jackson-module-parameter-names-2.10.3.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-tomcat/2.2.6.RELEASE/spring-boot-starter-tomcat-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/apache/tomcat/embed/tomcat-embed-core/9.0.33/tomcat-embed-core-9.0.33.jar, file:/F:/Maven/maven-jar/org/apache/tomcat/embed/tomcat-embed-el/9.0.33/tomcat-embed-el-9.0.33.jar, file:/F:/Maven/maven-jar/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.33/tomcat-embed-websocket-9.0.33.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-validation/2.2.6.RELEASE/spring-boot-starter-validation-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar, file:/F:/Maven/maven-jar/org/hibernate/validator/hibernate-validator/6.0.18.Final/hibernate-validator-6.0.18.Final.jar, file:/F:/Maven/maven-jar/org/jboss/logging/jboss-logging/3.4.1.Final/jboss-logging-3.4.1.Final.jar, file:/F:/Maven/maven-jar/com/fasterxml/classmate/1.5.1/classmate-1.5.1.jar, file:/F:/Maven/maven-jar/org/springframework/spring-web/5.2.5.RELEASE/spring-web-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-beans/5.2.5.RELEASE/spring-beans-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-webmvc/5.2.5.RELEASE/spring-webmvc-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-aop/5.2.5.RELEASE/spring-aop-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-expression/5.2.5.RELEASE/spring-expression-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-thymeleaf/2.2.5.RELEASE/spring-boot-starter-thymeleaf-2.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/thymeleaf/thymeleaf-spring5/3.0.11.RELEASE/thymeleaf-spring5-3.0.11.RELEASE.jar, file:/F:/Maven/maven-jar/org/thymeleaf/thymeleaf/3.0.11.RELEASE/thymeleaf-3.0.11.RELEASE.jar, file:/F:/Maven/maven-jar/org/attoparser/attoparser/2.0.5.RELEASE/attoparser-2.0.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/unbescape/unbescape/1.1.6.RELEASE/unbescape-1.1.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/thymeleaf/extras/thymeleaf-extras-java8time/3.0.4.RELEASE/thymeleaf-extras-java8time-3.0.4.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-data-redis/2.2.6.RELEASE/spring-boot-starter-data-redis-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/data/spring-data-redis/2.2.6.RELEASE/spring-data-redis-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/data/spring-data-keyvalue/2.2.6.RELEASE/spring-data-keyvalue-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/data/spring-data-commons/2.2.6.RELEASE/spring-data-commons-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-oxm/5.2.5.RELEASE/spring-oxm-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-context-support/5.2.5.RELEASE/spring-context-support-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/redis/clients/jedis/3.1.0/jedis-3.1.0.jar, file:/F:/Maven/maven-jar/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar, file:/F:/Maven/maven-jar/org/apache/commons/commons-pool2/2.7.0/commons-pool2-2.7.0.jar, file:/F:/Maven/maven-jar/org/springframework/kafka/spring-kafka/2.3.7.RELEASE/spring-kafka-2.3.7.RELEASE.jar, file:/F:/Maven/maven-jar/org/apache/kafka/kafka-clients/2.3.1/kafka-clients-2.3.1.jar, file:/F:/Maven/maven-jar/com/github/luben/zstd-jni/1.4.0-1/zstd-jni-1.4.0-1.jar, file:/F:/Maven/maven-jar/org/lz4/lz4-java/1.6.0/lz4-java-1.6.0.jar, file:/F:/Maven/maven-jar/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.jar, file:/F:/Maven/maven-jar/org/springframework/retry/spring-retry/1.2.5.RELEASE/spring-retry-1.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-context/5.2.5.RELEASE/spring-context-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-messaging/5.2.5.RELEASE/spring-messaging-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-tx/5.2.5.RELEASE/spring-tx-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/mybatis/spring/boot/mybatis-spring-boot-starter/2.1.1/mybatis-spring-boot-starter-2.1.1.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-starter-jdbc/2.2.6.RELEASE/spring-boot-starter-jdbc-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/com/zaxxer/HikariCP/3.4.2/HikariCP-3.4.2.jar, file:/F:/Maven/maven-jar/org/springframework/spring-jdbc/5.2.5.RELEASE/spring-jdbc-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/mybatis/spring/boot/mybatis-spring-boot-autoconfigure/2.1.1/mybatis-spring-boot-autoconfigure-2.1.1.jar, file:/F:/Maven/maven-jar/org/mybatis/mybatis/3.5.3/mybatis-3.5.3.jar, file:/F:/Maven/maven-jar/org/mybatis/mybatis-spring/2.0.3/mybatis-spring-2.0.3.jar, file:/F:/Maven/maven-jar/io/jsonwebtoken/jjwt/0.9.1/jjwt-0.9.1.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/core/jackson-databind/2.10.3/jackson-databind-2.10.3.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/core/jackson-annotations/2.10.3/jackson-annotations-2.10.3.jar, file:/F:/Maven/maven-jar/com/fasterxml/jackson/core/jackson-core/2.10.3/jackson-core-2.10.3.jar, file:/F:/Maven/maven-jar/com/alibaba/druid-spring-boot-starter/1.1.9/druid-spring-boot-starter-1.1.9.jar, file:/F:/Maven/maven-jar/com/alibaba/druid/1.1.9/druid-1.1.9.jar, file:/F:/Maven/maven-jar/org/springframework/boot/spring-boot-autoconfigure/2.2.6.RELEASE/spring-boot-autoconfigure-2.2.6.RELEASE.jar, file:/F:/Maven/maven-jar/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar, file:/F:/Maven/maven-jar/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar, file:/F:/Maven/maven-jar/mysql/mysql-connector-java/8.0.19/mysql-connector-java-8.0.19.jar, file:/F:/Maven/maven-jar/org/projectlombok/lombok/1.18.12/lombok-1.18.12.jar, file:/F:/Maven/maven-jar/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar, file:/F:/Maven/maven-jar/org/objenesis/objenesis/2.6/objenesis-2.6.jar, file:/F:/Maven/maven-jar/org/springframework/spring-core/5.2.5.RELEASE/spring-core-5.2.5.RELEASE.jar, file:/F:/Maven/maven-jar/org/springframework/spring-jcl/5.2.5.RELEASE/spring-jcl-5.2.5.RELEASE.jar, file:/D:/IDEA-U/IntelliJ%20IDEA%202019.1.1/lib/idea_rt.jar, file:/C:/Users/Zzwen/.IntelliJIdea2019.1/system/captureAgent/debugger-agent.jar]
2020-04-23 18:59:16 [DEBUG](ResourceBundleMessageInterpolator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loaded expression factory via original TCCL
2020-04-23 18:59:16 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.messageinterpolation.ResourceBundleMessageInterpolator as ValidatorFactory-scoped message interpolator.
2020-04-23 18:59:16 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.resolver.TraverseAllTraversableResolver as ValidatorFactory-scoped traversable resolver.
2020-04-23 18:59:16 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.util.ExecutableParameterNameProvider as ValidatorFactory-scoped parameter name provider.
2020-04-23 18:59:16 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.DefaultClockProvider as ValidatorFactory-scoped clock provider.
2020-04-23 18:59:16 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.scripting.DefaultScriptEvaluatorFactory as ValidatorFactory-scoped script evaluator factory.
2020-04-23 18:59:16 [INFO ](GraduationProjectWebApplication) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting GraduationProjectWebApplication on LAPTOP-JVSUCRQA with PID 6928 (F:\毕业设计\graduation-project\graduation-project-web\target\classes started by Zzwen in F:\毕业设计\graduation-project)
2020-04-23 18:59:16 [DEBUG](GraduationProjectWebApplication) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Running with Spring Boot v2.2.6.RELEASE, Spring v5.2.5.RELEASE
2020-04-23 18:59:16 [INFO ](GraduationProjectWebApplication) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No active profile set, falling back to default profiles: default
2020-04-23 18:59:16 [DEBUG](SpringApplication             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading source class com.example.graduationproject.web.GraduationProjectWebApplication
2020-04-23 18:59:16 [DEBUG](ConfigFileApplicationListener ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loaded config file 'file:/F:/%e6%af%95%e4%b8%9a%e8%ae%be%e8%ae%a1/graduation-project/graduation-project-web/target/classes/application.yml' (classpath:/application.yml)
2020-04-23 18:59:16 [DEBUG](AnnotationConfigServletWebServerApplicationContext) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0
2020-04-23 18:59:16 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.context.annotation.internalConfigurationAnnotationProcessor'
2020-04-23 18:59:16 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.internalCachingMetadataReaderFactory'
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\client\RedisClient.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\config\CustomCorsConfiguration.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\config\InterceptorConfig.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\config\RedisConfig.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\controller\BookController.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\controller\RecommendController.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\controller\UserController.class]
2020-04-23 18:59:16 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\controller\ViewController.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\interceptor\AuthInterceptor.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\BookServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\ItemCfCoefficientServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\ItemDetailServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\ItemServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\KafkaServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](ClassPathBeanDefinitionScanner) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\service\impl\UserServiceImpl.class]
2020-04-23 18:59:17 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.jmx.enabled' in PropertySource 'configurationProperties' with value of type String
2020-04-23 18:59:17 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.jmx.enabled' in PropertySource 'configurationProperties' with value of type String
2020-04-23 18:59:17 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.application.admin.enabled' in PropertySource 'configurationProperties' with value of type String
2020-04-23 18:59:17 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.jmx.enabled' in PropertySource 'configurationProperties' with value of type String
2020-04-23 18:59:17 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.application.admin.enabled' in PropertySource 'configurationProperties' with value of type String
2020-04-23 18:59:17 [INFO ](RepositoryConfigurationDelegate) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Multiple Spring Data modules found, entering strict repository configuration mode!
2020-04-23 18:59:17 [INFO ](RepositoryConfigurationDelegate) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-04-23 18:59:17 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.AutoConfigurationPackages'
2020-04-23 18:59:17 [DEBUG](AutoConfigurationPackages     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] @EnableAutoConfiguration was declared on a class in the package 'com.example.graduationproject.web'. Automatic @Repository and @Entity scanning is enabled.
2020-04-23 18:59:17 [DEBUG](RepositoryConfigurationDelegate) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Scanning for Redis repositories in packages com.example.graduationproject.web.
2020-04-23 18:59:17 [INFO ](RepositoryConfigurationDelegate) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Finished Spring Data repository scanning in 12ms. Found 0 Redis repository interfaces.
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'com.example.graduationproject.web.GraduationProjectWebApplication#MapperScannerRegistrar#0'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'propertySourcesPlaceholderConfigurer'
2020-04-23 18:59:18 [DEBUG](LogFactory                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Logging initialized using 'class org.apache.ibatis.logging.slf4j.Slf4jImpl' adapter.
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\mapper\BookMapper.class]
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\mapper\ItemDetailMapper.class]
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\mapper\ItemMapper.class]
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Identified candidate component class: file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\com\example\graduationproject\web\mapper\UserMapper.class]
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating MapperFactoryBean with name 'bookMapper' and 'com.example.graduationproject.web.mapper.BookMapper' mapperInterface
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Enabling autowire by type for MapperFactoryBean with name 'bookMapper'.
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating MapperFactoryBean with name 'itemDetailMapper' and 'com.example.graduationproject.web.mapper.ItemDetailMapper' mapperInterface
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Enabling autowire by type for MapperFactoryBean with name 'itemDetailMapper'.
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating MapperFactoryBean with name 'itemMapper' and 'com.example.graduationproject.web.mapper.ItemMapper' mapperInterface
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Enabling autowire by type for MapperFactoryBean with name 'itemMapper'.
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating MapperFactoryBean with name 'userMapper' and 'com.example.graduationproject.web.mapper.UserMapper' mapperInterface
2020-04-23 18:59:18 [DEBUG](ClassPathMapperScanner        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Enabling autowire by type for MapperFactoryBean with name 'userMapper'.
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBeanDefinitionValidator'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'preserveErrorControllerTargetClassPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.context.event.internalEventListenerFactory'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionalEventListenerFactory'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.context.annotation.internalAutowiredAnnotationProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.context.annotation.internalCommonAnnotationProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationPropertiesBindingPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinder'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.context.internalConfigurationPropertiesBinderFactory'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.aop.config.internalAutoProxyCreator'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'methodValidationPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'methodValidationPostProcessor' via factory method to bean named 'environment'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'dataSourceInitializerPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'persistenceExceptionTranslationPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'persistenceExceptionTranslationPostProcessor' via factory method to bean named 'environment'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'webServerFactoryCustomizerBeanPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'errorPageRegistrarBeanPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'projectingArgumentResolverBeanPostProcessor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.cache.config.internalCacheAdvisor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.cache.annotation.ProxyCachingConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisConfig'
2020-04-23 18:59:18 [INFO ](PostProcessorRegistrationDelegate$BeanPostProcessorChecker) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Bean 'redisConfig' of type [com.example.graduationproject.web.config.RedisConfig$$EnhancerBySpringCGLIB$$57b6d2b8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.transaction.config.internalTransactionAdvisor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'transactionAttributeSource'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'transactionInterceptor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'transactionInterceptor' via factory method to bean named 'transactionAttributeSource'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionAttributeSource'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.transaction.config.internalTransactionAdvisor' via factory method to bean named 'transactionInterceptor'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'cacheOperationSource'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'cacheInterceptor'
2020-04-23 18:59:18 [DEBUG](UiApplicationContextUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Unable to locate ThemeSource with name 'themeSource': using default [org.springframework.ui.context.support.ResourceBundleThemeSource@704641e3]
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'tomcatServletWebServerFactory'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'websocketServletWebServerCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration$TomcatWebSocketConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'servletWebServerFactoryCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'servletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'tomcatServletWebServerFactoryCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'tomcatServletWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'tomcatWebServerFactoryCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration$TomcatWebServerFactoryCustomizerConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'environment'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'tomcatWebServerFactoryCustomizer' via factory method to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'localeCharsetMappingsCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.http-org.springframework.boot.autoconfigure.http.HttpProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration' via constructor to bean named 'spring.http-org.springframework.boot.autoconfigure.http.HttpProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'errorPageCustomizer'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration' via constructor to bean named 'server-org.springframework.boot.autoconfigure.web.ServerProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'dispatcherServletRegistration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletRegistrationConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'dispatcherServlet'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration$DispatcherServletConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'dispatcherServlet' via factory method to bean named 'spring.http-org.springframework.boot.autoconfigure.http.HttpProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'dispatcherServlet' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'dispatcherServlet'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'dispatcherServletRegistration' via factory method to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'multipartConfigElement'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration' via constructor to bean named 'spring.servlet.multipart-org.springframework.boot.autoconfigure.web.servlet.MultipartProperties'
2020-04-23 18:59:18 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'errorPageCustomizer' via factory method to bean named 'dispatcherServletRegistration'
2020-04-23 18:59:18 [DEBUG](TomcatServletWebServerFactory ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Code archive: F:\Maven\maven-jar\org\springframework\boot\spring-boot\2.2.6.RELEASE\spring-boot-2.2.6.RELEASE.jar
2020-04-23 18:59:18 [DEBUG](TomcatServletWebServerFactory ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Code archive: F:\Maven\maven-jar\org\springframework\boot\spring-boot\2.2.6.RELEASE\spring-boot-2.2.6.RELEASE.jar
2020-04-23 18:59:18 [DEBUG](TomcatServletWebServerFactory ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] None of the document roots [src/main/webapp, public, static] point to a directory and will be ignored.
2020-04-23 18:59:18 [INFO ](TomcatWebServer               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Tomcat initialized with port(s): 8082 (http)
2020-04-23 18:59:19 [DEBUG](ContextLoader                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-04-23 18:59:19 [INFO ](ContextLoader                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Root WebApplicationContext: initialization completed in 2450 ms
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'statViewServletRegistrationBean'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'com.alibaba.druid.spring.boot.autoconfigure.stat.DruidStatViewServletConfiguration'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.datasource.druid-com.alibaba.druid.spring.boot.autoconfigure.properties.DruidStatProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'statViewServletRegistrationBean' via factory method to bean named 'spring.datasource.druid-com.alibaba.druid.spring.boot.autoconfigure.properties.DruidStatProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'webStatFilterRegistrationBean'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'com.alibaba.druid.spring.boot.autoconfigure.stat.DruidWebStatFilterConfiguration'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'webStatFilterRegistrationBean' via factory method to bean named 'spring.datasource.druid-com.alibaba.druid.spring.boot.autoconfigure.properties.DruidStatProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'corsFilter'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'customCorsConfiguration'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'requestContextFilter'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'formContentFilter'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'characterEncodingFilter'
2020-04-23 18:59:19 [DEBUG](ServletContextInitializerBeans) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Mapping filters: filterRegistrationBean urls=[/*] order=2147483647, characterEncodingFilter urls=[/*] order=-2147483648, formContentFilter urls=[/*] order=-9900, requestContextFilter urls=[/*] order=-105, corsFilter urls=[/*] order=2147483647
2020-04-23 18:59:19 [DEBUG](ServletContextInitializerBeans) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Mapping servlets: dispatcherServlet urls=[/], statViewServlet urls=[/druid/*]
2020-04-23 18:59:19 [DEBUG](OrderedRequestContextFilter   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Filter 'requestContextFilter' configured for use
2020-04-23 18:59:19 [DEBUG](CorsFilter                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Filter 'corsFilter' configured for use
2020-04-23 18:59:19 [DEBUG](OrderedCharacterEncodingFilter) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Filter 'characterEncodingFilter' configured for use
2020-04-23 18:59:19 [DEBUG](OrderedFormContentFilter      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Filter 'formContentFilter' configured for use
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'graduationProjectWebApplication'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisClient'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisTemplate'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisConnectionFactory'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.redis.JedisConnectionConfiguration'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.redis-org.springframework.boot.autoconfigure.data.redis.RedisProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.data.redis.JedisConnectionConfiguration' via constructor to bean named 'spring.redis-org.springframework.boot.autoconfigure.data.redis.RedisProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'redisTemplate' via factory method to bean named 'redisConnectionFactory'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'interceptorConfig'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'authInterceptor'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'bookController'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'bookServiceImpl'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'bookMapper'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'sqlSessionFactory'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration'
2020-04-23 18:59:19 [DEBUG](LocalVariableTableParameterNameDiscoverer) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot find '.class' file for class [class org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration$$EnhancerBySpringCGLIB$$e29ca8c4] - unable to determine constructor/method parameter names
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mybatis-org.mybatis.spring.boot.autoconfigure.MybatisProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration' via constructor to bean named 'mybatis-org.mybatis.spring.boot.autoconfigure.MybatisProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'dataSource'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceAutoConfigure'
2020-04-23 18:59:19 [INFO ](DruidDataSourceAutoConfigure  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Init DruidDataSource
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'statFilter'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'com.alibaba.druid.spring.boot.autoconfigure.stat.DruidFilterConfiguration'
2020-04-23 18:59:19 [INFO ](DruidDataSource               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] {dataSource-1} inited
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceInitializerInvoker'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jdbc.DataSourceInitializerInvoker' via constructor to bean named 'spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jdbc.DataSourceInitializerInvoker' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:19 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'sqlSessionFactory' via factory method to bean named 'dataSource'
2020-04-23 18:59:20 [DEBUG](SqlSessionFactoryBean         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parsed mapper file: 'file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\mapper\BookMapper.xml]'
2020-04-23 18:59:20 [DEBUG](SqlSessionFactoryBean         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parsed mapper file: 'file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\mapper\ItemDetailMapper.xml]'
2020-04-23 18:59:20 [DEBUG](SqlSessionFactoryBean         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parsed mapper file: 'file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\mapper\ItemMapper.xml]'
2020-04-23 18:59:20 [DEBUG](SqlSessionFactoryBean         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parsed mapper file: 'file [F:\毕业设计\graduation-project\graduation-project-web\target\classes\mapper\UserMapper.xml]'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'sqlSessionTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'sqlSessionTemplate' via factory method to bean named 'sqlSessionFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaServiceImpl'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaProducerFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaProducerListener'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'kafkaTemplate' via factory method to bean named 'kafkaProducerListener'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'recommendController'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'itemCfCoefficientServiceImpl'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'itemServiceImpl'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'itemMapper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'itemDetailServiceImpl'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'itemDetailMapper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'userController'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'userServiceImpl'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'userMapper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'viewController'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.context.properties.ConfigurationBeanFactoryMetadata'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'taskExecutorBuilder'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'taskExecutorBuilder' via factory method to bean named 'spring.task.execution-org.springframework.boot.autoconfigure.task.TaskExecutionProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'defaultValidator'
2020-04-23 18:59:20 [DEBUG](TraversableResolvers          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot find javax.persistence.Persistence on classpath. Assuming non JPA 2 environment. All properties will per default be traversable.
2020-04-23 18:59:20 [DEBUG](ResourceBundleMessageInterpolator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loaded expression factory via original TCCL
2020-04-23 18:59:20 [DEBUG](TraversableResolvers          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot find javax.persistence.Persistence on classpath. Assuming non JPA 2 environment. All properties will per default be traversable.
2020-04-23 18:59:20 [DEBUG](ConfigurationImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Setting custom MessageInterpolator of type org.springframework.validation.beanvalidation.LocaleContextMessageInterpolator
2020-04-23 18:59:20 [DEBUG](ConfigurationImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Setting custom ConstraintValidatorFactory of type org.springframework.validation.beanvalidation.SpringConstraintValidatorFactory
2020-04-23 18:59:20 [DEBUG](ConfigurationImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Setting custom ParameterNameProvider of type org.springframework.validation.beanvalidation.LocalValidatorFactoryBean$1
2020-04-23 18:59:20 [DEBUG](ValidationXmlParser           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml for XML based Validator configuration.
2020-04-23 18:59:20 [DEBUG](ResourceLoaderHelper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml via user class loader
2020-04-23 18:59:20 [DEBUG](ResourceLoaderHelper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml via TCCL
2020-04-23 18:59:20 [DEBUG](ResourceLoaderHelper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load META-INF/validation.xml via Hibernate Validator's class loader
2020-04-23 18:59:20 [DEBUG](ValidationXmlParser           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No META-INF/validation.xml found. Using annotation based configuration only.
2020-04-23 18:59:20 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.springframework.validation.beanvalidation.LocaleContextMessageInterpolator as ValidatorFactory-scoped message interpolator.
2020-04-23 18:59:20 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.resolver.TraverseAllTraversableResolver as ValidatorFactory-scoped traversable resolver.
2020-04-23 18:59:20 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.util.ExecutableParameterNameProvider as ValidatorFactory-scoped parameter name provider.
2020-04-23 18:59:20 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.DefaultClockProvider as ValidatorFactory-scoped clock provider.
2020-04-23 18:59:20 [DEBUG](ValidatorFactoryImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] HV000234: Using org.hibernate.validator.internal.engine.scripting.DefaultScriptEvaluatorFactory as ValidatorFactory-scoped script evaluator factory.
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$WhitelabelErrorViewConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'error'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'beanNameViewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.resources-org.springframework.boot.autoconfigure.web.ResourceProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration$DefaultErrorViewResolverConfiguration' via constructor to bean named 'spring.resources-org.springframework.boot.autoconfigure.web.ResourceProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'conventionErrorViewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'errorAttributes'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'basicErrorController'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'basicErrorController' via factory method to bean named 'errorAttributes'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$EnableWebMvcConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$EnableWebMvcConfiguration' via constructor to bean named 'spring.resources-org.springframework.boot.autoconfigure.web.ResourceProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$EnableWebMvcConfiguration' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@320de594'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter' via constructor to bean named 'spring.resources-org.springframework.boot.autoconfigure.web.ResourceProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter' via constructor to bean named 'spring.mvc-org.springframework.boot.autoconfigure.web.servlet.WebMvcProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration$WebMvcAutoConfigurationAdapter' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@320de594'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataWebConfiguration'
2020-04-23 18:59:20 [DEBUG](LocalVariableTableParameterNameDiscoverer) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot find '.class' file for class [class org.springframework.data.web.config.SpringDataWebConfiguration$$EnhancerBySpringCGLIB$$112c85e7] - unable to determine constructor/method parameter names
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.data.web.config.SpringDataWebConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'pageableCustomizer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration' via constructor to bean named 'spring.data.web-org.springframework.boot.autoconfigure.data.web.SpringDataWebProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'sortCustomizer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'requestMappingHandlerAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcValidator'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcValidator'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerAdapter' via factory method to bean named 'mvcValidator'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'messageConverters'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'stringHttpMessageConverter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration$StringHttpMessageConverterConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'stringHttpMessageConverter' via factory method to bean named 'spring.http-org.springframework.boot.autoconfigure.http.HttpProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mappingJackson2HttpMessageConverter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration$MappingJackson2HttpMessageConverterConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'jacksonObjectMapper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$JacksonObjectMapperBuilderConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'standardJacksonObjectMapperBuilderCustomizer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$Jackson2ObjectMapperBuilderCustomizerConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'standardJacksonObjectMapperBuilderCustomizer' via factory method to bean named 'spring.jackson-org.springframework.boot.autoconfigure.jackson.JacksonProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'jacksonObjectMapperBuilder' via factory method to bean named 'standardJacksonObjectMapperBuilderCustomizer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'parameterNamesModule'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration$ParameterNamesModuleConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'jsonComponentModule'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'jacksonGeoModule'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.data.web.config.SpringDataJacksonConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'jacksonObjectMapper' via factory method to bean named 'jacksonObjectMapperBuilder'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mappingJackson2HttpMessageConverter' via factory method to bean named 'jacksonObjectMapper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'sortResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'pageableResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'applicationTaskExecutor'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'applicationTaskExecutor' via factory method to bean named 'taskExecutorBuilder'
2020-04-23 18:59:20 [INFO ](ThreadPoolTaskExecutor        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing ExecutorService 'applicationTaskExecutor'
2020-04-23 18:59:20 [DEBUG](RequestMappingHandlerAdapter  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'requestMappingHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'requestMappingHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](RequestMappingHandlerMapping  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 12 mappings in 'requestMappingHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'welcomePageHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'welcomePageHandlerMapping' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'welcomePageHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'welcomePageHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [INFO ](WelcomePageHandlerMapping     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding welcome page template: index
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcPathMatcher'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcUrlPathHelper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'viewControllerHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcPathMatcher'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcUrlPathHelper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'viewControllerHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'beanNameHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'beanNameHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'routerFunctionMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'routerFunctionMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'resourceHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcUrlPathHelper'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcPathMatcher'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'resourceHandlerMapping' via factory method to bean named 'mvcResourceUrlProvider'
2020-04-23 18:59:20 [DEBUG](SimpleUrlHandlerMapping       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'defaultServletHandlerMapping'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'handlerFunctionAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcUriComponentsContributor'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'mvcConversionService'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mvcUriComponentsContributor' via factory method to bean named 'requestMappingHandlerAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'httpRequestHandlerAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'simpleControllerHandlerAdapter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'handlerExceptionResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'handlerExceptionResolver' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](ExceptionHandlerExceptionResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mvcViewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mvcViewResolver' via factory method to bean named 'mvcContentNegotiationManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'defaultViewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'viewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'viewResolver' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@320de594'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'thymeleafViewResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration$ThymeleafViewResolverConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'templateEngine'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafDefaultConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'templateEngine' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'defaultTemplateResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration' via constructor to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'java8TimeDialect'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafJava8TimeDialect'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'spring.thymeleaf-org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'thymeleafViewResolver' via factory method to bean named 'templateEngine'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration$HikariPoolDataSourceMetadataProviderConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'hikariPoolDataSourceMetadataProvider'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.metadata.DataSourcePoolMetadataProvidersConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceInitializationConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.mybatis.spring.boot.autoconfigure.MybatisLanguageDriverAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' via constructor to bean named 'environment'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mbeanExporter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'objectNamingStrategy'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'objectNamingStrategy'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'mbeanExporter' via factory method to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@320de594'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'mbeanServer'
2020-04-23 18:59:20 [DEBUG](JmxUtils                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found MBeanServer: com.sun.jmx.mbeanserver.JmxMBeanServer@dc24521
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'springApplicationAdminRegistrar'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'springApplicationAdminRegistrar' via factory method to bean named 'environment'
2020-04-23 18:59:20 [DEBUG](SpringApplicationAdminMXBeanRegistrar$SpringApplicationAdmin) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Application Admin MBean registered with name 'org.springframework.boot:type=Admin,name=SpringApplication'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$ClassProxyingConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration$ClassProxyingConfiguration' via constructor to bean named 'org.springframework.beans.factory.support.DefaultListableBeanFactory@320de594'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.aop.AopAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'stringRedisTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'stringRedisTemplate' via factory method to bean named 'redisConnectionFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.cache.RedisCacheConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'cacheManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'cacheManagerCustomizers'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'cacheManager' via factory method to bean named 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'cacheManager' via factory method to bean named 'cacheManagerCustomizers'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'cacheManager' via factory method to bean named 'redisConnectionFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'cacheManager' via factory method to bean named 'org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@14fc1f0'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'cacheAutoConfigurationValidator'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'cacheAutoConfigurationValidator' via factory method to bean named 'spring.cache-org.springframework.boot.autoconfigure.cache.CacheProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'keyValueMappingContext'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisCustomConversions'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisReferenceResolver'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisConverter'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisKeyValueAdapter'
2020-04-23 18:59:20 [DEBUG](RedisMessageListenerContainer ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Postpone listening for Redis messages until actual listeners are added
2020-04-23 18:59:20 [DEBUG](RedisMessageListenerContainer ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Started RedisMessageListenerContainer
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'redisKeyValueTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.http.JacksonHttpMessageConvertersConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.data.web.config.ProjectingArgumentResolverRegistrar'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration' via constructor to bean named 'spring.info-org.springframework.boot.autoconfigure.info.ProjectInfoProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'jdbcTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'dataSource'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'jdbcTemplate' via factory method to bean named 'spring.jdbc-org.springframework.boot.autoconfigure.jdbc.JdbcProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.NamedParameterJdbcTemplateConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'namedParameterJdbcTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'namedParameterJdbcTemplate' via factory method to bean named 'jdbcTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration$EnableKafkaConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'org.springframework.boot.autoconfigure.kafka.KafkaAnnotationDrivenConfiguration' via constructor to bean named 'spring.kafka-org.springframework.boot.autoconfigure.kafka.KafkaProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaListenerContainerFactoryConfigurer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaListenerContainerFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'kafkaListenerContainerFactory' via factory method to bean named 'kafkaListenerContainerFactoryConfigurer'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaConsumerFactory'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'kafkaAdmin'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.security.oauth2.resourceserver-org.springframework.boot.autoconfigure.security.oauth2.resource.OAuth2ResourceServerProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'taskSchedulerBuilder'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'taskSchedulerBuilder' via factory method to bean named 'spring.task.scheduling-org.springframework.boot.autoconfigure.task.TaskSchedulingProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$ThymeleafWebMvcConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration$DataSourceTransactionManagerConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'transactionManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'transactionManager' via factory method to bean named 'dataSource'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'platformTransactionManagerCustomizers'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'spring.transaction-org.springframework.boot.autoconfigure.transaction.TransactionProperties'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration$CglibAutoProxyConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$EnableTransactionManagementConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration$TransactionTemplateConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'transactionTemplate'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autowiring by type from bean name 'transactionTemplate' via factory method to bean named 'transactionManager'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'restTemplateBuilder'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration'
2020-04-23 18:59:20 [DEBUG](DefaultListableBeanFactory    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating shared instance of singleton bean 'multipartResolver'
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering beans for JMX exposure on startup
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Autodetecting user-defined JMX MBeans
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Bean with name 'statFilter' has been autodetected for JMX exposure
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Bean with name 'dataSource' has been autodetected for JMX exposure
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.spring.boot.autoconfigure:name=dataSource,type=DruidDataSourceWrapper]
2020-04-23 18:59:20 [DEBUG](AnnotationMBeanExporter       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Located MBean 'statFilter': registering with JMX server as MBean [com.alibaba.druid.filter.stat:name=statFilter,type=StatFilter]
2020-04-23 18:59:20 [DEBUG](DefaultLifecycleProcessor     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting beans in phase 2147483547
2020-04-23 18:59:20 [DEBUG](DefaultLifecycleProcessor     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully started bean 'org.springframework.kafka.config.internalKafkaListenerEndpointRegistry'
2020-04-23 18:59:20 [DEBUG](ConditionEvaluationReportLoggingListener) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 


============================
CONDITIONS EVALUATION REPORT
============================


Positive matches:
-----------------

   AopAutoConfiguration matched:
      - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition)

   AopAutoConfiguration.ClassProxyingConfiguration matched:
      - @ConditionalOnMissingClass did not find unwanted class 'org.aspectj.weaver.Advice' (OnClassCondition)
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   CacheAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.cache.CacheManager' (OnClassCondition)
      - @ConditionalOnBean (types: org.springframework.cache.interceptor.CacheAspectSupport; SearchStrategy: all) found bean 'cacheInterceptor'; @ConditionalOnMissingBean (names: cacheResolver types: org.springframework.cache.CacheManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   CacheAutoConfiguration#cacheManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.cache.CacheManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DataSourceAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   DataSourceConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)
      - @ConditionalOnProperty (spring.datasource.type=com.zaxxer.hikari.HikariDataSource) matched (OnPropertyCondition)

   DataSourceJmxConfiguration matched:
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   DataSourceJmxConfiguration.Hikari matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.HikariPoolDataSourceMetadataProviderConfiguration matched:
      - @ConditionalOnClass found required class 'com.zaxxer.hikari.HikariDataSource' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.jdbc.core.JdbcTemplate', 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   DataSourceTransactionManagerAutoConfiguration.DataSourceTransactionManagerConfiguration matched:
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a primary bean from beans 'dataSource' (OnBeanCondition)

   DataSourceTransactionManagerAutoConfiguration.DataSourceTransactionManagerConfiguration#transactionManager matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DispatcherServletAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - Default DispatcherServlet did not find dispatcher servlet beans (DispatcherServletAutoConfiguration.DefaultDispatcherServletCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRegistration' (OnClassCondition)
      - DispatcherServlet Registration did not find servlet registration bean (DispatcherServletAutoConfiguration.DispatcherServletRegistrationCondition)

   DispatcherServletAutoConfiguration.DispatcherServletRegistrationConfiguration#dispatcherServletRegistration matched:
      - @ConditionalOnBean (names: dispatcherServlet types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet' (OnBeanCondition)

   DruidDataSourceAutoConfigure matched:
      - @ConditionalOnClass found required class 'com.alibaba.druid.pool.DruidDataSource' (OnClassCondition)

   DruidDataSourceAutoConfigure#dataSource matched:
      - @ConditionalOnMissingBean (types: javax.sql.DataSource; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DruidFilterConfiguration#statFilter matched:
      - @ConditionalOnProperty (spring.datasource.druid.filter.stat.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: com.alibaba.druid.filter.stat.StatFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   DruidStatViewServletConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.datasource.druid.stat-view-servlet.enabled=true) matched (OnPropertyCondition)

   DruidWebStatFilterConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.datasource.druid.web-stat-filter.enabled=true) matched (OnPropertyCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration matched:
      - @ConditionalOnWebApplication (required) found 'session' scope (OnWebApplicationCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.TomcatWebServerFactoryCustomizerConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)

   ErrorMvcAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ErrorMvcAutoConfiguration#basicErrorController matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorController; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration#errorAttributes matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.error.ErrorAttributes; SearchStrategy: current) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.DefaultErrorViewResolverConfiguration#conventionErrorViewResolver matched:
      - @ConditionalOnBean (types: org.springframework.web.servlet.DispatcherServlet; SearchStrategy: all) found bean 'dispatcherServlet'; @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.web.servlet.error.ErrorViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration matched:
      - @ConditionalOnProperty (server.error.whitelabel.enabled) matched (OnPropertyCondition)
      - ErrorTemplate Missing did not find error template view (ErrorMvcAutoConfiguration.ErrorTemplateMissingCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#beanNameViewResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.BeanNameViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ErrorMvcAutoConfiguration.WhitelabelErrorViewConfiguration#defaultErrorView matched:
      - @ConditionalOnMissingBean (names: error; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpEncodingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.filter.CharacterEncodingFilter' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.http.encoding.enabled) matched (OnPropertyCondition)

   HttpEncodingAutoConfiguration#characterEncodingFilter matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.filter.CharacterEncodingFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.HttpMessageConverter' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (HttpMessageConvertersAutoConfiguration.NotReactiveWebApplicationCondition)

   HttpMessageConvertersAutoConfiguration#messageConverters matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.http.HttpMessageConverters; SearchStrategy: all) did not find any beans (OnBeanCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.StringHttpMessageConverter' (OnClassCondition)

   HttpMessageConvertersAutoConfiguration.StringHttpMessageConverterConfiguration#stringHttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.StringHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

   JacksonAutoConfiguration.Jackson2ObjectMapperBuilderCustomizerConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperBuilderConfiguration#jacksonObjectMapperBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.Jackson2ObjectMapperBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.http.converter.json.Jackson2ObjectMapperBuilder' (OnClassCondition)

   JacksonAutoConfiguration.JacksonObjectMapperConfiguration#jacksonObjectMapper matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.module.paramnames.ParameterNamesModule' (OnClassCondition)

   JacksonAutoConfiguration.ParameterNamesModuleConfiguration#parameterNamesModule matched:
      - @ConditionalOnMissingBean (types: com.fasterxml.jackson.module.paramnames.ParameterNamesModule; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration matched:
      - @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)
      - @ConditionalOnProperty (spring.http.converters.preferred-json-mapper=jackson) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2HttpMessageConverterConfiguration#mappingJackson2HttpMessageConverter matched:
      - @ConditionalOnMissingBean (types: org.springframework.http.converter.json.MappingJackson2HttpMessageConverter ignored: org.springframework.hateoas.server.mvc.TypeConstrainedMappingJackson2HttpMessageConverter,org.springframework.data.rest.webmvc.alps.AlpsJsonHttpMessageConverter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JdbcTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.core.JdbcTemplate' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a primary bean from beans 'dataSource' (OnBeanCondition)

   JdbcTemplateConfiguration matched:
      - @ConditionalOnMissingBean (types: org.springframework.jdbc.core.JdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JedisConnectionConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.commons.pool2.impl.GenericObjectPool', 'org.springframework.data.redis.connection.jedis.JedisConnection', 'redis.clients.jedis.Jedis' (OnClassCondition)

   JedisConnectionConfiguration#redisConnectionFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.redis.connection.RedisConnectionFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.jmx.export.MBeanExporter' (OnClassCondition)
      - @ConditionalOnProperty (spring.jmx.enabled=true) matched (OnPropertyCondition)

   JmxAutoConfiguration#mbeanExporter matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.MBeanExporter; SearchStrategy: current) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#mbeanServer matched:
      - @ConditionalOnMissingBean (types: javax.management.MBeanServer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   JmxAutoConfiguration#objectNamingStrategy matched:
      - @ConditionalOnMissingBean (types: org.springframework.jmx.export.naming.ObjectNamingStrategy; SearchStrategy: current) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.annotation.EnableKafka' (OnClassCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactory matched:
      - @ConditionalOnMissingBean (names: kafkaListenerContainerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration#kafkaListenerContainerFactoryConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.kafka.ConcurrentKafkaListenerContainerFactoryConfigurer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAnnotationDrivenConfiguration.EnableKafkaConfiguration matched:
      - @ConditionalOnMissingBean (names: org.springframework.kafka.config.internalKafkaListenerAnnotationProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.kafka.core.KafkaTemplate' (OnClassCondition)

   KafkaAutoConfiguration#kafkaAdmin matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaAdmin; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaConsumerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ConsumerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerFactory matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.ProducerFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaProducerListener matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.support.ProducerListener; SearchStrategy: all) did not find any beans (OnBeanCondition)

   KafkaAutoConfiguration#kafkaTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.kafka.core.KafkaTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MultipartAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.multipart.support.StandardServletMultipartResolver', 'javax.servlet.MultipartConfigElement' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.servlet.multipart.enabled) matched (OnPropertyCondition)

   MultipartAutoConfiguration#multipartConfigElement matched:
      - @ConditionalOnMissingBean (types: javax.servlet.MultipartConfigElement,org.springframework.web.multipart.commons.CommonsMultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MultipartAutoConfiguration#multipartResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MybatisAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.ibatis.session.SqlSessionFactory', 'org.mybatis.spring.SqlSessionFactoryBean' (OnClassCondition)
      - @ConditionalOnSingleCandidate (types: javax.sql.DataSource; SearchStrategy: all) found a primary bean from beans 'dataSource' (OnBeanCondition)

   MybatisAutoConfiguration#sqlSessionFactory matched:
      - @ConditionalOnMissingBean (types: org.apache.ibatis.session.SqlSessionFactory; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MybatisAutoConfiguration#sqlSessionTemplate matched:
      - @ConditionalOnMissingBean (types: org.mybatis.spring.SqlSessionTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   MybatisLanguageDriverAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.apache.ibatis.scripting.LanguageDriver' (OnClassCondition)

   NamedParameterJdbcTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.jdbc.core.JdbcTemplate; SearchStrategy: all) found a primary bean from beans 'jdbcTemplate'; @ConditionalOnMissingBean (types: org.springframework.jdbc.core.namedparam.NamedParameterJdbcOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   OAuth2ResourceServerAutoConfiguration matched:
      - found 'session' scope (OnWebApplicationCondition)

   PersistenceExceptionTranslationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor' (OnClassCondition)

   PersistenceExceptionTranslationAutoConfiguration#persistenceExceptionTranslationPostProcessor matched:
      - @ConditionalOnProperty (spring.dao.exceptiontranslation.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   PropertyPlaceholderAutoConfiguration#propertySourcesPlaceholderConfigurer matched:
      - @ConditionalOnMissingBean (types: org.springframework.context.support.PropertySourcesPlaceholderConfigurer; SearchStrategy: current) did not find any beans (OnBeanCondition)

   RedisAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.redis.core.RedisOperations' (OnClassCondition)

   RedisAutoConfiguration#stringRedisTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.redis.core.StringRedisTemplate; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RedisCacheConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.redis.connection.RedisConnectionFactory' (OnClassCondition)
      - Cache org.springframework.boot.autoconfigure.cache.RedisCacheConfiguration automatic cache type (CacheCondition)
      - @ConditionalOnBean (types: org.springframework.data.redis.connection.RedisConnectionFactory; SearchStrategy: all) found bean 'redisConnectionFactory'; @ConditionalOnMissingBean (types: org.springframework.cache.CacheManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RedisRepositoriesAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.data.redis.repository.configuration.EnableRedisRepositories' (OnClassCondition)
      - @ConditionalOnProperty (spring.data.redis.repositories.enabled=true) matched (OnPropertyCondition)
      - @ConditionalOnBean (types: org.springframework.data.redis.connection.RedisConnectionFactory; SearchStrategy: all) found bean 'redisConnectionFactory'; @ConditionalOnMissingBean (types: org.springframework.data.redis.repository.support.RedisRepositoryFactoryBean; SearchStrategy: all) did not find any beans (OnBeanCondition)

   RestTemplateAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.web.client.RestTemplate' (OnClassCondition)
      - NoneNestedConditions 0 matched 1 did not; NestedCondition on RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition.ReactiveWebApplication did not find reactive web application classes (RestTemplateAutoConfiguration.NotReactiveWebApplicationCondition)

   RestTemplateAutoConfiguration#restTemplateBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.client.RestTemplateBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ServletWebServerFactoryAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.servlet.ServletRequest' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   ServletWebServerFactoryAutoConfiguration#tomcatServletWebServerFactoryCustomizer matched:
      - @ConditionalOnClass found required class 'org.apache.catalina.startup.Tomcat' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedTomcat matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.apache.catalina.startup.Tomcat', 'org.apache.coyote.UpgradeProtocol' (OnClassCondition)
      - @ConditionalOnMissingBean (types: org.springframework.boot.web.servlet.server.ServletWebServerFactory; SearchStrategy: current) did not find any beans (OnBeanCondition)

   SpringApplicationAdminJmxAutoConfiguration matched:
      - @ConditionalOnProperty (spring.application.admin.enabled=true) matched (OnPropertyCondition)

   SpringApplicationAdminJmxAutoConfiguration#springApplicationAdminRegistrar matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.admin.SpringApplicationAdminMXBeanRegistrar; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.springframework.data.web.PageableHandlerMethodArgumentResolver', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.data.web.PageableHandlerMethodArgumentResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#pageableCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.PageableHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   SpringDataWebAutoConfiguration#sortCustomizer matched:
      - @ConditionalOnMissingBean (types: org.springframework.data.web.config.SortHandlerMethodArgumentResolverCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor' (OnClassCondition)

   TaskExecutionAutoConfiguration#applicationTaskExecutor matched:
      - @ConditionalOnMissingBean (types: java.util.concurrent.Executor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskExecutionAutoConfiguration#taskExecutorBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskExecutorBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TaskSchedulingAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskSchedulerBuilder matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.task.TaskSchedulerBuilder; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'org.thymeleaf.templatemode.TemplateMode', 'org.thymeleaf.spring5.SpringTemplateEngine' (OnClassCondition)

   ThymeleafAutoConfiguration.DefaultTemplateResolverConfiguration matched:
      - @ConditionalOnMissingBean (names: defaultTemplateResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafDefaultConfiguration#templateEngine matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.spring5.ISpringTemplateEngine; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect matched:
      - @ConditionalOnClass found required class 'org.thymeleaf.extras.java8time.dialect.Java8TimeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafJava8TimeDialect#java8TimeDialect matched:
      - @ConditionalOnMissingBean (types: org.thymeleaf.extras.java8time.dialect.Java8TimeDialect; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration matched:
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnProperty (spring.thymeleaf.enabled) matched (OnPropertyCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration.ThymeleafViewResolverConfiguration#thymeleafViewResolver matched:
      - @ConditionalOnMissingBean (names: thymeleafViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration matched:
      - @ConditionalOnClass found required class 'org.springframework.transaction.PlatformTransactionManager' (OnClassCondition)

   TransactionAutoConfiguration#platformTransactionManagerCustomizers matched:
      - @ConditionalOnMissingBean (types: org.springframework.boot.autoconfigure.transaction.TransactionManagerCustomizers; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration matched:
      - @ConditionalOnBean (types: org.springframework.transaction.TransactionManager; SearchStrategy: all) found bean 'transactionManager'; @ConditionalOnMissingBean (types: org.springframework.transaction.annotation.AbstractTransactionManagementConfiguration; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.CglibAutoProxyConfiguration matched:
      - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration matched:
      - @ConditionalOnSingleCandidate (types: org.springframework.transaction.PlatformTransactionManager; SearchStrategy: all) found a primary bean from beans 'transactionManager' (OnBeanCondition)

   TransactionAutoConfiguration.TransactionTemplateConfiguration#transactionTemplate matched:
      - @ConditionalOnMissingBean (types: org.springframework.transaction.support.TransactionOperations; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ValidationAutoConfiguration matched:
      - @ConditionalOnClass found required class 'javax.validation.executable.ExecutableValidator' (OnClassCondition)
      - @ConditionalOnResource found location classpath:META-INF/services/javax.validation.spi.ValidationProvider (OnResourceCondition)

   ValidationAutoConfiguration#defaultValidator matched:
      - @ConditionalOnMissingBean (types: javax.validation.Validator; SearchStrategy: all) did not find any beans (OnBeanCondition)

   ValidationAutoConfiguration#methodValidationPostProcessor matched:
      - @ConditionalOnMissingBean (types: org.springframework.validation.beanvalidation.MethodValidationPostProcessor; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebMvcAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'org.springframework.web.servlet.DispatcherServlet', 'org.springframework.web.servlet.config.annotation.WebMvcConfigurer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebMvcAutoConfiguration#formContentFilter matched:
      - @ConditionalOnProperty (spring.mvc.formcontent.filter.enabled) matched (OnPropertyCondition)
      - @ConditionalOnMissingBean (types: org.springframework.web.filter.FormContentFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#defaultViewResolver matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.InternalResourceViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#requestContextFilter matched:
      - @ConditionalOnMissingBean (types: org.springframework.web.context.request.RequestContextListener,org.springframework.web.filter.RequestContextFilter; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#viewResolver matched:
      - @ConditionalOnBean (types: org.springframework.web.servlet.ViewResolver; SearchStrategy: all) found beans 'defaultViewResolver', 'beanNameViewResolver', 'mvcViewResolver'; @ConditionalOnMissingBean (names: viewResolver types: org.springframework.web.servlet.view.ContentNegotiatingViewResolver; SearchStrategy: all) did not find any beans (OnBeanCondition)

   WebSocketServletAutoConfiguration matched:
      - @ConditionalOnClass found required classes 'javax.servlet.Servlet', 'javax.websocket.server.ServerContainer' (OnClassCondition)
      - found 'session' scope (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration matched:
      - @ConditionalOnClass found required classes 'org.apache.catalina.startup.Tomcat', 'org.apache.tomcat.websocket.server.WsSci' (OnClassCondition)

   WebSocketServletAutoConfiguration.TomcatWebSocketConfiguration#websocketServletWebServerCustomizer matched:
      - @ConditionalOnMissingBean (names: websocketServletWebServerCustomizer; SearchStrategy: all) did not find any beans (OnBeanCondition)


Negative matches:
-----------------

   ActiveMQAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   AopAutoConfiguration.AspectJAutoProxyingConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.aspectj.weaver.Advice' (OnClassCondition)

   ArtemisAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition)

   BatchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.batch.core.launch.JobLauncher' (OnClassCondition)

   CacheAutoConfiguration.CacheManagerEntityManagerFactoryDependsOnPostProcessor:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean' (OnClassCondition)

   CaffeineCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.benmanes.caffeine.cache.Caffeine' (OnClassCondition)

   CassandraAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.driver.core.Cluster' (OnClassCondition)

   CassandraDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.driver.core.Cluster' (OnClassCondition)

   CassandraReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.driver.core.Cluster' (OnClassCondition)

   CassandraReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.cassandra.ReactiveSession' (OnClassCondition)

   CassandraRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.datastax.driver.core.Session' (OnClassCondition)

   ClientHttpConnectorAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CloudServiceConnectorsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.cloud.config.java.CloudScanConfiguration' (OnClassCondition)

   CodecsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   CouchbaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Cluster' (OnClassCondition)

   CouchbaseCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'com.couchbase.client.java.Bucket', 'com.couchbase.client.spring.cache.CouchbaseCacheManager' (OnClassCondition)

   CouchbaseDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   CouchbaseRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.couchbase.client.java.Bucket' (OnClassCondition)

   DataSourceAutoConfiguration.EmbeddedDatabaseConfiguration:
      Did not match:
         - EmbeddedDataSource found supported pooled data source (DataSourceAutoConfiguration.EmbeddedDatabaseCondition)

   DataSourceAutoConfiguration.PooledDataSourceConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: javax.sql.DataSource,javax.sql.XADataSource; SearchStrategy: all) found beans of type 'javax.sql.DataSource' dataSource (OnBeanCondition)
      Matched:
         - AnyNestedCondition 1 matched 1 did not; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.PooledDataSourceAvailable PooledDataSource found supported DataSource; NestedCondition on DataSourceAutoConfiguration.PooledDataSourceCondition.ExplicitType @ConditionalOnProperty (spring.datasource.type) did not find property 'type' (DataSourceAutoConfiguration.PooledDataSourceCondition)

   DataSourceConfiguration.Dbcp2:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourceConfiguration.Generic:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.type) did not find property 'spring.datasource.type' (OnPropertyCondition)

   DataSourceConfiguration.Tomcat:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DataSourceJmxConfiguration.TomcatDataSourceJmxConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSourceProxy' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.CommonsDbcp2PoolDataSourceMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.commons.dbcp2.BasicDataSource' (OnClassCondition)

   DataSourcePoolMetadataProvidersConfiguration.TomcatDataSourcePoolMetadataProviderConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.tomcat.jdbc.pool.DataSource' (OnClassCondition)

   DispatcherServletAutoConfiguration.DispatcherServletConfiguration#multipartResolver:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.web.multipart.MultipartResolver; SearchStrategy: all) did not find any beans of type org.springframework.web.multipart.MultipartResolver (OnBeanCondition)

   DruidFilterConfiguration#commonsLogFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.commons-log.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#configFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.config.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#encodingConvertFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.encoding.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#log4j2Filter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.log4j2.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#log4jFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.log4j.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#slf4jLogFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.slf4j.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#wallConfig:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.wall.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidFilterConfiguration#wallFilter:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.filter.wall.enabled) did not find property 'enabled' (OnPropertyCondition)

   DruidSpringAopConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.druid.aop-patterns) did not find property 'spring.datasource.druid.aop-patterns' (OnPropertyCondition)

   EhCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'net.sf.ehcache.Cache' (OnClassCondition)

   ElasticsearchAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.Client' (OnClassCondition)

   ElasticsearchDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.core.ElasticsearchTemplate' (OnClassCondition)

   ElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.Client' (OnClassCondition)

   EmbeddedLdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.unboundid.ldap.listener.InMemoryDirectoryServer' (OnClassCondition)

   EmbeddedMongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClient' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.JettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.NettyWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.server.HttpServer' (OnClassCondition)

   EmbeddedWebServerFactoryCustomizerAutoConfiguration.UndertowWebServerFactoryCustomizerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   ErrorWebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   FlywayAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.flywaydb.core.Flyway' (OnClassCondition)

   FreeMarkerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'freemarker.template.Configuration' (OnClassCondition)

   GenericCacheConfiguration:
      Did not match:
         - @ConditionalOnBean (types: org.springframework.cache.Cache; SearchStrategy: all) did not find any beans of type org.springframework.cache.Cache (OnBeanCondition)
      Matched:
         - Cache org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration automatic cache type (CacheCondition)

   GroovyTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'groovy.text.markup.MarkupTemplateEngine' (OnClassCondition)

   GsonAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   GsonHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.google.gson.Gson' (OnClassCondition)

   H2ConsoleAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.h2.server.web.WebServlet' (OnClassCondition)

   HazelcastAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HazelcastCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'com.hazelcast.core.HazelcastInstance', 'com.hazelcast.spring.cache.HazelcastCacheManager' (OnClassCondition)

   HazelcastJpaDependencyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.hazelcast.core.HazelcastInstance' (OnClassCondition)

   HibernateJpaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.persistence.EntityManager' (OnClassCondition)

   HttpHandlerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.DispatcherHandler' (OnClassCondition)

   HypermediaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.hateoas.EntityModel' (OnClassCondition)

   InfinispanCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.infinispan.spring.embedded.provider.SpringEmbeddedCacheManager' (OnClassCondition)

   InfluxDbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.influxdb.InfluxDB' (OnClassCondition)

   IntegrationAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.integration.config.EnableIntegration' (OnClassCondition)

   JCacheCacheConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.cache.Caching' (OnClassCondition)

   JacksonAutoConfiguration.JodaDateTimeJacksonConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.joda.time.DateTime', 'com.fasterxml.jackson.datatype.joda.ser.DateTimeSerializer', 'com.fasterxml.jackson.datatype.joda.cfg.JacksonJodaDateFormat' (OnClassCondition)

   JacksonHttpMessageConvertersConfiguration.MappingJackson2XmlHttpMessageConverterConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.fasterxml.jackson.dataformat.xml.XmlMapper' (OnClassCondition)

   JdbcRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jdbc.repository.config.AbstractJdbcConfiguration' (OnClassCondition)

   JerseyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.glassfish.jersey.server.spring.SpringComponentProvider' (OnClassCondition)

   JestAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.searchbox.client.JestClient' (OnClassCondition)

   JmsAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.jms.Message' (OnClassCondition)

   JndiConnectionFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.jms.core.JmsTemplate' (OnClassCondition)

   JndiDataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.datasource.jndi-name) did not find property 'jndi-name' (OnPropertyCondition)
      Matched:
         - @ConditionalOnClass found required classes 'javax.sql.DataSource', 'org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType' (OnClassCondition)

   JooqAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.jooq.DSLContext' (OnClassCondition)

   JpaRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.jpa.repository.JpaRepository' (OnClassCondition)

   JsonbAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   JsonbHttpMessageConvertersConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.json.bind.Jsonb' (OnClassCondition)

   JtaAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.transaction.Transaction' (OnClassCondition)

   KafkaAutoConfiguration#kafkaJaasInitializer:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.jaas.enabled) did not find property 'spring.kafka.jaas.enabled' (OnPropertyCondition)

   KafkaAutoConfiguration#kafkaTransactionManager:
      Did not match:
         - @ConditionalOnProperty (spring.kafka.producer.transaction-id-prefix) did not find property 'spring.kafka.producer.transaction-id-prefix' (OnPropertyCondition)

   KafkaStreamsAnnotationDrivenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.kafka.streams.StreamsBuilder' (OnClassCondition)

   LdapAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ldap.core.ContextSource' (OnClassCondition)

   LdapRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.ldap.repository.LdapRepository' (OnClassCondition)

   LettuceConnectionConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.lettuce.core.RedisClient' (OnClassCondition)

   LiquibaseAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'liquibase.change.DatabaseChange' (OnClassCondition)

   MailSenderAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.mail.internet.MimeMessage' (OnClassCondition)

   MailSenderValidatorAutoConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.mail.test-connection) did not find property 'test-connection' (OnPropertyCondition)

   MessageSourceAutoConfiguration:
      Did not match:
         - ResourceBundle did not find bundle with basename messages (MessageSourceAutoConfiguration.ResourceBundleCondition)

   MongoAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClient' (OnClassCondition)

   MongoDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.client.MongoClient' (OnClassCondition)

   MongoReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoReactiveRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.reactivestreams.client.MongoClient' (OnClassCondition)

   MongoRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.mongodb.MongoClient' (OnClassCondition)

   MustacheAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.samskivert.mustache.Mustache' (OnClassCondition)

   MybatisAutoConfiguration.MapperScannerRegistrarNotFoundConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.mybatis.spring.mapper.MapperFactoryBean,org.mybatis.spring.mapper.MapperScannerConfigurer; SearchStrategy: all) found beans of type 'org.mybatis.spring.mapper.MapperScannerConfigurer' com.example.graduationproject.web.GraduationProjectWebApplication#MapperScannerRegistrar#0 (OnBeanCondition)

   MybatisLanguageDriverAutoConfiguration.FreeMarkerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.mybatis.scripting.freemarker.FreeMarkerLanguageDriver', 'org.mybatis.scripting.freemarker.FreeMarkerLanguageDriverConfig' (OnClassCondition)

   MybatisLanguageDriverAutoConfiguration.LegacyFreeMarkerConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.mybatis.scripting.freemarker.FreeMarkerLanguageDriver' (OnClassCondition)

   MybatisLanguageDriverAutoConfiguration.LegacyVelocityConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.mybatis.scripting.velocity.Driver' (OnClassCondition)

   MybatisLanguageDriverAutoConfiguration.ThymeleafConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.mybatis.scripting.thymeleaf.ThymeleafLanguageDriver' (OnClassCondition)

   MybatisLanguageDriverAutoConfiguration.VelocityConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.mybatis.scripting.velocity.VelocityLanguageDriver', 'org.mybatis.scripting.velocity.VelocityLanguageDriverConfig' (OnClassCondition)

   Neo4jDataAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.ogm.session.SessionFactory' (OnClassCondition)

   Neo4jRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.neo4j.ogm.session.Neo4jSession' (OnClassCondition)

   NoOpCacheConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.cache.CacheManager; SearchStrategy: all) found beans of type 'org.springframework.cache.CacheManager' cacheManager (OnBeanCondition)
      Matched:
         - Cache org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration automatic cache type (CacheCondition)

   OAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.configuration.EnableWebSecurity' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration.JwtConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.springframework.security.oauth2.server.resource.authentication.JwtAuthenticationToken', 'org.springframework.security.oauth2.jwt.JwtDecoder' (OnClassCondition)

   OAuth2ResourceServerAutoConfiguration.OpaqueTokenConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.springframework.security.oauth2.server.resource.BearerTokenAuthenticationToken', 'org.springframework.security.oauth2.server.resource.introspection.OpaqueTokenIntrospector' (OnClassCondition)

   ProjectInfoAutoConfiguration#buildProperties:
      Did not match:
         - @ConditionalOnResource did not find resource '${spring.info.build.location:classpath:META-INF/build-info.properties}' (OnResourceCondition)

   ProjectInfoAutoConfiguration#gitProperties:
      Did not match:
         - GitResource did not find git info at classpath:git.properties (ProjectInfoAutoConfiguration.GitResourceAvailableCondition)

   QuartzAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.quartz.Scheduler' (OnClassCondition)

   RSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocketFactory' (OnClassCondition)

   RSocketRequesterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocketFactory' (OnClassCondition)

   RSocketSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.rsocket.core.SecuritySocketAcceptorInterceptor' (OnClassCondition)

   RSocketServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocketFactory' (OnClassCondition)

   RSocketStrategiesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.rsocket.RSocketFactory' (OnClassCondition)

   RabbitAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.rabbitmq.client.Channel' (OnClassCondition)

   ReactiveElasticsearchRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.elasticsearch.client.reactive.ReactiveElasticsearchClient' (OnClassCondition)

   ReactiveOAuth2ClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveOAuth2ResourceServerAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.annotation.web.reactive.EnableWebFluxSecurity' (OnClassCondition)

   ReactiveRestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.netty.http.client.HttpClient' (OnClassCondition)

   ReactiveSecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   ReactiveUserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.ReactiveAuthenticationManager' (OnClassCondition)

   ReactiveWebServerFactoryAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   RedisAutoConfiguration#redisTemplate:
      Did not match:
         - @ConditionalOnMissingBean (names: redisTemplate; SearchStrategy: all) found beans named redisTemplate (OnBeanCondition)

   RedisReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'reactor.core.publisher.Flux' (OnClassCondition)

   RepositoryRestMvcAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.data.rest.webmvc.config.RepositoryRestMvcConfiguration' (OnClassCondition)

   RestClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.elasticsearch.client.RestClient' (OnClassCondition)

   Saml2RelyingPartyAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.saml2.provider.service.registration.RelyingPartyRegistrationRepository' (OnClassCondition)

   SecurityAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.DefaultAuthenticationEventPublisher' (OnClassCondition)

   SecurityFilterAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.config.http.SessionCreationPolicy' (OnClassCondition)

   SendGridAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.sendgrid.SendGrid' (OnClassCondition)

   ServletWebServerFactoryAutoConfiguration#forwardedHeaderFilter:
      Did not match:
         - @ConditionalOnProperty (server.forward-headers-strategy=framework) did not find property 'server.forward-headers-strategy' (OnPropertyCondition)

   ServletWebServerFactoryConfiguration.EmbeddedJetty:
      Did not match:
         - @ConditionalOnClass did not find required classes 'org.eclipse.jetty.server.Server', 'org.eclipse.jetty.util.Loader', 'org.eclipse.jetty.webapp.WebAppContext' (OnClassCondition)

   ServletWebServerFactoryConfiguration.EmbeddedUndertow:
      Did not match:
         - @ConditionalOnClass did not find required classes 'io.undertow.Undertow', 'org.xnio.SslClientAuthMode' (OnClassCondition)

   SessionAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.session.Session' (OnClassCondition)

   SimpleCacheConfiguration:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.cache.CacheManager; SearchStrategy: all) found beans of type 'org.springframework.cache.CacheManager' cacheManager (OnBeanCondition)
      Matched:
         - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition)

   SolrAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.solr.client.solrj.impl.CloudSolrClient' (OnClassCondition)

   SolrRepositoriesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.apache.solr.client.solrj.SolrClient' (OnClassCondition)

   TaskSchedulingAutoConfiguration#taskScheduler:
      Did not match:
         - @ConditionalOnBean (names: org.springframework.context.annotation.internalScheduledAnnotationProcessor; SearchStrategy: all) did not find any beans named org.springframework.context.annotation.internalScheduledAnnotationProcessor (OnBeanCondition)

   ThymeleafAutoConfiguration.DataAttributeDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'com.github.mxab.thymeleaf.extras.dataattribute.dialect.DataAttributeDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafReactiveConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.ThymeleafSecurityDialectConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.thymeleaf.extras.springsecurity5.dialect.SpringSecurityDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebFluxConfiguration:
      Did not match:
         - did not find reactive web application classes (OnWebApplicationCondition)

   ThymeleafAutoConfiguration.ThymeleafWebLayoutConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'nz.net.ultraq.thymeleaf.LayoutDialect' (OnClassCondition)

   ThymeleafAutoConfiguration.ThymeleafWebMvcConfiguration#resourceUrlEncodingFilter:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   TransactionAutoConfiguration#transactionalOperator:
      Did not match:
         - @ConditionalOnSingleCandidate (types: org.springframework.transaction.ReactiveTransactionManager; SearchStrategy: all) did not find any beans (OnBeanCondition)

   TransactionAutoConfiguration.EnableTransactionManagementConfiguration.JdkDynamicAutoProxyConfiguration:
      Did not match:
         - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition)

   UserDetailsServiceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.security.authentication.AuthenticationManager' (OnClassCondition)

   WebClientAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.function.client.WebClient' (OnClassCondition)

   WebFluxAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.reactive.config.WebFluxConfigurer' (OnClassCondition)

   WebMvcAutoConfiguration#hiddenHttpMethodFilter:
      Did not match:
         - @ConditionalOnProperty (spring.mvc.hiddenmethod.filter.enabled) did not find property 'enabled' (OnPropertyCondition)

   WebMvcAutoConfiguration.ResourceChainCustomizerConfiguration:
      Did not match:
         - @ConditionalOnEnabledResourceChain did not find class org.webjars.WebJarAssetLocator (OnEnabledResourceChainCondition)

   WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#beanNameViewResolver:
      Did not match:
         - @ConditionalOnMissingBean (types: org.springframework.web.servlet.view.BeanNameViewResolver; SearchStrategy: all) found beans of type 'org.springframework.web.servlet.view.BeanNameViewResolver' beanNameViewResolver (OnBeanCondition)

   WebMvcAutoConfiguration.WebMvcAutoConfigurationAdapter#localeResolver:
      Did not match:
         - @ConditionalOnProperty (spring.mvc.locale) did not find property 'locale' (OnPropertyCondition)

   WebServiceTemplateAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.client.core.WebServiceTemplate' (OnClassCondition)

   WebServicesAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.ws.transport.http.MessageDispatcherServlet' (OnClassCondition)

   WebSocketMessagingAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer' (OnClassCondition)

   WebSocketReactiveAutoConfiguration:
      Did not match:
         - @ConditionalOnWebApplication did not find reactive web application classes (OnWebApplicationCondition)

   WebSocketServletAutoConfiguration.JettyWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'org.eclipse.jetty.websocket.jsr356.server.deploy.WebSocketServerContainerInitializer' (OnClassCondition)

   WebSocketServletAutoConfiguration.UndertowWebSocketConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'io.undertow.websockets.jsr.Bootstrap' (OnClassCondition)

   XADataSourceAutoConfiguration:
      Did not match:
         - @ConditionalOnClass did not find required class 'javax.transaction.TransactionManager' (OnClassCondition)


Exclusions:
-----------

    None


Unconditional classes:
----------------------

    org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration

    org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration

    org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration



2020-04-23 18:59:20 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'spring.liveBeansView.mbeanDomain' in PropertySource 'systemProperties' with value of type String
2020-04-23 18:59:20 [INFO ](log                           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-04-23 18:59:20 [DEBUG](JspRuntimeContext             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] PWC5965: Parent class loader is: TomcatEmbeddedWebappClassLoader
  context: ROOT
  delegate: true
----------> Parent Classloader:
sun.misc.Launcher$AppClassLoader@18b4aac2

2020-04-23 18:59:20 [DEBUG](JspServlet                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] PWC5964: Scratch dir for the JSP engine is: C:\Users\Zzwen\AppData\Local\Temp\tomcat.9199566331830626401.8082\work\Tomcat\localhost\ROOT
2020-04-23 18:59:20 [DEBUG](JspServlet                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] PWC5966: IMPORTANT: Do not modify the generated servlets
2020-04-23 18:59:20 [INFO ](TomcatWebServer               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Tomcat started on port(s): 8082 (http) with context path ''
2020-04-23 18:59:20 [INFO ](GraduationProjectWebApplication) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Started GraduationProjectWebApplication in 5.249 seconds (JVM running for 7.884)
2020-04-23 18:59:22 [DEBUG](PropertySourcesPropertyResolver) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found key 'local.server.port' in PropertySource 'server.ports' with value of type Integer
2020-04-23 18:59:39 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.util.Properties
2020-04-23 18:59:39 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Long
2020-04-23 18:59:39 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=2, name='Map', outputType=String, parallelism=8}
2020-04-23 18:59:39 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming SourceTransformation{id=1, name='Custom Source', outputType=String, parallelism=8}
2020-04-23 18:59:39 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 1
2020-04-23 18:59:39 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 2
2020-04-23 18:59:39 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: Custom Source-1' {id: 1, parallelism: 8, user function: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer}
2020-04-23 18:59:39 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash '7df19f87deec5680128845fd9a6ca18d' for node 'Map-2' {id: 2, parallelism: 8, user function: com.example.graduationproject.map.UserHistoryMapFunction}
2020-04-23 18:59:39 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parallelism set: 8 for 1
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 18:59:39 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
2020-04-23 18:59:39 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Flink Mini Cluster
2020-04-23 18:59:39 [DEBUG](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, jobmanager.scheduler=ng, taskmanager.memory.managed.size=128 mb, taskmanager.numberOfTaskSlots=8, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2020-04-23 18:59:39 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Metrics Registry
2020-04-23 18:59:39 [INFO ](MetricRegistryImpl            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No metrics reporter configured, no metrics will be exposed/reported.
2020-04-23 18:59:39 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC Service(s)
2020-04-23 18:59:41 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 18:59:41 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 18:59:41 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 18:59:41 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to start actor system at :0
2020-04-23 18:59:41 [DEBUG](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy","provider":"akka.remote.RemoteActorRefProvider","warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","remote":{"log-remote-lifecycle-events":"off","netty":{"tcp":{"bind-hostname":"0.0.0.0","bind-port":0,"client-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"connection-timeout":"20000ms","hostname":"","maximum-frame-size":"10485760b","port":0,"server-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"tcp-nodelay":"on","transport-class":"akka.remote.transport.netty.NettyTransport"}},"retry-gate-closed-for":"50 ms","startup-timeout":"100000ms","transport-failure-detector":{"acceptable-heartbeat-pause":"6000000ms","heartbeat-interval":"1000000ms","threshold":300}},"serialize-messages":"off","stdout-loglevel":"OFF"}}))
2020-04-23 18:59:42 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 18:59:42 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 18:59:42 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 18:59:42 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting remoting
2020-04-23 18:59:42 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using select timeout of 500
2020-04-23 18:59:42 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Epoll-bug workaround enabled = false
2020-04-23 18:59:43 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.65.1:56429]
2020-04-23 18:59:43 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Actor system started at akka.tcp://flink-metrics@192.168.65.1:56429
2020-04-23 18:59:43 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-04-23 18:59:43 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting high-availability services
2020-04-23 18:59:43 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB server storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-d0441d4a-c87e-46f9-b61a-23b55fa44e90
2020-04-23 18:59:43 [DEBUG](NetUtils                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to open socket on port 0
2020-04-23 18:59:43 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Started BLOB server at 0.0.0.0:56430 - max concurrent requests: 50 - max backlog: 1000
2020-04-23 18:59:43 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-cc2ff824-d634-4cae-b7fd-2f4b5bfac87f
2020-04-23 18:59:43 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-850fca36-d553-462f-810c-2bb1aa114d13
2020-04-23 18:59:43 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting 1 TaskManger(s)
2020-04-23 18:59:43 [INFO ](TaskManagerRunner             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting TaskManager with ResourceID: b370fe99-e079-4822-a0ee-66aefd15310b
2020-04-23 18:59:43 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 18:59:43 [INFO ](TaskManagerServices           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Temporary file directory 'C:\Users\Zzwen\AppData\Local\Temp': total 237 GB, usable 69 GB (29.11% usable)
2020-04-23 18:59:43 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-a5bab873-3b5d-4e85-a2de-1b695e46ef53 for spill files.
2020-04-23 18:59:43 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-aebe7087-fb5f-4a80-8998-0a5926eda35a for spill files.
2020-04-23 18:59:43 [INFO ](NetworkBufferPool             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2020-04-23 18:59:43 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the network environment and its components.
2020-04-23 18:59:43 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting network connection manager
2020-04-23 18:59:43 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the kvState service and its components.
2020-04-23 18:59:43 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 18:59:43 [INFO ](TaskManagerConfiguration      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Messages have a max timeout of 10000 ms
2020-04-23 18:59:43 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-04-23 18:59:43 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start job leader service.
2020-04-23 18:59:43 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] User file cache uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-8ee05535-9e40-452c-bbdd-3e085f47c49b
2020-04-23 18:59:44 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Upload directory C:\Users\Zzwen\AppData\Local\Temp\flink-web-upload does not exist. 
2020-04-23 18:59:44 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created directory C:\Users\Zzwen\AppData\Local\Temp\flink-web-upload for file uploads.
2020-04-23 18:59:44 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher REST endpoint.
2020-04-23 18:59:44 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting rest endpoint.
2020-04-23 18:59:44 [DEBUG](InternalLoggerFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using SLF4J as the default logging framework
2020-04-23 18:59:44 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2020-04-23 18:59:44 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2020-04-23 18:59:44 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Log file environment variable 'log.file' is not set.
2020-04-23 18:59:44 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:192)
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:98)
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:141)
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:165)
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:394)
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:360)
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:314)
	at org.apache.flink.client.deployment.executors.LocalExecutor.startMiniCluster(LocalExecutor.java:117)
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:63)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1733)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1634)
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:74)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)
	at com.example.graduationproject.task.ItemHistoryTask.main(ItemHistoryTask.java:27)
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Platform: Windows
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noUnsafe: false
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Java version: 8
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.theUnsafe: available
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.copyMemory: available
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Buffer.address: available
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] direct buffer constructor: available
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Bits.unaligned: available, true
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2020-04-23 18:59:44 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.DirectByteBuffer.<init>(long, int): available
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe: available
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.tmpdir: C:\Users\Zzwen\AppData\Local\Temp (java.io.tmpdir)
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.bitMode: 64 (sun.arch.data.model)
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxDirectMemory: 3810525184 bytes
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.uninitializedArrayAllocationThreshold: -1
2020-04-23 18:59:44 [DEBUG](CleanerJava6                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.ByteBuffer.cleaner(): available
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noPreferDirect: false
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@3766c667 under DELETE@/v1/cluster.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@3766c667 under DELETE@/cluster.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@2dbd803f under GET@/v1/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@2dbd803f under GET@/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3e48e859 under GET@/v1/jobmanager/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@3e48e859 under GET@/jobmanager/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@31ddd4a4 under GET@/v1/jobmanager/log.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@31ddd4a4 under GET@/jobmanager/log.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@1a5f7e7c under GET@/v1/jobmanager/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@1a5f7e7c under GET@/jobmanager/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@5b22b970 under GET@/v1/jobmanager/stdout.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@5b22b970 under GET@/jobmanager/stdout.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@22d1886d under GET@/v1/jobs.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@22d1886d under GET@/jobs.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@7df60067 under POST@/v1/jobs.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@7df60067 under POST@/jobs.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1cbb3d3b under GET@/v1/jobs/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@1cbb3d3b under GET@/jobs/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@529cfee5 under GET@/v1/jobs/overview.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@529cfee5 under GET@/jobs/overview.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@7ca0863b under GET@/v1/jobs/:jobid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@7ca0863b under GET@/jobs/:jobid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@319854f0 under PATCH@/v1/jobs/:jobid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@319854f0 under PATCH@/jobs/:jobid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@748fe51d under GET@/v1/jobs/:jobid/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@748fe51d under GET@/jobs/:jobid/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@415156bf under GET@/v1/jobs/:jobid/checkpoints.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@415156bf under GET@/jobs/:jobid/checkpoints.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@393881f0 under GET@/v1/jobs/:jobid/checkpoints/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@393881f0 under GET@/jobs/:jobid/checkpoints/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@4af46df3 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@4af46df3 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@4158debd under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@4158debd under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@af78c87 under GET@/v1/jobs/:jobid/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@af78c87 under GET@/jobs/:jobid/config.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@773dab28 under GET@/v1/jobs/:jobid/exceptions.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@773dab28 under GET@/jobs/:jobid/exceptions.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@1ecfcbc9 under GET@/v1/jobs/:jobid/execution-result.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@1ecfcbc9 under GET@/jobs/:jobid/execution-result.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1965539b under GET@/v1/jobs/:jobid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@1965539b under GET@/jobs/:jobid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@2fc07784 under GET@/v1/jobs/:jobid/plan.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@2fc07784 under GET@/jobs/:jobid/plan.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@353efdbf under PATCH@/v1/jobs/:jobid/rescaling.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@353efdbf under PATCH@/jobs/:jobid/rescaling.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@55cff952 under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@55cff952 under GET@/jobs/:jobid/rescaling/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@660591fb under POST@/v1/jobs/:jobid/savepoints.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@660591fb under POST@/jobs/:jobid/savepoints.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@4a55a6e8 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@4a55a6e8 under GET@/jobs/:jobid/savepoints/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@8c46918 under POST@/v1/jobs/:jobid/stop.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@8c46918 under POST@/jobs/:jobid/stop.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@226b143b under GET@/v1/jobs/:jobid/vertices/:vertexid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@226b143b under GET@/jobs/:jobid/vertices/:vertexid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@682bd3c4 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@682bd3c4 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@f2e4acf under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@f2e4acf under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@24097e9b under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@24097e9b under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@5eb97ced under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@5eb97ced under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@68ba310d under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@68ba310d under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@153f66e7 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@153f66e7 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@7aad3f7d under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@7aad3f7d under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@6f667ad1 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@6f667ad1 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@566d0c69 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@566d0c69 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@388b401d under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@388b401d under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2bcec6a6 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@2bcec6a6 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@77a281fc under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@77a281fc under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@319854f0 under GET@/v1/jobs/:jobid/yarn-cancel.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@319854f0 under GET@/jobs/:jobid/yarn-cancel.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4912d525 under GET@/v1/jobs/:jobid/yarn-stop.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4912d525 under GET@/jobs/:jobid/yarn-stop.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@2bfbffb2 under GET@/v1/overview.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@2bfbffb2 under GET@/overview.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@765df79d under POST@/v1/savepoint-disposal.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@765df79d under POST@/savepoint-disposal.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@151335cb under GET@/v1/savepoint-disposal/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@151335cb under GET@/savepoint-disposal/:triggerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@4a7761b1 under GET@/v1/taskmanagers.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@4a7761b1 under GET@/taskmanagers.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@3e850122 under GET@/v1/taskmanagers/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@3e850122 under GET@/taskmanagers/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@27fde870 under GET@/v1/taskmanagers/:taskmanagerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@27fde870 under GET@/taskmanagers/:taskmanagerid.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@2b4c3c29 under GET@/v1/taskmanagers/:taskmanagerid/log.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@2b4c3c29 under GET@/taskmanagers/:taskmanagerid/log.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@5ac7aa18 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@5ac7aa18 under GET@/taskmanagers/:taskmanagerid/metrics.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@4cdd2c73 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2020-04-23 18:59:44 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@4cdd2c73 under GET@/taskmanagers/:taskmanagerid/stdout.
2020-04-23 18:59:44 [DEBUG](MultithreadEventLoopGroup     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.eventLoopThreads: 16
2020-04-23 18:59:44 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noKeySetOptimization: false
2020-04-23 18:59:44 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.selectorAutoRebuildThreshold: 512
2020-04-23 18:59:44 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] org.jctools-core.MpscChunkedArrayQueue: available
2020-04-23 18:59:44 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.processId: 1008 (auto-detected)
2020-04-23 18:59:44 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv4Stack: false
2020-04-23 18:59:44 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv6Addresses: false
2020-04-23 18:59:45 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2020-04-23 18:59:45 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2020-04-23 18:59:46 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.machineId: 7c:b0:c2:ff:fe:e9:fe:6c (auto-detected)
2020-04-23 18:59:46 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2020-04-23 18:59:46 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numHeapArenas: 16
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numDirectArenas: 16
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.pageSize: 8192
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxOrder: 11
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.chunkSize: 16777216
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.tinyCacheSize: 512
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.smallCacheSize: 256
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.normalCacheSize: 64
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimInterval: 8192
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.useCacheForAllThreads: true
2020-04-23 18:59:46 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2020-04-23 18:59:46 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.type: pooled
2020-04-23 18:59:46 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalDirectBufferSize: 0
2020-04-23 18:59:46 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxThreadLocalCharBufferSize: 16384
2020-04-23 18:59:46 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Binding rest endpoint to null:0.
2020-04-23 18:59:46 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Rest endpoint listening at localhost:56468
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender http://localhost:56468
2020-04-23 18:59:46 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] http://localhost:56468 was granted leadership with leaderSessionID=fdd17114-634f-4007-ac7e-143c6a6e4089
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader http://localhost:56468 , session=fdd17114-634f-4007-ac7e-143c6a6e4089
2020-04-23 18:59:46 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-04-23 18:59:46 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher.
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2020-04-23 18:59:46 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting ResourceManager.
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: StandaloneResourceManager
2020-04-23 18:59:46 [DEBUG](DefaultDispatcherRunner       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create new DispatcherLeaderProcess with leader session id 444cdc37-4c78-4bad-91a8-1b7ca47e43b4.
2020-04-23 18:59:46 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b94609b118ed6547425b0c674c9c4ebe
2020-04-23 18:59:46 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Flink Mini Cluster started successfully
2020-04-23 18:59:46 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start SessionDispatcherLeaderProcess.
2020-04-23 18:59:46 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the SlotManager.
2020-04-23 18:59:46 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Recover all persisted job graphs.
2020-04-23 18:59:46 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully recovered 0 persisted job graphs.
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=425b0c67-4c9c-4ebe-b946-09b118ed6547
2020-04-23 18:59:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 18:59:46 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(b94609b118ed6547425b0c674c9c4ebe).
2020-04-23 18:59:46 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 18:59:46 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 18:59:46 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 18:59:46 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=444cdc37-4c78-4bad-91a8-1b7ca47e43b4
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 18:59:46 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 18:59:46 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager with ResourceID b370fe99-e079-4822-a0ee-66aefd15310b (akka://flink/user/taskmanager_0) at ResourceManager
2020-04-23 18:59:46 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at resource manager akka://flink/user/resourcemanager under registration id 01cccd0a8515cdcf17b605867d5a4617.
2020-04-23 18:59:47 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received JobGraph submission 05a741b535c25ce2c2dfbf46b67fa073 (Item History Task).
2020-04-23 18:59:47 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager b370fe99-e079-4822-a0ee-66aefd15310b under 01cccd0a8515cdcf17b605867d5a4617 at the SlotManager.
2020-04-23 18:59:47 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Submitting job 05a741b535c25ce2c2dfbf46b67fa073 (Item History Task).
2020-04-23 18:59:47 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing job Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using restart back off time strategy NoRestartBackoffTimeStrategy for Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Running initialization on master for job Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully ran initialization on master in 0 ms.
2020-04-23 18:59:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding 1 vertices from job graph Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attaching 1 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2020-04-23 18:59:47 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: Custom Source -> Map) to 0 predecessors.
2020-04-23 18:59:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully created execution graph from job graph Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Status of the shared state registry of job 05a741b535c25ce2c2dfbf46b67fa073 after restore: SharedStateRegistry{registeredStates={}}.
2020-04-23 18:59:47 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resetting the master hooks.
2020-04-23 18:59:47 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start building failover regions.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 18:59:47 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created 8 failover regions.
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy@71308c93 for Item History Task (05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 18:59:47 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender akka://flink/user/jobmanager_1
2020-04-23 18:59:47 [INFO ](JobManagerRunnerImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager runner for job Item History Task (05a741b535c25ce2c2dfbf46b67fa073) was granted leadership with session id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280 at akka://flink/user/jobmanager_1.
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting execution of job Item History Task (05a741b535c25ce2c2dfbf46b67fa073) under job master id 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Item History Task (05a741b535c25ce2c2dfbf46b67fa073) switched from state CREATED to RUNNING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from CREATED to SCHEDULED.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{95b247e003273f1c87b8d7b16d6d8d35} for execution cbc357ccb763df2852fee8c4fc7d55f2_0
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{95b247e003273f1c87b8d7b16d6d8d35}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{76ce7f89d5684c29c1bb862b27e6e330}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{eb8a6743fc16040ccda822e395fae106}] in slot [SlotRequestId{76ce7f89d5684c29c1bb862b27e6e330}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{95b247e003273f1c87b8d7b16d6d8d35}] in multi task slot [SlotRequestId{eb8a6743fc16040ccda822e395fae106}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{821b582b8bc4202dfc64f4580c0a21e3} for execution cbc357ccb763df2852fee8c4fc7d55f2_1
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{821b582b8bc4202dfc64f4580c0a21e3}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{be1a8793e0597400aa7f734a0bc7600f}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{8383b1be5d9aba76eecbfd3044ac4184}] in slot [SlotRequestId{be1a8793e0597400aa7f734a0bc7600f}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{821b582b8bc4202dfc64f4580c0a21e3}] in multi task slot [SlotRequestId{8383b1be5d9aba76eecbfd3044ac4184}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{28ad2ce6f69046b69b63c8cde915d9bf} for execution cbc357ccb763df2852fee8c4fc7d55f2_2
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{28ad2ce6f69046b69b63c8cde915d9bf}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d77fa885f2c98c0cd47b011fc5c6f4da}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{2dd41cd4e13cb12123c32a7c5edb7fda}] in slot [SlotRequestId{d77fa885f2c98c0cd47b011fc5c6f4da}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{28ad2ce6f69046b69b63c8cde915d9bf}] in multi task slot [SlotRequestId{2dd41cd4e13cb12123c32a7c5edb7fda}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{4642ae9029afa26c63ac35f82a19a246} for execution cbc357ccb763df2852fee8c4fc7d55f2_3
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{4642ae9029afa26c63ac35f82a19a246}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{56158afbca7b57e85618e707b8425cf8}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{f6bf002a105142074c416f6b36ccc236}] in slot [SlotRequestId{56158afbca7b57e85618e707b8425cf8}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{4642ae9029afa26c63ac35f82a19a246}] in multi task slot [SlotRequestId{f6bf002a105142074c416f6b36ccc236}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{a162557c33b611e62bc9654876941b04} for execution cbc357ccb763df2852fee8c4fc7d55f2_4
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{a162557c33b611e62bc9654876941b04}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3df32867f36450c1f5bc779373b28db3}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{5567517b5efc7aa8017784b4ec4719bd}] in slot [SlotRequestId{3df32867f36450c1f5bc779373b28db3}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{a162557c33b611e62bc9654876941b04}] in multi task slot [SlotRequestId{5567517b5efc7aa8017784b4ec4719bd}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{23b395a0e98f907385b9f76bb07efcd4} for execution cbc357ccb763df2852fee8c4fc7d55f2_5
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{23b395a0e98f907385b9f76bb07efcd4}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a30ba7a292ec54f217758def1b27d538}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{aa623df00066a96926b0ef5540911548}] in slot [SlotRequestId{a30ba7a292ec54f217758def1b27d538}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{23b395a0e98f907385b9f76bb07efcd4}] in multi task slot [SlotRequestId{aa623df00066a96926b0ef5540911548}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{55ae409eed53bd3a8833b3365ed89c5c} for execution cbc357ccb763df2852fee8c4fc7d55f2_6
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{55ae409eed53bd3a8833b3365ed89c5c}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{634653b397ed04e4fcf8bf91902788d1}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{bef441a113f72c2cc0ce20f09a219764}] in slot [SlotRequestId{634653b397ed04e4fcf8bf91902788d1}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{55ae409eed53bd3a8833b3365ed89c5c}] in multi task slot [SlotRequestId{bef441a113f72c2cc0ce20f09a219764}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{9d760a0f88a977983657c0cc771aa3c3} for execution cbc357ccb763df2852fee8c4fc7d55f2_7
2020-04-23 18:59:47 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{9d760a0f88a977983657c0cc771aa3c3}] for task: null
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{da3a98ded62549242a1c9e2b32cb1e61}]
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{8984696c6794bc30269c6c8f56758b89}] in slot [SlotRequestId{da3a98ded62549242a1c9e2b32cb1e61}].
2020-04-23 18:59:47 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{9d760a0f88a977983657c0cc771aa3c3}] in multi task slot [SlotRequestId{8984696c6794bc30269c6c8f56758b89}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 18:59:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:47 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=2f3de9cc-71f2-4c7d-9a1e-8323069e9280
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(b94609b118ed6547425b0c674c9c4ebe)
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 18:59:47 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 to job leader id monitoring.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering job manager 9a1e8323069e92802f3de9cc71f24c7d@akka://flink/user/jobmanager_1 for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader 2f3de9cc-71f2-4c7d-9a1e-8323069e9280@akka://flink/user/jobmanager_1.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered job manager 9a1e8323069e92802f3de9cc71f24c7d@akka://flink/user/jobmanager_1 for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager successfully registered at ResourceManager, leader id: b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{76ce7f89d5684c29c1bb862b27e6e330}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{be1a8793e0597400aa7f734a0bc7600f}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{d77fa885f2c98c0cd47b011fc5c6f4da}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{56158afbca7b57e85618e707b8425cf8}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{3df32867f36450c1f5bc779373b28db3}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{a30ba7a292ec54f217758def1b27d538}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{634653b397ed04e4fcf8bf91902788d1}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{da3a98ded62549242a1c9e2b32cb1e61}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 32fc9a10bd028cb75ae5bd1124fc5fb6 for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 006533f19a6cbdc6720315c99f88cd21.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 71c1aaf49bb6b32ade179b74dc58569a.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 3838da10f636b26bdc6a3152dc503b9b.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 9363ffcc6be5fef95228334e4e531199.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id 95f27efe50fa05a572972e60b2461e9d.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id b6c267da26204b5268ff3b3606794913.
2020-04-23 18:59:47 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 05a741b535c25ce2c2dfbf46b67fa073 with allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 32fc9a10bd028cb75ae5bd1124fc5fb6.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 006533f19a6cbdc6720315c99f88cd21 for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 006533f19a6cbdc6720315c99f88cd21.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 71c1aaf49bb6b32ade179b74dc58569a for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 71c1aaf49bb6b32ade179b74dc58569a.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 3838da10f636b26bdc6a3152dc503b9b for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 3838da10f636b26bdc6a3152dc503b9b.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at JobManager attempt 1 (timeout=100ms)
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 9363ffcc6be5fef95228334e4e531199 for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 9363ffcc6be5fef95228334e4e531199.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 95f27efe50fa05a572972e60b2461e9d for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 95f27efe50fa05a572972e60b2461e9d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request b6c267da26204b5268ff3b3606794913 for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for b6c267da26204b5268ff3b3606794913.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request f70a0d2dc6fe12eb690ddf0fa1fdb0e2 for job 05a741b535c25ce2c2dfbf46b67fa073 from resource manager with leader id b94609b118ed6547425b0c674c9c4ebe.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 05a741b535c25ce2c2dfbf46b67fa073 for job leader monitoring.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 18:59:47 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: akka://flink/user/jobmanager_1, leader id: 9a1e8323069e92802f3de9cc71f24c7d.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2f3de9cc-71f2-4c7d-9a1e-8323069e9280.
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register new TaskExecutor b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 18:59:47 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at JobManager attempt 1 (timeout=100ms)
2020-04-23 18:59:47 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at job manager akka://flink/user/jobmanager_1 for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Establish JobManager connection for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Offer reserved slots to the leader of job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{56158afbca7b57e85618e707b8425cf8}] with allocated slot [3838da10f636b26bdc6a3152dc503b9b].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{76ce7f89d5684c29c1bb862b27e6e330}] with allocated slot [32fc9a10bd028cb75ae5bd1124fc5fb6].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{d77fa885f2c98c0cd47b011fc5c6f4da}] with allocated slot [71c1aaf49bb6b32ade179b74dc58569a].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{634653b397ed04e4fcf8bf91902788d1}] with allocated slot [b6c267da26204b5268ff3b3606794913].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{be1a8793e0597400aa7f734a0bc7600f}] with allocated slot [006533f19a6cbdc6720315c99f88cd21].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{3df32867f36450c1f5bc779373b28db3}] with allocated slot [9363ffcc6be5fef95228334e4e531199].
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{a30ba7a292ec54f217758def1b27d538}] with allocated slot [95f27efe50fa05a572972e60b2461e9d].
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from SCHEDULED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1)
2020-04-23 18:59:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{da3a98ded62549242a1c9e2b32cb1e61}] with allocated slot [f70a0d2dc6fe12eb690ddf0fa1fdb0e2].
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6 for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_32fc9a10bd028cb75ae5bd1124fc5fb6], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (1/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) [DEPLOYING]
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 006533f19a6cbdc6720315c99f88cd21 for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_006533f19a6cbdc6720315c99f88cd21], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=1}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 1 under allocation id 006533f19a6cbdc6720315c99f88cd21.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task cf54fafc9399d0bba840fe85ad9b7ee0 at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (2/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) [DEPLOYING].
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 85446e96075abdf74403e0674dc5db20 at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 71c1aaf49bb6b32ade179b74dc58569a for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_71c1aaf49bb6b32ade179b74dc58569a], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=2}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 2 under allocation id 71c1aaf49bb6b32ade179b74dc58569a.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (3/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 5f3eb6adac58f67ebc22f6c20ce5451f at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 3838da10f636b26bdc6a3152dc503b9b for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_3838da10f636b26bdc6a3152dc503b9b], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=3}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 3 under allocation id 3838da10f636b26bdc6a3152dc503b9b.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (4/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 21df1873138a49ae09cae5ce4cb0f5ef at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 9363ffcc6be5fef95228334e4e531199 for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_9363ffcc6be5fef95228334e4e531199], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=4}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 4 under allocation id 9363ffcc6be5fef95228334e4e531199.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (5/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task d484a82161c74a5241a6e1efa3bc7e1f at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 95f27efe50fa05a572972e60b2461e9d for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_95f27efe50fa05a572972e60b2461e9d], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=5}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 5 under allocation id 95f27efe50fa05a572972e60b2461e9d.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (2/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (5/8).
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (1/8).
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (3/8).
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (4/8).
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (6/8).
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 7bf141c9e5ab52106e4c6018f1fbb84e at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id b6c267da26204b5268ff3b3606794913 for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) [DEPLOYING].
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (6/8).
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_b6c267da26204b5268ff3b3606794913], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=6}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 6 under allocation id b6c267da26204b5268ff3b3606794913.
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (7/8).
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2 for local state stores for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) [DEPLOYING].
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 5ad8ca58b0acc826d506e86b31fad100 at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_f70a0d2dc6fe12eb690ddf0fa1fdb0e2], jobID=05a741b535c25ce2c2dfbf46b67fa073, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=7}} for 05a741b535c25ce2c2dfbf46b67fa073 - cbc357ccb763df2852fee8c4fc7d55f2 - 7 under allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) [DEPLOYING].
2020-04-23 18:59:47 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (8/8).
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from CREATED to DEPLOYING.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 3838da10f636b26bdc6a3152dc503b9b.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (7/8).
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 32fc9a10bd028cb75ae5bd1124fc5fb6.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) [DEPLOYING]
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 71c1aaf49bb6b32ade179b74dc58569a.
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot b6c267da26204b5268ff3b3606794913.
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) [DEPLOYING].
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 006533f19a6cbdc6720315c99f88cd21.
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 9363ffcc6be5fef95228334e4e531199.
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 95f27efe50fa05a572972e60b2461e9d.
2020-04-23 18:59:47 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
2020-04-23 18:59:47 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 6d34fcd396e69f559abbef220cee77b4 at library cache manager took 0 milliseconds
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) [DEPLOYING].
2020-04-23 18:59:47 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (8/8).
2020-04-23 18:59:47 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 18:59:47 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from DEPLOYING to RUNNING.
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (2/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (7/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (1/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (5/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (8/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (4/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (6/8)
2020-04-23 18:59:47 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (3/8)
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(5/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(4/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(6/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(1/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(8/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(2/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(7/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(3/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(2/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(3/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(4/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(8/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(5/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(6/8) with empty state.
2020-04-23 18:59:47 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(7/8) with empty state.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:47 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:47 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Kafka consumer initialized
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:47 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:47 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Topic metadata fetch included errors: {book=LEADER_NOT_AVAILABLE}
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 0 initially has no partitions to read from.
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 3 initially has no partitions to read from.
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 2 initially has no partitions to read from.
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 6 initially has no partitions to read from.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 1 initially has no partitions to read from.
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 7 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='book', partition=0}]
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 4 initially has no partitions to read from.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 5 initially has no partitions to read from.
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=history] Kafka consumer has been closed
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = history
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initializing the Kafka consumer
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 18:59:48 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Kafka consumer initialized
2020-04-23 18:59:48 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Subscribed to partition(s): book-0
2020-04-23 18:59:48 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending FindCoordinator request to broker aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed connection to node -1. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating API versions fetch from node -1.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending metadata request (type=MetadataRequest, topics=book) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 18:59:48 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 18:59:48 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [Partition(topic = book, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 18:59:48 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Received FindCoordinator response ClientResponse(receivedTimeMs=1587639588518, latencyMs=194, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-16, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=aliyun:9092 (id: 0 rack: null)))
2020-04-23 18:59:48 [INFO ](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Discovered group coordinator aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating connection to node aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Fetching committed offsets for partitions: [book-0]
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed connection to node 2147483647. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating API versions fetch from node 2147483647.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Recorded API versions for node 2147483647: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Found no committed offset for partition book-0
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={book-0=-1}, isolationLevel=READ_UNCOMMITTED) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 18:59:48 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 18:59:48 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed connection to node 0. Fetching API versions.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Initiating API versions fetch from node 0.
2020-04-23 18:59:48 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Handling ListOffsetResponse response for book-0. Fetched offset 0, timestamp -1
2020-04-23 18:59:48 [INFO ](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Resetting offset for partition book-0 to offset 0.
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
2020-04-23 18:59:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED FullFetchRequest(book-0) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent a full fetch response that created a new incremental fetch session 592814464 with 1 response partition(s)
2020-04-23 18:59:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2020-04-23 18:59:49 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.bytes-fetched
2020-04-23 18:59:49 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.records-fetched
2020-04-23 18:59:49 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lag
2020-04-23 18:59:49 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lead
2020-04-23 18:59:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=1) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=2) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=3) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=4) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=5) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=6) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=7) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:53 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 18:59:53 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:53 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:53 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=8) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:53 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:53 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 18:59:53 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 18:59:53 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:53 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:53 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=9) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:53 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:54 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:54 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:54 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=10) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:54 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:55 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:55 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:55 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=11) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:55 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:55 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:55 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:55 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=12) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:55 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:56 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:56 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:56 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=13) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:56 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:56 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:56 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:56 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=14) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:56 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:56 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:56 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:56 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 18:59:56 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 18:59:56 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 18:59:56 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 18:59:56 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 18:59:57 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 18:59:57 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 18:59:57 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:57 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:57 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=15) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:57 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:57 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 18:59:57 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:57 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:57 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=16) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:57 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:58 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 18:59:58 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 18:59:58 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 18:59:58 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:58 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:58 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=17) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:58 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:58 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:58 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:58 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=18) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:58 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:59 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 18:59:59 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:59 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=19) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 18:59:59 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 18:59:59 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.util.Properties
2020-04-23 18:59:59 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Long
2020-04-23 19:00:00 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class com.example.graduationproject.domain.UserBehavior is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:00 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=2, name='Map', outputType=GenericType<com.example.graduationproject.domain.UserBehavior>, parallelism=8}
2020-04-23 19:00:00 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming SourceTransformation{id=1, name='Custom Source', outputType=String, parallelism=8}
2020-04-23 19:00:00 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 1
2020-04-23 19:00:00 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 2
2020-04-23 19:00:00 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: Custom Source-1' {id: 1, parallelism: 8, user function: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer}
2020-04-23 19:00:00 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash '7df19f87deec5680128845fd9a6ca18d' for node 'Map-2' {id: 2, parallelism: 8, user function: com.example.graduationproject.map.LogMapFunction}
2020-04-23 19:00:00 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:00 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:00 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=20) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:00 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:00 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parallelism set: 8 for 1
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 19:00:00 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
2020-04-23 19:00:00 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Flink Mini Cluster
2020-04-23 19:00:00 [DEBUG](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, jobmanager.scheduler=ng, taskmanager.memory.managed.size=128 mb, taskmanager.numberOfTaskSlots=8, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2020-04-23 19:00:00 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Metrics Registry
2020-04-23 19:00:00 [INFO ](MetricRegistryImpl            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No metrics reporter configured, no metrics will be exposed/reported.
2020-04-23 19:00:00 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC Service(s)
2020-04-23 19:00:00 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:00 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:00 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=21) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:00 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:01 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:01 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:01 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=22) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:01 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:01 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 19:00:01 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 19:00:01 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 19:00:01 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to start actor system at :0
2020-04-23 19:00:01 [DEBUG](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy","provider":"akka.remote.RemoteActorRefProvider","warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","remote":{"log-remote-lifecycle-events":"off","netty":{"tcp":{"bind-hostname":"0.0.0.0","bind-port":0,"client-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"connection-timeout":"20000ms","hostname":"","maximum-frame-size":"10485760b","port":0,"server-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"tcp-nodelay":"on","transport-class":"akka.remote.transport.netty.NettyTransport"}},"retry-gate-closed-for":"50 ms","startup-timeout":"100000ms","transport-failure-detector":{"acceptable-heartbeat-pause":"6000000ms","heartbeat-interval":"1000000ms","threshold":300}},"serialize-messages":"off","stdout-loglevel":"OFF"}}))
2020-04-23 19:00:01 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 19:00:01 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:01 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:01 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=23) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:01 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:01 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 19:00:01 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 19:00:01 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting remoting
2020-04-23 19:00:01 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using select timeout of 500
2020-04-23 19:00:01 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Epoll-bug workaround enabled = false
2020-04-23 19:00:02 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:02 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:02 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=24) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:02 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:02 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:02 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:02 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=25) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:02 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:03 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.65.1:56545]
2020-04-23 19:00:03 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:03 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Actor system started at akka.tcp://flink-metrics@192.168.65.1:56545
2020-04-23 19:00:03 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-04-23 19:00:03 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:03 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:03 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting high-availability services
2020-04-23 19:00:03 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB server storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-4c74caf7-7f70-488a-980a-dee98c33a9ae
2020-04-23 19:00:03 [DEBUG](NetUtils                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to open socket on port 0
2020-04-23 19:00:03 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Started BLOB server at 0.0.0.0:56546 - max concurrent requests: 50 - max backlog: 1000
2020-04-23 19:00:03 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-b1364f71-0035-4703-88cf-dae9e3cb4caf
2020-04-23 19:00:03 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-f2dd7a9d-2581-4bec-b5a6-f962c69869af
2020-04-23 19:00:03 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting 1 TaskManger(s)
2020-04-23 19:00:03 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:03 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:03 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=26) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:03 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:03 [INFO ](TaskManagerRunner             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting TaskManager with ResourceID: aecf994c-886e-4ef7-ac4b-f2532302002d
2020-04-23 19:00:03 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 19:00:03 [INFO ](TaskManagerServices           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Temporary file directory 'C:\Users\Zzwen\AppData\Local\Temp': total 237 GB, usable 69 GB (29.11% usable)
2020-04-23 19:00:03 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-bb06c901-c69a-4533-a04a-7c5cf8194f82 for spill files.
2020-04-23 19:00:03 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-88deca4b-e956-4309-8d93-1f4af1ab01c2 for spill files.
2020-04-23 19:00:03 [INFO ](NetworkBufferPool             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2020-04-23 19:00:03 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the network environment and its components.
2020-04-23 19:00:03 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting network connection manager
2020-04-23 19:00:03 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the kvState service and its components.
2020-04-23 19:00:03 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 19:00:03 [INFO ](TaskManagerConfiguration      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Messages have a max timeout of 10000 ms
2020-04-23 19:00:03 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-04-23 19:00:03 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start job leader service.
2020-04-23 19:00:03 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] User file cache uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-2e3e598e-293f-4365-b11d-61fd3ae8b2f6
2020-04-23 19:00:03 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher REST endpoint.
2020-04-23 19:00:03 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting rest endpoint.
2020-04-23 19:00:03 [DEBUG](InternalLoggerFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using SLF4J as the default logging framework
2020-04-23 19:00:03 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2020-04-23 19:00:03 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2020-04-23 19:00:03 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Log file environment variable 'log.file' is not set.
2020-04-23 19:00:03 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:192)
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:98)
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:141)
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:165)
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:394)
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:360)
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:314)
	at org.apache.flink.client.deployment.executors.LocalExecutor.startMiniCluster(LocalExecutor.java:117)
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:63)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1733)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1634)
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:74)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)
	at com.example.graduationproject.task.LogTask.main(LogTask.java:28)
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Platform: Windows
2020-04-23 19:00:04 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:04 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:04 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=27) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:04 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noUnsafe: false
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Java version: 8
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.theUnsafe: available
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.copyMemory: available
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Buffer.address: available
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] direct buffer constructor: available
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Bits.unaligned: available, true
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2020-04-23 19:00:04 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.DirectByteBuffer.<init>(long, int): available
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe: available
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.tmpdir: C:\Users\Zzwen\AppData\Local\Temp (java.io.tmpdir)
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.bitMode: 64 (sun.arch.data.model)
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxDirectMemory: 3810525184 bytes
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.uninitializedArrayAllocationThreshold: -1
2020-04-23 19:00:04 [DEBUG](CleanerJava6                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.ByteBuffer.cleaner(): available
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noPreferDirect: false
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@29f0c4f2 under DELETE@/v1/cluster.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@29f0c4f2 under DELETE@/cluster.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@65bb9029 under GET@/v1/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@65bb9029 under GET@/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@1bfe3203 under GET@/v1/jobmanager/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@1bfe3203 under GET@/jobmanager/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@2b214b94 under GET@/v1/jobmanager/log.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@2b214b94 under GET@/jobmanager/log.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@70e3f36f under GET@/v1/jobmanager/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@70e3f36f under GET@/jobmanager/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@49601f82 under GET@/v1/jobmanager/stdout.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@49601f82 under GET@/jobmanager/stdout.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@23e44287 under GET@/v1/jobs.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@23e44287 under GET@/jobs.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@2b8d084 under POST@/v1/jobs.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@2b8d084 under POST@/jobs.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@6daf2337 under GET@/v1/jobs/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@6daf2337 under GET@/jobs/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@24fabd0f under GET@/v1/jobs/overview.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@24fabd0f under GET@/jobs/overview.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@250b236d under GET@/v1/jobs/:jobid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@250b236d under GET@/jobs/:jobid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@61f3fbb8 under PATCH@/v1/jobs/:jobid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@61f3fbb8 under PATCH@/jobs/:jobid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@7551da2a under GET@/v1/jobs/:jobid/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@7551da2a under GET@/jobs/:jobid/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@432034a under GET@/v1/jobs/:jobid/checkpoints.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@432034a under GET@/jobs/:jobid/checkpoints.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@78de58ea under GET@/v1/jobs/:jobid/checkpoints/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@78de58ea under GET@/jobs/:jobid/checkpoints/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@60e5272 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@60e5272 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@7d755813 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@7d755813 under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@69c93ca4 under GET@/v1/jobs/:jobid/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@69c93ca4 under GET@/jobs/:jobid/config.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@63da207f under GET@/v1/jobs/:jobid/exceptions.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@63da207f under GET@/jobs/:jobid/exceptions.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@173373b4 under GET@/v1/jobs/:jobid/execution-result.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@173373b4 under GET@/jobs/:jobid/execution-result.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@40d10481 under GET@/v1/jobs/:jobid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@40d10481 under GET@/jobs/:jobid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@60dd3c23 under GET@/v1/jobs/:jobid/plan.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@60dd3c23 under GET@/jobs/:jobid/plan.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@52b6319f under PATCH@/v1/jobs/:jobid/rescaling.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@52b6319f under PATCH@/jobs/:jobid/rescaling.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@5e9456ae under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@5e9456ae under GET@/jobs/:jobid/rescaling/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@16a9a4f1 under POST@/v1/jobs/:jobid/savepoints.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@16a9a4f1 under POST@/jobs/:jobid/savepoints.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@1f1cae23 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@1f1cae23 under GET@/jobs/:jobid/savepoints/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@7c455e96 under POST@/v1/jobs/:jobid/stop.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@7c455e96 under POST@/jobs/:jobid/stop.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@985696 under GET@/v1/jobs/:jobid/vertices/:vertexid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@985696 under GET@/jobs/:jobid/vertices/:vertexid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@5bcde458 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@5bcde458 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@215a34b4 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@215a34b4 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@77bd7fe7 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@77bd7fe7 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@35d3ab60 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@35d3ab60 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@10876a6 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@10876a6 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@71870da7 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@71870da7 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6dd91637 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@6dd91637 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@45792847 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@45792847 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@706cb08 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@706cb08 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@4e25147a under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@4e25147a under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@6b68cb27 under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@6b68cb27 under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@675ffd1d under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@675ffd1d under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@61f3fbb8 under GET@/v1/jobs/:jobid/yarn-cancel.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@61f3fbb8 under GET@/jobs/:jobid/yarn-cancel.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@56303475 under GET@/v1/jobs/:jobid/yarn-stop.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@56303475 under GET@/jobs/:jobid/yarn-stop.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@30506c0d under GET@/v1/overview.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@30506c0d under GET@/overview.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@1dcca8d3 under POST@/v1/savepoint-disposal.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@1dcca8d3 under POST@/savepoint-disposal.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@5631962 under GET@/v1/savepoint-disposal/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@5631962 under GET@/savepoint-disposal/:triggerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@52a70627 under GET@/v1/taskmanagers.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@52a70627 under GET@/taskmanagers.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@6124287a under GET@/v1/taskmanagers/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@6124287a under GET@/taskmanagers/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@19569ebd under GET@/v1/taskmanagers/:taskmanagerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@19569ebd under GET@/taskmanagers/:taskmanagerid.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@4632cfc under GET@/v1/taskmanagers/:taskmanagerid/log.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@4632cfc under GET@/taskmanagers/:taskmanagerid/log.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@6e1f8469 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@6e1f8469 under GET@/taskmanagers/:taskmanagerid/metrics.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@2e380628 under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2020-04-23 19:00:04 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@2e380628 under GET@/taskmanagers/:taskmanagerid/stdout.
2020-04-23 19:00:04 [DEBUG](MultithreadEventLoopGroup     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.eventLoopThreads: 16
2020-04-23 19:00:04 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noKeySetOptimization: false
2020-04-23 19:00:04 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.selectorAutoRebuildThreshold: 512
2020-04-23 19:00:04 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] org.jctools-core.MpscChunkedArrayQueue: available
2020-04-23 19:00:04 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.processId: 5952 (auto-detected)
2020-04-23 19:00:04 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv4Stack: false
2020-04-23 19:00:04 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv6Addresses: false
2020-04-23 19:00:04 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:04 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:04 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=28) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:04 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:05 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:05 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:05 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=29) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:05 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:05 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2020-04-23 19:00:05 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2020-04-23 19:00:05 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:05 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:05 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=30) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:05 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:06 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:06 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:06 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=31) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:06 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:06 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.machineId: 7c:b0:c2:ff:fe:e9:fe:6c (auto-detected)
2020-04-23 19:00:06 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2020-04-23 19:00:06 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numHeapArenas: 16
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numDirectArenas: 16
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.pageSize: 8192
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxOrder: 11
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.chunkSize: 16777216
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.tinyCacheSize: 512
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.smallCacheSize: 256
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.normalCacheSize: 64
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimInterval: 8192
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.useCacheForAllThreads: true
2020-04-23 19:00:06 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2020-04-23 19:00:06 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.type: pooled
2020-04-23 19:00:06 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalDirectBufferSize: 0
2020-04-23 19:00:06 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxThreadLocalCharBufferSize: 16384
2020-04-23 19:00:06 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Binding rest endpoint to null:0.
2020-04-23 19:00:06 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Rest endpoint listening at localhost:56583
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender http://localhost:56583
2020-04-23 19:00:06 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] http://localhost:56583 was granted leadership with leaderSessionID=60eb93fc-024c-42e7-8d78-66ee9c593ad3
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader http://localhost:56583 , session=60eb93fc-024c-42e7-8d78-66ee9c593ad3
2020-04-23 19:00:06 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-04-23 19:00:06 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher.
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2020-04-23 19:00:06 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting ResourceManager.
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: StandaloneResourceManager
2020-04-23 19:00:06 [DEBUG](DefaultDispatcherRunner       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create new DispatcherLeaderProcess with leader session id 85bb6fe8-81de-4ae9-8ec3-2ec9edac8352.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9c6e4dd595d2f20ddb87399311104d47
2020-04-23 19:00:06 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Flink Mini Cluster started successfully
2020-04-23 19:00:06 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the SlotManager.
2020-04-23 19:00:06 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start SessionDispatcherLeaderProcess.
2020-04-23 19:00:06 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Recover all persisted job graphs.
2020-04-23 19:00:06 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully recovered 0 persisted job graphs.
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=db873993-1110-4d47-9c6e-4dd595d2f20d
2020-04-23 19:00:06 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:06 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(9c6e4dd595d2f20ddb87399311104d47).
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:06 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=85bb6fe8-81de-4ae9-8ec3-2ec9edac8352
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager with ResourceID aecf994c-886e-4ef7-ac4b-f2532302002d (akka://flink/user/taskmanager_0) at ResourceManager
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at resource manager akka://flink/user/resourcemanager under registration id fa41931cb237a0d8f807e13392a773d1.
2020-04-23 19:00:06 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager aecf994c-886e-4ef7-ac4b-f2532302002d under fa41931cb237a0d8f807e13392a773d1 at the SlotManager.
2020-04-23 19:00:06 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received JobGraph submission 77d397c647a53cd8ed694029397cec7d (Log message receive).
2020-04-23 19:00:06 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Submitting job 77d397c647a53cd8ed694029397cec7d (Log message receive).
2020-04-23 19:00:06 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing job Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using restart back off time strategy NoRestartBackoffTimeStrategy for Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Running initialization on master for job Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully ran initialization on master in 0 ms.
2020-04-23 19:00:06 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding 1 vertices from job graph Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attaching 1 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2020-04-23 19:00:06 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: Custom Source -> Map) to 0 predecessors.
2020-04-23 19:00:06 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully created execution graph from job graph Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Status of the shared state registry of job 77d397c647a53cd8ed694029397cec7d after restore: SharedStateRegistry{registeredStates={}}.
2020-04-23 19:00:06 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resetting the master hooks.
2020-04-23 19:00:06 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start building failover regions.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 1 vertices.
2020-04-23 19:00:06 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created 8 failover regions.
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy@35b81da5 for Log message receive (77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender akka://flink/user/jobmanager_1
2020-04-23 19:00:06 [INFO ](JobManagerRunnerImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager runner for job Log message receive (77d397c647a53cd8ed694029397cec7d) was granted leadership with session id 00d2e1a5-9330-46e3-8f23-8c0789f5be67 at akka://flink/user/jobmanager_1.
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting execution of job Log message receive (77d397c647a53cd8ed694029397cec7d) under job master id 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Log message receive (77d397c647a53cd8ed694029397cec7d) switched from state CREATED to RUNNING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from CREATED to SCHEDULED.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{dccefb61405b9a535b2daeb44ef47013} for execution cbc357ccb763df2852fee8c4fc7d55f2_0
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{dccefb61405b9a535b2daeb44ef47013}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a3cf5499568b1ef0d1507fac81539b9a}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{d8a260875a58543bc68841da712dc084}] in slot [SlotRequestId{a3cf5499568b1ef0d1507fac81539b9a}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{dccefb61405b9a535b2daeb44ef47013}] in multi task slot [SlotRequestId{d8a260875a58543bc68841da712dc084}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{1004c283932523f90fe70e226580f9f0} for execution cbc357ccb763df2852fee8c4fc7d55f2_1
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{1004c283932523f90fe70e226580f9f0}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b0c9292b64d962181d91f3a0fb15f594}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{f37f5dd307a4ffe0fe617ccadca6fc18}] in slot [SlotRequestId{b0c9292b64d962181d91f3a0fb15f594}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{1004c283932523f90fe70e226580f9f0}] in multi task slot [SlotRequestId{f37f5dd307a4ffe0fe617ccadca6fc18}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{e1fe4858c5d5be67cd22e2d6f3feaaa1} for execution cbc357ccb763df2852fee8c4fc7d55f2_2
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{e1fe4858c5d5be67cd22e2d6f3feaaa1}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{48a3eb21fc31144a752e9359c55031ab}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{a6ca9b5ea31a3a99d02eec3097d42d1b}] in slot [SlotRequestId{48a3eb21fc31144a752e9359c55031ab}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{e1fe4858c5d5be67cd22e2d6f3feaaa1}] in multi task slot [SlotRequestId{a6ca9b5ea31a3a99d02eec3097d42d1b}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{ee22f9922ed79513a73c51a3cbd26994} for execution cbc357ccb763df2852fee8c4fc7d55f2_3
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{ee22f9922ed79513a73c51a3cbd26994}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ad966e514ac9e992bc2202c727f22b08}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{844e2f4a399b1ac8eef15022b32fc892}] in slot [SlotRequestId{ad966e514ac9e992bc2202c727f22b08}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{ee22f9922ed79513a73c51a3cbd26994}] in multi task slot [SlotRequestId{844e2f4a399b1ac8eef15022b32fc892}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{18b7108752915a2bfe3f1895a76fb183} for execution cbc357ccb763df2852fee8c4fc7d55f2_4
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{18b7108752915a2bfe3f1895a76fb183}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7e1aa5f1358f052e8fc1b07747942fba}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{e5ea791a6316a1b1d1c396fc9c7c7b39}] in slot [SlotRequestId{7e1aa5f1358f052e8fc1b07747942fba}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{18b7108752915a2bfe3f1895a76fb183}] in multi task slot [SlotRequestId{e5ea791a6316a1b1d1c396fc9c7c7b39}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{a86257361f2dadb96e419ddfd3a8f2f3} for execution cbc357ccb763df2852fee8c4fc7d55f2_5
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{a86257361f2dadb96e419ddfd3a8f2f3}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{56f2fb6a0c703663ecd1673fc9a98eea}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{6a3699491b526a155ad75dc61f38df79}] in slot [SlotRequestId{56f2fb6a0c703663ecd1673fc9a98eea}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{a86257361f2dadb96e419ddfd3a8f2f3}] in multi task slot [SlotRequestId{6a3699491b526a155ad75dc61f38df79}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{b9450b9a0fac99f7e0618b0893372dee} for execution cbc357ccb763df2852fee8c4fc7d55f2_6
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{b9450b9a0fac99f7e0618b0893372dee}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c955ab5f7f815ea12d6ef03192de925b}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{f6f9131240b4d415adc144e26dc212ad}] in slot [SlotRequestId{c955ab5f7f815ea12d6ef03192de925b}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{b9450b9a0fac99f7e0618b0893372dee}] in multi task slot [SlotRequestId{f6f9131240b4d415adc144e26dc212ad}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{ce1552316b6720ef9ad1405219b71efd} for execution cbc357ccb763df2852fee8c4fc7d55f2_7
2020-04-23 19:00:06 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{ce1552316b6720ef9ad1405219b71efd}] for task: null
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{af7354fc8313bcdb225bd0bb44e9ff26}]
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{3a54847cd4ba2a465e80e4f8bf530597}] in slot [SlotRequestId{af7354fc8313bcdb225bd0bb44e9ff26}].
2020-04-23 19:00:06 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{ce1552316b6720ef9ad1405219b71efd}] in multi task slot [SlotRequestId{3a54847cd4ba2a465e80e4f8bf530597}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:06 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:06 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=00d2e1a5-9330-46e3-8f23-8c0789f5be67
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(9c6e4dd595d2f20ddb87399311104d47)
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 19:00:06 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d to job leader id monitoring.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering job manager 8f238c0789f5be6700d2e1a5933046e3@akka://flink/user/jobmanager_1 for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader 00d2e1a5-9330-46e3-8f23-8c0789f5be67@akka://flink/user/jobmanager_1.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered job manager 8f238c0789f5be6700d2e1a5933046e3@akka://flink/user/jobmanager_1 for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager successfully registered at ResourceManager, leader id: 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{a3cf5499568b1ef0d1507fac81539b9a}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id 3273e2c96b6c175720d2ac6a41cb9b69.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{b0c9292b64d962181d91f3a0fb15f594}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{48a3eb21fc31144a752e9359c55031ab}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{ad966e514ac9e992bc2202c727f22b08}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{7e1aa5f1358f052e8fc1b07747942fba}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{56f2fb6a0c703663ecd1673fc9a98eea}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{c955ab5f7f815ea12d6ef03192de925b}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{af7354fc8313bcdb225bd0bb44e9ff26}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 3273e2c96b6c175720d2ac6a41cb9b69 for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id a746278421e81a200e3e711bd55f79b3.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id 9c80a0a8bea77c101ca67025ba67a41d.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id 0626db8ad338c8acae965455a1c1f8b3.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id 7fdb5a165f28137eb3f2370c5c5168fb.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id 302fd85a4551294dea1a4b6533203048.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id f975e64a3787208d80fb979ad63e9b50.
2020-04-23 19:00:06 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job 77d397c647a53cd8ed694029397cec7d with allocation id aa58d9c04b3ffd199f2860a9ff0e34fc.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 3273e2c96b6c175720d2ac6a41cb9b69.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request a746278421e81a200e3e711bd55f79b3 for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for a746278421e81a200e3e711bd55f79b3.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 9c80a0a8bea77c101ca67025ba67a41d for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 9c80a0a8bea77c101ca67025ba67a41d.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 0626db8ad338c8acae965455a1c1f8b3 for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 0626db8ad338c8acae965455a1c1f8b3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 7fdb5a165f28137eb3f2370c5c5168fb for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 7fdb5a165f28137eb3f2370c5c5168fb.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 302fd85a4551294dea1a4b6533203048 for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 302fd85a4551294dea1a4b6533203048.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request f975e64a3787208d80fb979ad63e9b50 for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for f975e64a3787208d80fb979ad63e9b50.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request aa58d9c04b3ffd199f2860a9ff0e34fc for job 77d397c647a53cd8ed694029397cec7d from resource manager with leader id 9c6e4dd595d2f20ddb87399311104d47.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 16777216 ({OFF_HEAP=16777216}), page size 32768.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for aa58d9c04b3ffd199f2860a9ff0e34fc.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job 77d397c647a53cd8ed694029397cec7d for job leader monitoring.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: akka://flink/user/jobmanager_1, leader id: 8f238c0789f5be6700d2e1a5933046e3.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 00d2e1a5-9330-46e3-8f23-8c0789f5be67.
2020-04-23 19:00:06 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Retrying registration towards akka://flink/user/jobmanager_1 was cancelled.
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at JobManager attempt 1 (timeout=100ms)
2020-04-23 19:00:06 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register new TaskExecutor aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:06 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at job manager akka://flink/user/jobmanager_1 for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Establish JobManager connection for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Offer reserved slots to the leader of job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{b0c9292b64d962181d91f3a0fb15f594}] with allocated slot [a746278421e81a200e3e711bd55f79b3].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{48a3eb21fc31144a752e9359c55031ab}] with allocated slot [9c80a0a8bea77c101ca67025ba67a41d].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{ad966e514ac9e992bc2202c727f22b08}] with allocated slot [0626db8ad338c8acae965455a1c1f8b3].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{c955ab5f7f815ea12d6ef03192de925b}] with allocated slot [f975e64a3787208d80fb979ad63e9b50].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{a3cf5499568b1ef0d1507fac81539b9a}] with allocated slot [3273e2c96b6c175720d2ac6a41cb9b69].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{af7354fc8313bcdb225bd0bb44e9ff26}] with allocated slot [aa58d9c04b3ffd199f2860a9ff0e34fc].
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{56f2fb6a0c703663ecd1673fc9a98eea}] with allocated slot [302fd85a4551294dea1a4b6533203048].
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to aecf994c-886e-4ef7-ac4b-f2532302002d @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:06 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{7e1aa5f1358f052e8fc1b07747942fba}] with allocated slot [7fdb5a165f28137eb3f2370c5c5168fb].
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 3273e2c96b6c175720d2ac6a41cb9b69 for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_3273e2c96b6c175720d2ac6a41cb9b69], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 3273e2c96b6c175720d2ac6a41cb9b69.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (1/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) [DEPLOYING]
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id a746278421e81a200e3e711bd55f79b3 for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 97ff9825aaa9bfe7e4770641ac5a65ea at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_a746278421e81a200e3e711bd55f79b3], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=1}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 1 under allocation id a746278421e81a200e3e711bd55f79b3.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) [DEPLOYING].
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (2/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task e11b3a9481cfbf8542683eda1b684d25 at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 9c80a0a8bea77c101ca67025ba67a41d for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_9c80a0a8bea77c101ca67025ba67a41d], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=2}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 2 under allocation id 9c80a0a8bea77c101ca67025ba67a41d.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (3/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task b6663df1c73f3748851416b98074a779 at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 0626db8ad338c8acae965455a1c1f8b3 for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_0626db8ad338c8acae965455a1c1f8b3], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=3}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 3 under allocation id 0626db8ad338c8acae965455a1c1f8b3.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (4/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task f8f5c4467240550c200b682746d8590b at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 7fdb5a165f28137eb3f2370c5c5168fb for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_7fdb5a165f28137eb3f2370c5c5168fb], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=4}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 4 under allocation id 7fdb5a165f28137eb3f2370c5c5168fb.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (5/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (1/8).
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (2/8).
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (4/8).
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (3/8).
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task a06777b6f6119c3401c7fb7a7d04a2f9 at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 302fd85a4551294dea1a4b6533203048 for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_302fd85a4551294dea1a4b6533203048], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=5}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 5 under allocation id 302fd85a4551294dea1a4b6533203048.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) [DEPLOYING].
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (6/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (5/8).
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id f975e64a3787208d80fb979ad63e9b50 for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 1487880cbd096edeb628aa46a82071ae at library cache manager took 1 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_f975e64a3787208d80fb979ad63e9b50], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=6}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 6 under allocation id f975e64a3787208d80fb979ad63e9b50.
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (7/8).
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) [DEPLOYING].
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id aa58d9c04b3ffd199f2860a9ff0e34fc for local state stores for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (6/8).
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task a91a7c7188aa765787ea10c0b3fbbc76 at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_aa58d9c04b3ffd199f2860a9ff0e34fc], jobID=77d397c647a53cd8ed694029397cec7d, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=7}} for 77d397c647a53cd8ed694029397cec7d - cbc357ccb763df2852fee8c4fc7d55f2 - 7 under allocation id aa58d9c04b3ffd199f2860a9ff0e34fc.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) [DEPLOYING].
2020-04-23 19:00:06 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map (8/8).
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot a746278421e81a200e3e711bd55f79b3.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 9c80a0a8bea77c101ca67025ba67a41d.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 0626db8ad338c8acae965455a1c1f8b3.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot f975e64a3787208d80fb979ad63e9b50.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 3273e2c96b6c175720d2ac6a41cb9b69.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot aa58d9c04b3ffd199f2860a9ff0e34fc.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 302fd85a4551294dea1a4b6533203048.
2020-04-23 19:00:06 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 7fdb5a165f28137eb3f2370c5c5168fb.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from CREATED to DEPLOYING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) [DEPLOYING]
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) [DEPLOYING].
2020-04-23 19:00:06 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task e4cbdd7945b19ed17cae715d6c20ca54 at library cache manager took 0 milliseconds
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (7/8).
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) [DEPLOYING].
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map (8/8).
2020-04-23 19:00:06 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:06 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (8/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (1/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (3/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (2/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (6/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (4/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (5/8)
2020-04-23 19:00:06 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map (7/8)
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(6/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(4/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(1/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(8/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(2/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(5/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(3/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_7df19f87deec5680128845fd9a6ca18d_(7/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(8/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(3/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(2/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(7/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(6/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(5/8) with empty state.
2020-04-23 19:00:06 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(4/8) with empty state.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:06 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:06 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:06 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:06 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=32) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:06 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:06 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Kafka consumer initialized
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:06 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:06 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:07 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:07 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:07 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:07 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:07 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:07 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 6 initially has no partitions to read from.
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 4 initially has no partitions to read from.
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 0 initially has no partitions to read from.
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 7 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='book', partition=0}]
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 3 initially has no partitions to read from.
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 5 initially has no partitions to read from.
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 1 initially has no partitions to read from.
2020-04-23 19:00:07 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 2 initially has no partitions to read from.
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-3, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-7, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-5, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-4, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-8, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-6, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = log
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initializing the Kafka consumer
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:07 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Kafka consumer initialized
2020-04-23 19:00:07 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Subscribed to partition(s): book-0
2020-04-23 19:00:07 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending FindCoordinator request to broker aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating API versions fetch from node -1.
2020-04-23 19:00:07 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=33) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending metadata request (type=MetadataRequest, topics=book) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:07 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:07 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [Partition(topic = book, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:07 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Received FindCoordinator response ClientResponse(receivedTimeMs=1587639607491, latencyMs=176, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-16, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=aliyun:9092 (id: 0 rack: null)))
2020-04-23 19:00:07 [INFO ](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Discovered group coordinator aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating connection to node aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Fetching committed offsets for partitions: [book-0]
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed connection to node 2147483647. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating API versions fetch from node 2147483647.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Recorded API versions for node 2147483647: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Found no committed offset for partition book-0
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={book-0=-1}, isolationLevel=READ_UNCOMMITTED) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 19:00:07 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 19:00:07 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed connection to node 0. Fetching API versions.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Initiating API versions fetch from node 0.
2020-04-23 19:00:07 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Handling ListOffsetResponse response for book-0. Fetched offset 0, timestamp -1
2020-04-23 19:00:07 [INFO ](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Resetting offset for partition book-0 to offset 0.
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED FullFetchRequest(book-0) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:07 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=34) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:07 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:08 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:08 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:08 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:08 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent a full fetch response that created a new incremental fetch session 1179162920 with 1 response partition(s)
2020-04-23 19:00:08 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2020-04-23 19:00:08 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.bytes-fetched
2020-04-23 19:00:08 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.records-fetched
2020-04-23 19:00:08 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lag
2020-04-23 19:00:08 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lead
2020-04-23 19:00:08 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:08 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=1) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:08 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:08 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:08 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:08 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=35) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:08 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=2) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=36) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=3) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:09 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=37) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:09 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=4) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=38) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=5) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:10 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=39) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:10 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=6) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=40) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=7) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:11 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=41) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:11 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:12 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:12 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:12 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:12 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:12 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:12 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=8) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:12 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:12 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:12 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:12 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=42) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:12 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=9) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=43) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:13 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:13 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=44) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:13 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=10) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:13 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=45) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=11) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=46) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:14 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=12) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:14 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=47) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=13) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=48) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:15 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=14) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:15 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:16 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:16 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:16 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:16 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:16 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=49) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance fa41931cb237a0d8f807e13392a773d1: SlotReport{slotsStatus=[SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3273e2c96b6c175720d2ac6a41cb9b69, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=a746278421e81a200e3e711bd55f79b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9c80a0a8bea77c101ca67025ba67a41d, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=0626db8ad338c8acae965455a1c1f8b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=7fdb5a165f28137eb3f2370c5c5168fb, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=302fd85a4551294dea1a4b6533203048, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f975e64a3787208d80fb979ad63e9b50, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=aa58d9c04b3ffd199f2860a9ff0e34fc, jobID=77d397c647a53cd8ed694029397cec7d}]}.
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=15) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:16 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:16 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:16 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=50) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:16 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=16) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:17 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:17 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:17 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:17 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:17 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 19:00:17 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:17 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:17 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:17 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:17 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:17 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:17 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.util.Properties
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Long
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=51) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class com.example.graduationproject.domain.UserBehavior is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:17 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=17) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:17 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:17 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class com.example.graduationproject.domain.ItemViewCount is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:17 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class com.example.graduationproject.domain.ItemViewCount is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the org.apache.flink.api.common.functions.util.PrintSinkOutputWriter
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Boolean
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.String
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the [C
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the com.example.graduationproject.sink.TopNRedisSink
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the org.apache.flink.streaming.connectors.redis.common.mapper.RedisCommand
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the org.apache.flink.streaming.connectors.redis.common.mapper.RedisDataType
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the org.apache.flink.streaming.connectors.redis.common.config.FlinkJedisPoolConfig
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.String
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the [C
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.String
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the [C
2020-04-23 19:00:17 [DEBUG](ClosureCleaner                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Dig to clean the java.lang.Integer
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=2, name='Map', outputType=GenericType<com.example.graduationproject.domain.UserBehavior>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming SourceTransformation{id=1, name='Custom Source', outputType=String, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 1
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 2
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=3, name='Timestamps/Watermarks', outputType=GenericType<com.example.graduationproject.domain.UserBehavior>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 3
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=5, name='Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)', outputType=GenericType<com.example.graduationproject.domain.ItemViewCount>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming PartitionTransformation{id=4, name='Partition', outputType=GenericType<com.example.graduationproject.domain.UserBehavior>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 5
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming OneInputTransformation{id=7, name='KeyedProcess', outputType=GenericType<com.example.graduationproject.domain.ItemViewCount>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming PartitionTransformation{id=6, name='Partition', outputType=GenericType<com.example.graduationproject.domain.ItemViewCount>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 7
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming SinkTransformation{id=8, name='Print to Std. Out', outputType=GenericType<java.lang.Object>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 8
2020-04-23 19:00:17 [DEBUG](StreamGraphGenerator          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Transforming SinkTransformation{id=9, name='Unnamed', outputType=GenericType<java.lang.Object>, parallelism=1}
2020-04-23 19:00:17 [DEBUG](StreamGraph                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Vertex: 9
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'cbc357ccb763df2852fee8c4fc7d55f2' for node 'Source: Custom Source-1' {id: 1, parallelism: 1, user function: org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash '570f707193e0fe32f4d86d067aba243b' for node 'Map-2' {id: 2, parallelism: 1, user function: com.example.graduationproject.map.TopItemMapFunction}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'b728d985904d42b0fdd945a9e3253fca' for node 'Timestamps/Watermarks-3' {id: 3, parallelism: 1, user function: com.example.graduationproject.task.TopNItemTask$1}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash '306d8342cb5b2ad8b53f1be57f65bee8' for node 'Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.runtime.operators.windowing.functions.InternalSingleValueWindowFunction}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'a11f7b3dcd72fbd94a295f0c524af5af' for node 'KeyedProcess-7' {id: 7, parallelism: 1, user function: com.example.graduationproject.top.TopNHotItems}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash '3a529094f0c3b7952561e342c2723212' for node 'Sink: Print to Std. Out-8' {id: 8, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
2020-04-23 19:00:17 [DEBUG](StreamGraphHasherV2           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Generated hash 'd99500e9afad3b634f244c94e6088de5' for node 'Sink: Unnamed-9' {id: 9, parallelism: 1, user function: org.apache.flink.streaming.connectors.redis.RedisSink}
2020-04-23 19:00:17 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parallelism set: 1 for 7
2020-04-23 19:00:17 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parallelism set: 1 for 5
2020-04-23 19:00:17 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] CONNECTED: KeyGroupStreamPartitioner - 5 -> 7
2020-04-23 19:00:17 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Parallelism set: 1 for 1
2020-04-23 19:00:17 [DEBUG](StreamingJobGraphGenerator    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] CONNECTED: KeyGroupStreamPartitioner - 1 -> 5
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.cpu.cores' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 1.7976931348623157E308
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.heap.size' , default: null (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.task.off-heap.size' , default: 0 bytes (fallback keys: []) required for local execution is not set, setting it to its default value 9223372036854775807 bytes
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.min' , default: 64 mb (fallback keys: [{key=taskmanager.network.memory.min, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.network.max' , default: 1 gb (fallback keys: [{key=taskmanager.network.memory.max, isDeprecated=true}]) required for local execution is not set, setting it to its default value 64 mb
2020-04-23 19:00:17 [INFO ](TaskExecutorResourceUtils     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The configuration option Key: 'taskmanager.memory.managed.size' , default: null (fallback keys: [{key=taskmanager.memory.size, isDeprecated=true}]) required for local execution is not set, setting it to its default value 128 mb
2020-04-23 19:00:17 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Flink Mini Cluster
2020-04-23 19:00:17 [DEBUG](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using configuration MiniClusterConfiguration {singleRpcService=SHARED, numTaskManagers=1, commonBindAddress='null', config={taskmanager.memory.network.min=64 mb, taskmanager.cpu.cores=1.7976931348623157E308, taskmanager.memory.task.off-heap.size=9223372036854775807 bytes, execution.target=local, rest.bind-port=0, taskmanager.memory.network.max=64 mb, execution.attached=true, jobmanager.scheduler=ng, taskmanager.memory.managed.size=128 mb, taskmanager.numberOfTaskSlots=1, taskmanager.memory.task.heap.size=9223372036854775807 bytes, rest.address=localhost}}
2020-04-23 19:00:17 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Metrics Registry
2020-04-23 19:00:17 [INFO ](MetricRegistryImpl            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No metrics reporter configured, no metrics will be exposed/reported.
2020-04-23 19:00:17 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC Service(s)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=52) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=18) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:18 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:18 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=53) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:18 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=19) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:18 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 19:00:19 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 19:00:19 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=54) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=20) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to start actor system at :0
2020-04-23 19:00:19 [DEBUG](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using akka configuration
 Config(SimpleConfigObject({"akka":{"actor":{"default-dispatcher":{"executor":"thread-pool-executor","thread-pool-executor":{"core-pool-size-max":1,"core-pool-size-min":1},"thread-priority":1,"throughput":15,"type":"akka.dispatch.PriorityThreadsDispatcher"},"guardian-supervisor-strategy":"org.apache.flink.runtime.akka.StoppingSupervisorWithoutLoggingActorKilledExceptionStrategy","provider":"akka.remote.RemoteActorRefProvider","warn-about-java-serializer-usage":"off"},"daemonic":"off","jvm-exit-on-fatal-error":"on","log-config-on-start":"off","log-dead-letters":"off","log-dead-letters-during-shutdown":"off","loggers":["akka.event.slf4j.Slf4jLogger"],"logging-filter":"akka.event.slf4j.Slf4jLoggingFilter","loglevel":"DEBUG","remote":{"log-remote-lifecycle-events":"off","netty":{"tcp":{"bind-hostname":"0.0.0.0","bind-port":0,"client-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"connection-timeout":"20000ms","hostname":"","maximum-frame-size":"10485760b","port":0,"server-socket-worker-pool":{"pool-size-factor":1,"pool-size-max":2,"pool-size-min":1},"tcp-nodelay":"on","transport-class":"akka.remote.transport.netty.NettyTransport"}},"retry-gate-closed-for":"50 ms","startup-timeout":"100000ms","transport-failure-detector":{"acceptable-heartbeat-pause":"6000000ms","heartbeat-interval":"1000000ms","threshold":300}},"serialize-messages":"off","stdout-loglevel":"OFF"}}))
2020-04-23 19:00:19 [INFO ](Slf4jLogger                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slf4jLogger started
2020-04-23 19:00:19 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] logger log1-Slf4jLogger started
2020-04-23 19:00:19 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Default Loggers started
2020-04-23 19:00:19 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting remoting
2020-04-23 19:00:19 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using select timeout of 500
2020-04-23 19:00:19 [DEBUG](SelectorUtil                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Epoll-bug workaround enabled = false
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=55) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:19 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=21) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:19 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=56) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=22) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [INFO ](Remoting                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.65.1:56664]
2020-04-23 19:00:20 [INFO ](AkkaRpcServiceUtils           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Actor system started at akka.tcp://flink-metrics@192.168.65.1:56664
2020-04-23 19:00:20 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=57) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting high-availability services
2020-04-23 19:00:20 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB server storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-8da9d4e0-8246-4ea1-9dd1-2e6c1ac886d6
2020-04-23 19:00:20 [DEBUG](NetUtils                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to open socket on port 0
2020-04-23 19:00:20 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Started BLOB server at 0.0.0.0:56665 - max concurrent requests: 50 - max backlog: 1000
2020-04-23 19:00:20 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-9aefc601-e780-4c24-a258-089c187758fb
2020-04-23 19:00:20 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created BLOB cache storage directory C:\Users\Zzwen\AppData\Local\Temp\blobStore-6400d38e-abdb-46e2-a2be-00373fe46afe
2020-04-23 19:00:20 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting 1 TaskManger(s)
2020-04-23 19:00:20 [INFO ](TaskManagerRunner             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting TaskManager with ResourceID: 560bac02-865d-43cf-9365-b5c17bf4a4c2
2020-04-23 19:00:20 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=23) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:20 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:20 [INFO ](TaskManagerServices           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Temporary file directory 'C:\Users\Zzwen\AppData\Local\Temp': total 237 GB, usable 69 GB (29.11% usable)
2020-04-23 19:00:21 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-b4e25467-edf3-4a62-9219-8924e7929db3 for spill files.
2020-04-23 19:00:21 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-9cf3bc7b-0700-46bd-98b4-9ff5d2b9f2f1 for spill files.
2020-04-23 19:00:21 [INFO ](NetworkBufferPool             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2020-04-23 19:00:21 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the network environment and its components.
2020-04-23 19:00:21 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting network connection manager
2020-04-23 19:00:21 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the kvState service and its components.
2020-04-23 19:00:21 [WARN ](TaskManagerLocation           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2020-04-23 19:00:21 [INFO ](TaskManagerConfiguration      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Messages have a max timeout of 10000 ms
2020-04-23 19:00:21 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-04-23 19:00:21 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start job leader service.
2020-04-23 19:00:21 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] User file cache uses directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-0761e993-d94d-40d2-8951-afbd876b571f
2020-04-23 19:00:21 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher REST endpoint.
2020-04-23 19:00:21 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting rest endpoint.
2020-04-23 19:00:21 [DEBUG](InternalLoggerFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using SLF4J as the default logging framework
2020-04-23 19:00:21 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2020-04-23 19:00:21 [DEBUG](InternalThreadLocalMap        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2020-04-23 19:00:21 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:21 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:21 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=58) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:21 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:21 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Log file environment variable 'log.file' is not set.
2020-04-23 19:00:21 [WARN ](WebMonitorUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to load web based job submission extension.
org.apache.flink.util.FlinkException: The module flink-runtime-web could not be found in the class path. Please add this jar in order to enable web based job submission.
	at org.apache.flink.runtime.webmonitor.WebMonitorUtils.loadWebSubmissionExtension(WebMonitorUtils.java:192)
	at org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint.initializeHandlers(DispatcherRestEndpoint.java:98)
	at org.apache.flink.runtime.rest.RestServerEndpoint.start(RestServerEndpoint.java:141)
	at org.apache.flink.runtime.entrypoint.component.DefaultDispatcherResourceManagerComponentFactory.create(DefaultDispatcherResourceManagerComponentFactory.java:165)
	at org.apache.flink.runtime.minicluster.MiniCluster.createDispatcherResourceManagerComponents(MiniCluster.java:394)
	at org.apache.flink.runtime.minicluster.MiniCluster.setupDispatcherResourceManagerComponents(MiniCluster.java:360)
	at org.apache.flink.runtime.minicluster.MiniCluster.start(MiniCluster.java:314)
	at org.apache.flink.client.deployment.executors.LocalExecutor.startMiniCluster(LocalExecutor.java:117)
	at org.apache.flink.client.deployment.executors.LocalExecutor.execute(LocalExecutor.java:63)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1733)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1634)
	at org.apache.flink.streaming.api.environment.LocalStreamEnvironment.execute(LocalStreamEnvironment.java:74)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1620)
	at com.example.graduationproject.task.TopNItemTask.main(TopNItemTask.java:78)
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Platform: Windows
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noUnsafe: false
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Java version: 8
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.theUnsafe: available
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe.copyMemory: available
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Buffer.address: available
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] direct buffer constructor: available
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.Bits.unaligned: available, true
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2020-04-23 19:00:21 [DEBUG](PlatformDependent0            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.DirectByteBuffer.<init>(long, int): available
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] sun.misc.Unsafe: available
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.tmpdir: C:\Users\Zzwen\AppData\Local\Temp (java.io.tmpdir)
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.bitMode: 64 (sun.arch.data.model)
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxDirectMemory: 3810525184 bytes
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.uninitializedArrayAllocationThreshold: -1
2020-04-23 19:00:21 [DEBUG](CleanerJava6                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] java.nio.ByteBuffer.cleaner(): available
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noPreferDirect: false
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@3fdecce under DELETE@/v1/cluster.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ShutdownHandler@3fdecce under DELETE@/cluster.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@290aeb20 under GET@/v1/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.DashboardConfigHandler@290aeb20 under GET@/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@73ad4ecc under GET@/v1/jobmanager/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterConfigHandler@73ad4ecc under GET@/jobmanager/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@69da0b12 under GET@/v1/jobmanager/log.
2020-04-23 19:00:21 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:21 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:21 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=24) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:21 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@69da0b12 under GET@/jobmanager/log.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@2764c546 under GET@/v1/jobmanager/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobManagerMetricsHandler@2764c546 under GET@/jobmanager/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@59496961 under GET@/v1/jobmanager/stdout.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.legacy.ConstantTextHandler@59496961 under GET@/jobmanager/stdout.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@408b87aa under GET@/v1/jobs.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobIdsHandler@408b87aa under GET@/jobs.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@79b08632 under POST@/v1/jobs.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobSubmitHandler@79b08632 under POST@/jobs.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@787f32b7 under GET@/v1/jobs/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingJobsMetricsHandler@787f32b7 under GET@/jobs/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6aef4eb8 under GET@/v1/jobs/overview.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobsOverviewHandler@6aef4eb8 under GET@/jobs/overview.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@76c52298 under GET@/v1/jobs/:jobid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobDetailsHandler@76c52298 under GET@/jobs/:jobid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@bb9ab64 under PATCH@/v1/jobs/:jobid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@bb9ab64 under PATCH@/jobs/:jobid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@a52ca2e under GET@/v1/jobs/:jobid/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobAccumulatorsHandler@a52ca2e under GET@/jobs/:jobid/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@1ad8df52 under GET@/v1/jobs/:jobid/checkpoints.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointingStatisticsHandler@1ad8df52 under GET@/jobs/:jobid/checkpoints.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@45d6ef73 under GET@/v1/jobs/:jobid/checkpoints/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointConfigHandler@45d6ef73 under GET@/jobs/:jobid/checkpoints/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@3f29e26 under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.CheckpointStatisticDetailsHandler@3f29e26 under GET@/jobs/:jobid/checkpoints/details/:checkpointid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@1f6d27cc under GET@/v1/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.checkpoints.TaskCheckpointStatisticDetailsHandler@1f6d27cc under GET@/jobs/:jobid/checkpoints/details/:checkpointid/subtasks/:vertexid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@4393593c under GET@/v1/jobs/:jobid/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobConfigHandler@4393593c under GET@/jobs/:jobid/config.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@314c8b4a under GET@/v1/jobs/:jobid/exceptions.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler@314c8b4a under GET@/jobs/:jobid/exceptions.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@26d820eb under GET@/v1/jobs/:jobid/execution-result.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobExecutionResultHandler@26d820eb under GET@/jobs/:jobid/execution-result.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@507d20bb under GET@/v1/jobs/:jobid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobMetricsHandler@507d20bb under GET@/jobs/:jobid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@9fec931 under GET@/v1/jobs/:jobid/plan.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobPlanHandler@9fec931 under GET@/jobs/:jobid/plan.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@5cbd159f under PATCH@/v1/jobs/:jobid/rescaling.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingTriggerHandler@5cbd159f under PATCH@/jobs/:jobid/rescaling.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@3b05a99b under GET@/v1/jobs/:jobid/rescaling/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.rescaling.RescalingHandlers$RescalingStatusHandler@3b05a99b under GET@/jobs/:jobid/rescaling/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@2c43eb8 under POST@/v1/jobs/:jobid/savepoints.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointTriggerHandler@2c43eb8 under POST@/jobs/:jobid/savepoints.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@7d0cc890 under GET@/v1/jobs/:jobid/savepoints/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$SavepointStatusHandler@7d0cc890 under GET@/jobs/:jobid/savepoints/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@49293b43 under POST@/v1/jobs/:jobid/stop.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointHandlers$StopWithSavepointHandler@49293b43 under POST@/jobs/:jobid/stop.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@5ff60a8c under GET@/v1/jobs/:jobid/vertices/:vertexid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexDetailsHandler@5ff60a8c under GET@/jobs/:jobid/vertices/:vertexid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@7ce4de34 under GET@/v1/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexAccumulatorsHandler@7ce4de34 under GET@/jobs/:jobid/vertices/:vertexid/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@67b7c170 under GET@/v1/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexBackPressureHandler@67b7c170 under GET@/jobs/:jobid/vertices/:vertexid/backpressure.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@67440de6 under GET@/v1/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexMetricsHandler@67440de6 under GET@/jobs/:jobid/vertices/:vertexid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@889d9e8 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksAllAccumulatorsHandler@889d9e8 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@5246a3b3 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingSubtasksMetricsHandler@5246a3b3 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@ba354ca under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskCurrentAttemptDetailsHandler@ba354ca under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4c4f4365 under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptDetailsHandler@4c4f4365 under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@acf859d under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtaskExecutionAttemptAccumulatorsHandler@acf859d under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt/accumulators.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@6df3e44c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.SubtaskMetricsHandler@6df3e44c under GET@/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@7ce7e83c under GET@/v1/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.SubtasksTimesHandler@7ce7e83c under GET@/jobs/:jobid/vertices/:vertexid/subtasktimes.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4a05d8ae under GET@/v1/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobVertexTaskManagersHandler@4a05d8ae under GET@/jobs/:jobid/vertices/:vertexid/taskmanagers.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@3c904f1e under GET@/v1/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.JobVertexWatermarksHandler@3c904f1e under GET@/jobs/:jobid/vertices/:vertexid/watermarks.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@bb9ab64 under GET@/v1/jobs/:jobid/yarn-cancel.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@bb9ab64 under GET@/jobs/:jobid/yarn-cancel.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4eb30d44 under GET@/v1/jobs/:jobid/yarn-stop.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.JobCancellationHandler@4eb30d44 under GET@/jobs/:jobid/yarn-stop.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@d56aaa6 under GET@/v1/overview.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.cluster.ClusterOverviewHandler@d56aaa6 under GET@/overview.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@6972c30a under POST@/v1/savepoint-disposal.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalTriggerHandler@6972c30a under POST@/savepoint-disposal.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@57a48985 under GET@/v1/savepoint-disposal/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.savepoints.SavepointDisposalHandlers$SavepointDisposalStatusHandler@57a48985 under GET@/savepoint-disposal/:triggerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1ab6718 under GET@/v1/taskmanagers.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagersHandler@1ab6718 under GET@/taskmanagers.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@3910fe11 under GET@/v1/taskmanagers/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.AggregatingTaskManagersMetricsHandler@3910fe11 under GET@/taskmanagers/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@460510aa under GET@/v1/taskmanagers/:taskmanagerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerDetailsHandler@460510aa under GET@/taskmanagers/:taskmanagerid.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@351e414e under GET@/v1/taskmanagers/:taskmanagerid/log.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerLogFileHandler@351e414e under GET@/taskmanagers/:taskmanagerid/log.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@6fd77352 under GET@/v1/taskmanagers/:taskmanagerid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.job.metrics.TaskManagerMetricsHandler@6fd77352 under GET@/taskmanagers/:taskmanagerid/metrics.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@5109e8cf under GET@/v1/taskmanagers/:taskmanagerid/stdout.
2020-04-23 19:00:21 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register handler org.apache.flink.runtime.rest.handler.taskmanager.TaskManagerStdoutFileHandler@5109e8cf under GET@/taskmanagers/:taskmanagerid/stdout.
2020-04-23 19:00:21 [DEBUG](MultithreadEventLoopGroup     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.eventLoopThreads: 16
2020-04-23 19:00:21 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.noKeySetOptimization: false
2020-04-23 19:00:21 [DEBUG](NioEventLoop                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.selectorAutoRebuildThreshold: 512
2020-04-23 19:00:21 [DEBUG](PlatformDependent             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] org.jctools-core.MpscChunkedArrayQueue: available
2020-04-23 19:00:21 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.processId: 27460 (auto-detected)
2020-04-23 19:00:21 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv4Stack: false
2020-04-23 19:00:21 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Djava.net.preferIPv6Addresses: false
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=59) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=25) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:22 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:22 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=60) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=26) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:22 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:22 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2020-04-23 19:00:22 [DEBUG](NetUtil                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=61) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=27) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:23 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:23 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=62) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=28) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:23 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:23 [DEBUG](DefaultChannelId              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.machineId: 7c:b0:c2:ff:fe:e9:fe:6c (auto-detected)
2020-04-23 19:00:23 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.level: simple
2020-04-23 19:00:23 [DEBUG](ResourceLeakDetector          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dorg.apache.flink.shaded.netty4.io.netty.leakDetection.targetRecords: 4
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numHeapArenas: 16
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.numDirectArenas: 16
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.pageSize: 8192
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxOrder: 11
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.chunkSize: 16777216
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.tinyCacheSize: 512
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.smallCacheSize: 256
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.normalCacheSize: 64
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimInterval: 8192
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.useCacheForAllThreads: true
2020-04-23 19:00:23 [DEBUG](PooledByteBufAllocator        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2020-04-23 19:00:23 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.allocator.type: pooled
2020-04-23 19:00:23 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.threadLocalDirectBufferSize: 0
2020-04-23 19:00:23 [DEBUG](ByteBufUtil                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] -Dio.netty.maxThreadLocalCharBufferSize: 16384
2020-04-23 19:00:23 [DEBUG](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Binding rest endpoint to null:0.
2020-04-23 19:00:23 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Rest endpoint listening at localhost:56701
2020-04-23 19:00:23 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender http://localhost:56701
2020-04-23 19:00:23 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] http://localhost:56701 was granted leadership with leaderSessionID=75476eea-ce16-4219-b5e1-b935013e6376
2020-04-23 19:00:23 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader http://localhost:56701 , session=75476eea-ce16-4219-b5e1-b935013e6376
2020-04-23 19:00:23 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-04-23 19:00:23 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting Dispatcher.
2020-04-23 19:00:23 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2020-04-23 19:00:23 [DEBUG](DefaultDispatcherResourceManagerComponentFactory) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting ResourceManager.
2020-04-23 19:00:23 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender LeaderContender: StandaloneResourceManager
2020-04-23 19:00:23 [DEBUG](DefaultDispatcherRunner       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create new DispatcherLeaderProcess with leader session id 0365ccf5-dce9-49b7-b43e-c8775acfc5f7.
2020-04-23 19:00:23 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 935d64cd9c6645bdfa66b4cf0a4a4f8d
2020-04-23 19:00:23 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Flink Mini Cluster started successfully
2020-04-23 19:00:23 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting the SlotManager.
2020-04-23 19:00:23 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start SessionDispatcherLeaderProcess.
2020-04-23 19:00:23 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Recover all persisted job graphs.
2020-04-23 19:00:23 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:23 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=fa66b4cf-0a4a-4f8d-935d-64cd9c6645bd
2020-04-23 19:00:23 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:23 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully recovered 0 persisted job graphs.
2020-04-23 19:00:23 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:23 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:23 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(935d64cd9c6645bdfa66b4cf0a4a4f8d).
2020-04-23 19:00:23 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:23 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 19:00:24 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=0365ccf5-dce9-49b7-b43e-c8775acfc5f7
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/dispatcher. Returning a org.apache.flink.runtime.dispatcher.DispatcherGateway gateway.
2020-04-23 19:00:24 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager with ResourceID 560bac02-865d-43cf-9365-b5c17bf4a4c2 (akka://flink/user/taskmanager_0) at ResourceManager
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at resource manager akka://flink/user/resourcemanager under registration id e3a1aaa9ed77405f70e42daf9caa5ef6.
2020-04-23 19:00:24 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering TaskManager 560bac02-865d-43cf-9365-b5c17bf4a4c2 under e3a1aaa9ed77405f70e42daf9caa5ef6 at the SlotManager.
2020-04-23 19:00:24 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received JobGraph submission ad36c851e62a2a17ea029f70b9e78c4a (TopN Job).
2020-04-23 19:00:24 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Submitting job ad36c851e62a2a17ea029f70b9e78c4a (TopN Job).
2020-04-23 19:00:24 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using restart back off time strategy NoRestartBackoffTimeStrategy for TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Running initialization on master for job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully ran initialization on master in 0 ms.
2020-04-23 19:00:24 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding 3 vertices from job graph TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attaching 3 topologically sorted vertices to existing job graph with 0 vertices and 0 intermediate results.
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting ExecutionJobVertex cbc357ccb763df2852fee8c4fc7d55f2 (Source: Custom Source -> Map -> Timestamps/Watermarks) to 0 predecessors.
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting ExecutionJobVertex 306d8342cb5b2ad8b53f1be57f65bee8 (Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)) to 1 predecessors.
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting input 0 of vertex 306d8342cb5b2ad8b53f1be57f65bee8 (Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)) to intermediate result referenced via predecessor cbc357ccb763df2852fee8c4fc7d55f2 (Source: Custom Source -> Map -> Timestamps/Watermarks).
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting ExecutionJobVertex a11f7b3dcd72fbd94a295f0c524af5af (KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed)) to 1 predecessors.
2020-04-23 19:00:24 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting input 0 of vertex a11f7b3dcd72fbd94a295f0c524af5af (KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed)) to intermediate result referenced via predecessor 306d8342cb5b2ad8b53f1be57f65bee8 (Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)).
2020-04-23 19:00:24 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successfully created execution graph from job graph TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:24 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Status of the shared state registry of job ad36c851e62a2a17ea029f70b9e78c4a after restore: SharedStateRegistry{registeredStates={}}.
2020-04-23 19:00:24 [DEBUG](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resetting the master hooks.
2020-04-23 19:00:24 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Start building failover regions.
2020-04-23 19:00:24 [DEBUG](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a failover region with 3 vertices.
2020-04-23 19:00:24 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created 1 failover regions.
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionStrategy@286f3ceb for TopN Job (ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:24 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Proposing leadership to contender akka://flink/user/jobmanager_1
2020-04-23 19:00:24 [INFO ](JobManagerRunnerImpl          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager runner for job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a) was granted leadership with session id f4e7c8d9-5366-4998-b439-895615782409 at akka://flink/user/jobmanager_1.
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting execution of job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a) under job master id b439895615782409f4e7c8d953664998.
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.EagerSchedulingStrategy]
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a) switched from state CREATED to RUNNING.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from CREATED to SCHEDULED.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from CREATED to SCHEDULED.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from CREATED to SCHEDULED.
2020-04-23 19:00:24 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{8234b244928aebe8a1b0edd5f1967366} for execution cbc357ccb763df2852fee8c4fc7d55f2_0
2020-04-23 19:00:24 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{8234b244928aebe8a1b0edd5f1967366}] for task: null
2020-04-23 19:00:24 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{6981f5be481d6237fd29f2b595336954}]
2020-04-23 19:00:24 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create multi task slot [SlotRequestId{f7c0b0d3c035105f98a936e8e54cf965}] in slot [SlotRequestId{6981f5be481d6237fd29f2b595336954}].
2020-04-23 19:00:24 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{8234b244928aebe8a1b0edd5f1967366}] in multi task slot [SlotRequestId{f7c0b0d3c035105f98a936e8e54cf965}] for group cbc357ccb763df2852fee8c4fc7d55f2.
2020-04-23 19:00:24 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{60d26f55886e4b25e910b580d7bd19e8} for execution 306d8342cb5b2ad8b53f1be57f65bee8_0
2020-04-23 19:00:24 [DEBUG](DefaultExecutionSlotAllocator ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocate slot with id SlotRequestId{0cfb735426e5ba293ff5ac6c8d744d9b} for execution a11f7b3dcd72fbd94a295f0c524af5af_0
2020-04-23 19:00:24 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:24 [INFO ](EmbeddedLeaderService         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=f4e7c8d9-5366-4998-b439-895615782409
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to ResourceManager akka://flink/user/resourcemanager(935d64cd9c6645bdfa66b4cf0a4a4f8d)
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/resourcemanager. Returning a org.apache.flink.runtime.resourcemanager.ResourceManagerGateway gateway.
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved ResourceManager address, beginning registration
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at ResourceManager attempt 1 (timeout=100ms)
2020-04-23 19:00:24 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job ad36c851e62a2a17ea029f70b9e78c4a to job leader id monitoring.
2020-04-23 19:00:24 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering job manager b439895615782409f4e7c8d953664998@akka://flink/user/jobmanager_1 for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader f4e7c8d9-5366-4998-b439-895615782409@akka://flink/user/jobmanager_1.
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:24 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered job manager b439895615782409f4e7c8d953664998@akka://flink/user/jobmanager_1 for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager successfully registered at ResourceManager, leader id: 935d64cd9c6645bdfa66b4cf0a4a4f8d.
2020-04-23 19:00:24 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting new slot [SlotRequestId{6981f5be481d6237fd29f2b595336954}] and profile ResourceProfile{UNKNOWN} from resource manager.
2020-04-23 19:00:24 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Request slot with profile ResourceProfile{UNKNOWN} for job ad36c851e62a2a17ea029f70b9e78c4a with allocation id 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Receive slot request 717af0e4296be25acde6c7d90d85f53e for job ad36c851e62a2a17ea029f70b9e78c4a from resource manager with leader id 935d64cd9c6645bdfa66b4cf0a4a4f8d.
2020-04-23 19:00:24 [DEBUG](MemoryManager                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initialized MemoryManager with total memory size 134217728 ({OFF_HEAP=134217728}), page size 32768.
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Allocated slot for 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Add job ad36c851e62a2a17ea029f70b9e78c4a for job leader monitoring.
2020-04-23 19:00:24 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job ad36c851e62a2a17ea029f70b9e78c4a. Address: akka://flink/user/jobmanager_1, leader id: b439895615782409f4e7c8d953664998.
2020-04-23 19:00:24 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to register at job manager akka://flink/user/jobmanager_1 with leader id f4e7c8d9-5366-4998-b439-895615782409.
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/jobmanager_1. Returning a org.apache.flink.runtime.jobmaster.JobMasterGateway gateway.
2020-04-23 19:00:24 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Resolved JobManager address, beginning registration
2020-04-23 19:00:24 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registration at JobManager attempt 1 (timeout=100ms)
2020-04-23 19:00:24 [DEBUG](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Try to connect to remote RPC endpoint with address akka://flink/user/taskmanager_0. Returning a org.apache.flink.runtime.taskexecutor.TaskExecutorGateway gateway.
2020-04-23 19:00:24 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Register new TaskExecutor 560bac02-865d-43cf-9365-b5c17bf4a4c2.
2020-04-23 19:00:24 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful registration at job manager akka://flink/user/jobmanager_1 for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Establish JobManager connection for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Offer reserved slots to the leader of job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=63) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{60d26f55886e4b25e910b580d7bd19e8}] for task: null
2020-04-23 19:00:24 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{60d26f55886e4b25e910b580d7bd19e8}] in multi task slot [SlotRequestId{f7c0b0d3c035105f98a936e8e54cf965}] for group 306d8342cb5b2ad8b53f1be57f65bee8.
2020-04-23 19:00:24 [DEBUG](SchedulerImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot request [SlotRequestId{0cfb735426e5ba293ff5ac6c8d744d9b}] for task: null
2020-04-23 19:00:24 [DEBUG](SlotSharingManager            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Create single task slot [SlotRequestId{0cfb735426e5ba293ff5ac6c8d744d9b}] in multi task slot [SlotRequestId{f7c0b0d3c035105f98a936e8e54cf965}] for group a11f7b3dcd72fbd94a295f0c524af5af.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (attempt #0) to 560bac02-865d-43cf-9365-b5c17bf4a4c2 @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (attempt #0) to 560bac02-865d-43cf-9365-b5c17bf4a4c2 @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from SCHEDULED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Deploying KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (attempt #0) to 560bac02-865d-43cf-9365-b5c17bf4a4c2 @ 127.0.0.1 (dataPort=-1)
2020-04-23 19:00:24 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fulfilled slot request [SlotRequestId{6981f5be481d6237fd29f2b595336954}] with allocated slot [717af0e4296be25acde6c7d90d85f53e].
2020-04-23 19:00:24 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new allocation id 717af0e4296be25acde6c7d90d85f53e for local state stores for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:24 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_717af0e4296be25acde6c7d90d85f53e], jobID=ad36c851e62a2a17ea029f70b9e78c4a, jobVertexID=cbc357ccb763df2852fee8c4fc7d55f2, subtaskIndex=0}} for ad36c851e62a2a17ea029f70b9e78c4a - cbc357ccb763df2852fee8c4fc7d55f2 - 0 under allocation id 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [DEBUG](ResultPartitionFactory        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@3241ced2
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1).
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from CREATED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) [DEPLOYING]
2020-04-23 19:00:24 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_717af0e4296be25acde6c7d90d85f53e], jobID=ad36c851e62a2a17ea029f70b9e78c4a, jobVertexID=306d8342cb5b2ad8b53f1be57f65bee8, subtaskIndex=0}} for ad36c851e62a2a17ea029f70b9e78c4a - 306d8342cb5b2ad8b53f1be57f65bee8 - 0 under allocation id 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [DEBUG](ResultPartitionFactory        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Initialized org.apache.flink.runtime.io.network.partition.ResultPartitionFactory@3241ced2
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task ecbe111afa485d5e6c51b8ef01f3565a at library cache manager took 0 milliseconds
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](LocalBufferPool               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using a local buffer pool with 2-10 buffers
2020-04-23 19:00:24 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered ReleaseOnConsumptionResultPartition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2020-04-23 19:00:24 [DEBUG](TaskEventDispatcher           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] registering 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a
2020-04-23 19:00:24 [DEBUG](SingleInputGateFactory        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1).
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from CREATED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) [DEPLOYING]
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task 217ef54de6b23a12673bdf65df55161e at library cache manager took 1 milliseconds
2020-04-23 19:00:24 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered new local state store with configuration LocalRecoveryConfig{localRecoveryMode=false, localStateDirectories=LocalRecoveryDirectoryProvider{rootDirectories=[C:\Users\Zzwen\AppData\Local\Temp\localState\aid_717af0e4296be25acde6c7d90d85f53e], jobID=ad36c851e62a2a17ea029f70b9e78c4a, jobVertexID=a11f7b3dcd72fbd94a295f0c524af5af, subtaskIndex=0}} for ad36c851e62a2a17ea029f70b9e78c4a - a11f7b3dcd72fbd94a295f0c524af5af - 0 under allocation id 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](LocalBufferPool               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using a local buffer pool with 2-10 buffers
2020-04-23 19:00:24 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registered ReleaseOnConsumptionResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2020-04-23 19:00:24 [DEBUG](SingleInputGateFactory        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65): Created 1 input channels (local: 1, remote: 0, unknown: 0).
2020-04-23 19:00:24 [DEBUG](LocalBufferPool               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using a local buffer pool with 0-8 buffers
2020-04-23 19:00:24 [DEBUG](LocalInputChannel             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] LocalInputChannel [50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a]: Requesting LOCAL subpartition 0 of partition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a.
2020-04-23 19:00:24 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2020-04-23 19:00:24 [DEBUG](PipelinedSubpartition         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a): Creating read view for subpartition 0 of partition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a.
2020-04-23 19:00:24 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1).
2020-04-23 19:00:24 [DEBUG](ResultPartition               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created PipelinedSubpartitionView(index: 0) of ResultPartition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from CREATED to DEPLOYING.
2020-04-23 19:00:24 [INFO ](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Activate slot 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating FileSystem stream leak safety net for task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) [DEPLOYING]
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loading JAR files for task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Getting user code class loader for task c59849536cef20558f4972e95ec78d65 at library cache manager took 0 milliseconds
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Registering task at network: KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) [DEPLOYING].
2020-04-23 19:00:24 [DEBUG](LocalBufferPool               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using a local buffer pool with 0-8 buffers
2020-04-23 19:00:24 [DEBUG](LocalInputChannel             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] LocalInputChannel [e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e]: Requesting LOCAL subpartition 0 of partition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e.
2020-04-23 19:00:24 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Requesting subpartition 0 of ReleaseOnConsumptionResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2020-04-23 19:00:24 [DEBUG](PipelinedSubpartition         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Creating read view for subpartition 0 of partition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e.
2020-04-23 19:00:24 [DEBUG](ResultPartition               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created PipelinedSubpartitionView(index: 0) of ResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e
2020-04-23 19:00:24 [DEBUG](TaskEventDispatcher           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] registering e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using partitioner HASH for output 0 of task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult)
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using partitioner HASH for output 0 of task Source: Custom Source -> Map -> Timestamps/Watermarks
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1).
2020-04-23 19:00:24 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1).
2020-04-23 19:00:24 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Source: Custom Source -> Map -> Timestamps/Watermarks (1/1).
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [INFO ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-04-23 19:00:24 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from DEPLOYING to RUNNING.
2020-04-23 19:00:24 [WARN ](MetricGroup                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] The operator name Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) exceeded the 80 characters length limit and was truncated.
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Source: Custom Source -> Map -> Timestamps/Watermarks (1/1)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=29) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for TimestampsAndPeriodicWatermarksOperator_b728d985904d42b0fdd945a9e3253fca_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1)
2020-04-23 19:00:24 [DEBUG](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Invoking Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1)
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSink_3a529094f0c3b7952561e342c2723212_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating keyed state backend for WindowOperator_306d8342cb5b2ad8b53f1be57f65bee8_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSink_d99500e9afad3b634f244c94e6088de5_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamMap_570f707193e0fe32f4d86d067aba243b_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for StreamSource_cbc357ccb763df2852fee8c4fc7d55f2_(1/1) with empty state.
2020-04-23 19:00:24 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-04-23 19:00:24 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:24 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] No restore state for FlinkKafkaConsumer.
2020-04-23 19:00:24 [INFO ](HeapKeyedStateBackend         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing heap keyed state backend with stream factory.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for WindowOperator_306d8342cb5b2ad8b53f1be57f65bee8_(1/1) with empty state.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating keyed state backend for KeyedProcessOperator_a11f7b3dcd72fbd94a295f0c524af5af_(1/1) with empty state.
2020-04-23 19:00:24 [INFO ](HeapKeyedStateBackend         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing heap keyed state backend with stream factory.
2020-04-23 19:00:24 [DEBUG](BackendRestorerProcedure      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating operator state backend for KeyedProcessOperator_a11f7b3dcd72fbd94a295f0c524af5af_(1/1) with empty state.
2020-04-23 19:00:24 [INFO ](TypeExtractor                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] class com.example.graduationproject.domain.ItemViewCount is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-04-23 19:00:24 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topItem
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Initializing the Kafka consumer
2020-04-23 19:00:24 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:24 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:24 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Kafka consumer initialized
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:24 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Initiating API versions fetch from node -1.
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Sending metadata request (type=MetadataRequest, topics=) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=64) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:24 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:24 [INFO ](FlinkKafkaConsumerBase        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='book', partition=0}]
2020-04-23 19:00:24 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-1, groupId=topItem] Kafka consumer has been closed
2020-04-23 19:00:24 [INFO ](ConsumerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [aliyun:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = topItem
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initializing the Kafka consumer
2020-04-23 19:00:24 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 1 to Cluster(id = null, nodes = [aliyun:9092 (id: -1 rack: null)], partitions = [], controller = null)
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-throttle-time
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name heartbeat-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name join-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name sync-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name commit-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-fetched
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-fetched
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name fetch-latency
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lag
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-lead
2020-04-23 19:00:24 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version : 2.0.1
2020-04-23 19:00:24 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId : fa14705e51bd2ce5
2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Kafka consumer initialized
2020-04-23 19:00:24 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Subscribed to partition(s): book-0
2020-04-23 19:00:24 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending FindCoordinator request to broker aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating connection to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:24 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:24 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating API versions fetch from node -1.
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=30) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:24 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:24 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending metadata request (type=MetadataRequest, topics=book) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:25 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:25 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Updated cluster metadata version 2 to Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [Partition(topic = book, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = aliyun:9092 (id: 0 rack: null))
2020-04-23 19:00:25 [DEBUG](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Received FindCoordinator response ClientResponse(receivedTimeMs=1587639625030, latencyMs=164, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=aliyun:9092 (id: 0 rack: null)))
2020-04-23 19:00:25 [INFO ](AbstractCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Discovered group coordinator aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating connection to node aliyun:9092 (id: 2147483647 rack: null)
2020-04-23 19:00:25 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Fetching committed offsets for partitions: [book-0]
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-sent
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.bytes-received
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-2147483647.latency
2020-04-23 19:00:25 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed connection to node 2147483647. Fetching API versions.
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating API versions fetch from node 2147483647.
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Recorded API versions for node 2147483647: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:25 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Found no committed offset for partition book-0
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={book-0=-1}, isolationLevel=READ_UNCOMMITTED) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating connection to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 19:00:25 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed connection to node 0. Fetching API versions.
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Initiating API versions fetch from node 0.
2020-04-23 19:00:25 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 6], Fetch(1): 0 to 10 [usable: 8], ListOffsets(2): 0 to 4 [usable: 3], Metadata(3): 0 to 7 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 4], OffsetFetch(9): 0 to 5 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=65) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Handling ListOffsetResponse response for book-0. Fetched offset 0, timestamp -1
2020-04-23 19:00:25 [INFO ](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Resetting offset for partition book-0 to offset 0.
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED FullFetchRequest(book-0) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=31) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=66) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent a full fetch response that created a new incremental fetch session 927511445 with 1 response partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=0, lastStableOffset = 0, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=0)
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.bytes-fetched
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.records-fetched
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lag
2020-04-23 19:00:25 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name book-0.records-lead
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:25 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=1) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:25 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=32) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:26 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:26 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:26 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:26 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:26 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance fa41931cb237a0d8f807e13392a773d1: SlotReport{slotsStatus=[SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3273e2c96b6c175720d2ac6a41cb9b69, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=a746278421e81a200e3e711bd55f79b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9c80a0a8bea77c101ca67025ba67a41d, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=0626db8ad338c8acae965455a1c1f8b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=7fdb5a165f28137eb3f2370c5c5168fb, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=302fd85a4551294dea1a4b6533203048, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f975e64a3787208d80fb979ad63e9b50, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=aa58d9c04b3ffd199f2860a9ff0e34fc, jobID=77d397c647a53cd8ed694029397cec7d}]}.
2020-04-23 19:00:26 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=67) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=2) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:26 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:26 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:26 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=33) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:26 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=68) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:27 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:27 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:27 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:27 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:27 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:27 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=3) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=34) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:27 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:27 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:27 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:27 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:27 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=69) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=4) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:27 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=35) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:27 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=70) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=5) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=36) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:28 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=71) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=6) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:28 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=37) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:28 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=72) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=7) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=38) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=73) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=8) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:29 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:29 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 0 for partition book-0
2020-04-23 19:00:29 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=39) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=74) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=9) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=40) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=75) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:30 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=10) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:30 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=41) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=76) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=11) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:31 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=42) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:31 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=77) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=12) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=43) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:32 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:32 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=78) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=13) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:32 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=44) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:32 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=79) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=14) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:33 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:33 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=45) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=80) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=15) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:33 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=46) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:33 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:34 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:34 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1557143d4991f864843161f886586f4b.
2020-04-23 19:00:34 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1557143d4991f864843161f886586f4b.
2020-04-23 19:00:34 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from bf8e99d89d910b016909166ae5ce9cc1.
2020-04-23 19:00:34 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 560bac02-865d-43cf-9365-b5c17bf4a4c2.
2020-04-23 19:00:34 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance e3a1aaa9ed77405f70e42daf9caa5ef6: SlotReport{slotsStatus=[SlotStatus{slotID=560bac02-865d-43cf-9365-b5c17bf4a4c2_0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationID=717af0e4296be25acde6c7d90d85f53e, jobID=ad36c851e62a2a17ea029f70b9e78c4a}]}.
2020-04-23 19:00:34 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:34 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from bf8e99d89d910b016909166ae5ce9cc1.
2020-04-23 19:00:34 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 560bac02-865d-43cf-9365-b5c17bf4a4c2.
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=81) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=16) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=47) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:34 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:34 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:34 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 0 for partition book-0
2020-04-23 19:00:34 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=17) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=82) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=48) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [INFO ](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initializing Servlet 'dispatcherServlet'
2020-04-23 19:00:35 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Detected StandardServletMultipartResolver
2020-04-23 19:00:35 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-04-23 19:00:35 [INFO ](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Completed initialization in 12 ms
2020-04-23 19:00:35 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] GET "/book/doFetchData", parameters={}
2020-04-23 19:00:35 [DEBUG](RequestMappingHandlerMapping  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Mapped to com.example.graduationproject.web.controller.BookController#fetchData()
2020-04-23 19:00:35 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ***************************
2020-04-23 19:00:35 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] url : /book/doFetchData
2020-04-23 19:00:35 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ***************************
2020-04-23 19:00:35 [INFO ](BookServiceImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ============================
2020-04-23 19:00:35 [INFO ](BookServiceImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 获取书籍信息：
2020-04-23 19:00:35 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a new SqlSession
2020-04-23 19:00:35 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@23071bc7] was not registered for synchronization because synchronization is not active
2020-04-23 19:00:35 [DEBUG](DataSourceUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fetching JDBC Connection from DataSource
2020-04-23 19:00:35 [DEBUG](SpringManagedTransaction      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7e3556ef] will not be managed by Spring
2020-04-23 19:00:35 [DEBUG](queryAll                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==>  Preparing: SELECT * FROM t_book 
2020-04-23 19:00:35 [DEBUG](queryAll                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==> Parameters: 
2020-04-23 19:00:35 [DEBUG](queryAll                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] <==      Total: 2
2020-04-23 19:00:35 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@23071bc7]
2020-04-23 19:00:35 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=18) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=83) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=49) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:35 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:35 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:35 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=19) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=84) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=50) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:36 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:36 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:36 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:36 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:36 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:36 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:36 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance fa41931cb237a0d8f807e13392a773d1: SlotReport{slotsStatus=[SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3273e2c96b6c175720d2ac6a41cb9b69, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=a746278421e81a200e3e711bd55f79b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9c80a0a8bea77c101ca67025ba67a41d, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=0626db8ad338c8acae965455a1c1f8b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=7fdb5a165f28137eb3f2370c5c5168fb, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=302fd85a4551294dea1a4b6533203048, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f975e64a3787208d80fb979ad63e9b50, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=aa58d9c04b3ffd199f2860a9ff0e34fc, jobID=77d397c647a53cd8ed694029397cec7d}]}.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:36 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:36 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:36 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=20) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=85) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=51) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:36 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:36 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:37 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:37 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:37 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:37 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:37 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:37 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:37 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:37 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:37 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:37 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:37 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=86) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:37 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=52) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=21) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening RedisConnection
2020-04-23 19:00:37 [DEBUG](RedisConnectionUtils          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing Redis Connection.
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=87) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a new SqlSession
2020-04-23 19:00:37 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5bf59d04] was not registered for synchronization because synchronization is not active
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=53) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](DataSourceUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fetching JDBC Connection from DataSource
2020-04-23 19:00:37 [DEBUG](SpringManagedTransaction      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7e3556ef] will not be managed by Spring
2020-04-23 19:00:37 [DEBUG](selectByIdList                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==>  Preparing: SELECT * FROM t_book WHERE id IN ( ? , ? ) 
2020-04-23 19:00:37 [DEBUG](selectByIdList                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==> Parameters: 1(String), 2(String)
2020-04-23 19:00:37 [DEBUG](selectByIdList                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] <==      Total: 2
2020-04-23 19:00:37 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5bf59d04]
2020-04-23 19:00:37 [INFO ](BookServiceImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 榜单：
[Book(id=1, name=Python编程快速上手——让繁琐工作自动化（异步图书）, author=斯维加特(Al Sweigart)，王海鹏, price=￥21.99, src=https://images-cn.ssl-images-amazon.com/images/I/51HZLuA0ABL._SX260_.jpg, remark=如今，人们面临的大多数任务都可以通过编写计算机软件来完成。Python是一种解释型、面向对象、动态数据类型的高级程序设计语言。通过Python编程，我们能够解决现实生活中的很多任务。
本书是一本面向实践的Python编程实用指南。本书的目的，不仅是介绍Python语言的基础知识，而且还通过项目实践教会读者如何应用这些知识和技能。本书的首部分介绍了基本Python编程概念，第二部分介绍), Book(id=2, name=Python网络爬虫技术, author=江吉彬，张良均, price=￥24.70, src=https://images-cn.ssl-images-amazon.com/images/I/41cfMQfa2RL.jpg, remark=张良均，信息系统项目管理师，泰迪杯全国大学生数据挖掘竞赛（www.tipdm.org）发起人。华南师范大学、广东工业大学兼职教授，广东省工业与应用数学学会理事。兼有大型高科技企业和高校的工作经历，主要从事大数据挖掘及其应用的策划、研发及咨询培训。全国计算机技术与软件专业技术资格（水平）考试继续教育和CDA数据分析师培训讲师。发表数据挖掘相关论文数20余篇，已取得国家发明专利12项，主)]
2020-04-23 19:00:37 [INFO ](BookServiceImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ============================
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:37 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=22) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:37 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](RequestResponseBodyMethodProcessor) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using 'application/json', given [application/json, text/plain, */*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-04-23 19:00:38 [DEBUG](RequestResponseBodyMethodProcessor) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Writing [ResultDto(code=20000, msg=查询成功！, data=BookVo(books=[Book(id=1, name=Python编程快速上手——让繁琐工作自动化（异步图书）, au (truncated)...]
2020-04-23 19:00:38 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Completed 200 OK
2020-04-23 19:00:38 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:38 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:38 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=88) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=54) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:38 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=23) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:38 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=89) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=55) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=24) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=90) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=56) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=25) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:39 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:39 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:39 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 0 for partition book-0
2020-04-23 19:00:39 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=91) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=57) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=26) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=92) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=27) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:40 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=58) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:40 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=93) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=28) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=59) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=94) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=29) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:41 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=60) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:41 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:42 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:42 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=95) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=30) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=61) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=96) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:42 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=31) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:42 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=62) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:43 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:43 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=97) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=32) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:43 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=63) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:43 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:44 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:44 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1557143d4991f864843161f886586f4b.
2020-04-23 19:00:44 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1557143d4991f864843161f886586f4b.
2020-04-23 19:00:44 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 560bac02-865d-43cf-9365-b5c17bf4a4c2.
2020-04-23 19:00:44 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance e3a1aaa9ed77405f70e42daf9caa5ef6: SlotReport{slotsStatus=[SlotStatus{slotID=560bac02-865d-43cf-9365-b5c17bf4a4c2_0, resourceProfile=ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationID=717af0e4296be25acde6c7d90d85f53e, jobID=ad36c851e62a2a17ea029f70b9e78c4a}]}.
2020-04-23 19:00:44 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from bf8e99d89d910b016909166ae5ce9cc1.
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=98) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=33) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:44 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from bf8e99d89d910b016909166ae5ce9cc1.
2020-04-23 19:00:44 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 560bac02-865d-43cf-9365-b5c17bf4a4c2.
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=64) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=99) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=34) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:44 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 0 for partition book-0
2020-04-23 19:00:44 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:44 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=65) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:44 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=100) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=35) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=66) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=101) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:45 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=36) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:45 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=67) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=37) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:46 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:46 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 1ae9b6d94b76e3ffb9af61e34e38d214.
2020-04-23 19:00:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:46 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance fa41931cb237a0d8f807e13392a773d1: SlotReport{slotsStatus=[SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3273e2c96b6c175720d2ac6a41cb9b69, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=a746278421e81a200e3e711bd55f79b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9c80a0a8bea77c101ca67025ba67a41d, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=0626db8ad338c8acae965455a1c1f8b3, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=7fdb5a165f28137eb3f2370c5c5168fb, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=302fd85a4551294dea1a4b6533203048, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f975e64a3787208d80fb979ad63e9b50, jobID=77d397c647a53cd8ed694029397cec7d}, SlotStatus{slotID=aecf994c-886e-4ef7-ac4b-f2532302002d_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=aa58d9c04b3ffd199f2860a9ff0e34fc, jobID=77d397c647a53cd8ed694029397cec7d}]}.
2020-04-23 19:00:46 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=68) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=102) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:46 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 3c4bcf72c58942254fa887e0c7109988.
2020-04-23 19:00:46 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from aecf994c-886e-4ef7-ac4b-f2532302002d.
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:46 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=38) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:46 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:47 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:47 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 308338456c9928e7514112c645907f29.
2020-04-23 19:00:47 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:47 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:47 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received slot report from instance 01cccd0a8515cdcf17b605867d5a4617: SlotReport{slotsStatus=[SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_0, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=32fc9a10bd028cb75ae5bd1124fc5fb6, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_1, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=006533f19a6cbdc6720315c99f88cd21, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_2, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=71c1aaf49bb6b32ade179b74dc58569a, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_3, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=3838da10f636b26bdc6a3152dc503b9b, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_4, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=9363ffcc6be5fef95228334e4e531199, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_5, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=95f27efe50fa05a572972e60b2461e9d, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_6, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=b6c267da26204b5268ff3b3606794913, jobID=05a741b535c25ce2c2dfbf46b67fa073}, SlotStatus{slotID=b370fe99-e079-4822-a0ee-66aefd15310b_7, resourceProfile=ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationID=f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobID=05a741b535c25ce2c2dfbf46b67fa073}]}.
2020-04-23 19:00:47 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Slot Pool Status:
	status: connected to akka://flink/user/resourcemanager
	registered TaskManagers: [b370fe99-e079-4822-a0ee-66aefd15310b]
	available slots: []
	allocated slots: [[AllocatedSlot 3838da10f636b26bdc6a3152dc503b9b @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 3, AllocatedSlot 71c1aaf49bb6b32ade179b74dc58569a @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 2, AllocatedSlot 95f27efe50fa05a572972e60b2461e9d @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 5, AllocatedSlot 9363ffcc6be5fef95228334e4e531199 @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 4, AllocatedSlot f70a0d2dc6fe12eb690ddf0fa1fdb0e2 @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 7, AllocatedSlot b6c267da26204b5268ff3b3606794913 @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 6, AllocatedSlot 32fc9a10bd028cb75ae5bd1124fc5fb6 @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 0, AllocatedSlot 006533f19a6cbdc6720315c99f88cd21 @ b370fe99-e079-4822-a0ee-66aefd15310b @ 127.0.0.1 (dataPort=-1) - 1]]
	pending requests: []
	}

2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=69) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=103) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trigger heartbeat request.
2020-04-23 19:00:47 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat request from 89123140e8c9aea48d5f0aeaa2f09d79.
2020-04-23 19:00:47 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received heartbeat from b370fe99-e079-4822-a0ee-66aefd15310b.
2020-04-23 19:00:47 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:47 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 0 for partition book-0
2020-04-23 19:00:47 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=39) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=70) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:47 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=104) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:47 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=40) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=71) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=105) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 0 for partition book-0
2020-04-23 19:00:48 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=41) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=106) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:48 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=72) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:48 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=42) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=107) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=73) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=43) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:49 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:49 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:49 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 0 for partition book-0
2020-04-23 19:00:49 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Completed asynchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=0, metadata=''}}
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=108) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=74) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=44) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=109) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=75) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:50 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=45) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:50 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=110) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=76) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] GET "/book/doGetDetail?bookId=1&userId=1", parameters={masked}
2020-04-23 19:00:51 [DEBUG](RequestMappingHandlerMapping  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Mapped to com.example.graduationproject.web.controller.BookController#getBookDetail(String, String)
2020-04-23 19:00:51 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ***************************
2020-04-23 19:00:51 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] url : /book/doGetDetail
2020-04-23 19:00:51 [INFO ](AuthInterceptor               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ***************************
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=46) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [INFO ](ProducerConfig                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ProducerConfig values: 
	acks = 1
	batch.size = 65536
	bootstrap.servers = [aliyun:9092]
	buffer.memory = 524288
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bufferpool-wait-time
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name buffer-exhausted-records
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name errors
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name produce-throttle-time
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-closed:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name connections-created:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-reauthentication:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name successful-authentication-no-reauth:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-authentication:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name failed-reauthentication:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name reauthentication-latency:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent-received:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-sent:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name bytes-received:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name select-time:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name io-time:
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name batch-size
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name compression-rate
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name queue-time
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name request-time
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name records-per-request
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name record-retries
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name record-size
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name batch-split-rate
2020-04-23 19:00:51 [DEBUG](Sender                        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Starting Kafka producer I/O thread.
2020-04-23 19:00:51 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka version: 2.3.1
2020-04-23 19:00:51 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka commitId: 18a913733fb71c01
2020-04-23 19:00:51 [INFO ](AppInfoParser                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kafka startTimeMs: 1587639651541
2020-04-23 19:00:51 [DEBUG](KafkaProducer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Kafka producer started
2020-04-23 19:00:51 [DEBUG](DefaultKafkaProducerFactory   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Created new Producer: CloseSafeProducer [delegate=org.apache.kafka.clients.producer.KafkaProducer@558dac39]
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Initialize connection to node aliyun:9092 (id: -1 rack: null) for sending metadata request
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Initiating connection to node aliyun:9092 (id: -1 rack: null) using address aliyun/39.105.201.221
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-sent
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.bytes-received
2020-04-23 19:00:51 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node--1.latency
2020-04-23 19:00:51 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=111) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=77) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Completed connection to node -1. Fetching API versions.
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Initiating API versions fetch from node -1.
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=47) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:51 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Recorded API versions for node -1: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 10 [usable: 10], ListOffsets(2): 0 to 4 [usable: 4], Metadata(3): 0 to 7 [usable: 7], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 6], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 2], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='book')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node aliyun:9092 (id: -1 rack: null)
2020-04-23 19:00:51 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Using older server API v7 to send METADATA {topics=[{name=book}],allow_auto_topic_creation=true} with correlation id 1 to node -1
2020-04-23 19:00:52 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Updating last seen epoch from null to 0 for partition book-0
2020-04-23 19:00:52 [INFO ](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Cluster ID: ywiXp-SQSUaWes-7n-R4dg
2020-04-23 19:00:52 [DEBUG](Metadata                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = ywiXp-SQSUaWes-7n-R4dg, nodes = [aliyun:9092 (id: 0 rack: null)], partitions = [Partition(topic = book, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = aliyun:9092 (id: 0 rack: null))}
2020-04-23 19:00:52 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Initiating connection to node aliyun:9092 (id: 0 rack: null) using address aliyun/39.105.201.221
2020-04-23 19:00:52 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Creating a new SqlSession
2020-04-23 19:00:52 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@472734be] was not registered for synchronization because synchronization is not active
2020-04-23 19:00:52 [DEBUG](DataSourceUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Fetching JDBC Connection from DataSource
2020-04-23 19:00:52 [DEBUG](SpringManagedTransaction      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@7e3556ef] will not be managed by Spring
2020-04-23 19:00:52 [DEBUG](findBookById                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==>  Preparing: SELECT * FROM t_book WHERE id = ? 
2020-04-23 19:00:52 [DEBUG](findBookById                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ==> Parameters: 1(String)
2020-04-23 19:00:52 [DEBUG](findBookById                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] <==      Total: 1
2020-04-23 19:00:52 [DEBUG](SqlSessionUtils               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@472734be]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name node-0.latency
2020-04-23 19:00:52 [DEBUG](Selector                      ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2020-04-23 19:00:52 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
2020-04-23 19:00:52 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Initiating API versions fetch from node 0.
2020-04-23 19:00:52 [DEBUG](NetworkClient                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 7 [usable: 7], Fetch(1): 0 to 10 [usable: 10], ListOffsets(2): 0 to 4 [usable: 4], Metadata(3): 0 to 7 [usable: 7], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 6 [usable: 6], OffsetFetch(9): 0 to 5 [usable: 5], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 3 [usable: 3], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 2 [usable: 2], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 2 [usable: 2], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1], ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.records-per-batch
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.bytes
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.compression-rate
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.record-retries
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Added sensor with name topic.book.record-errors
2020-04-23 19:00:52 [DEBUG](Groups                        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:]  Creating new Groups object
2020-04-23 19:00:52 [DEBUG](NativeCodeLoader              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Trying to load the custom-built native-hadoop library...
2020-04-23 19:00:52 [DEBUG](NativeCodeLoader              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Loaded the native-hadoop library
2020-04-23 19:00:52 [DEBUG](JniBasedUnixGroupsMapping     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using JniBasedUnixGroupsMapping for Group resolution
2020-04-23 19:00:52 [DEBUG](JniBasedUnixGroupsMappingWithFallback) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 0 response partition(s), 1 implied partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 0 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=112) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(book-0)) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Node 0 sent an incremental fetch response for session 927511445 with 1 response partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=1, lastStableOffset = 1, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=85)
2020-04-23 19:00:52 [INFO ](KafkaServiceImpl              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] kafka send msg success, topic = book, data = 1,1,1587639651,pv
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Node 0 sent an incremental fetch response for session 1179162920 with 1 response partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=1, lastStableOffset = 1, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=85)
2020-04-23 19:00:52 [DEBUG](Groups                        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 1 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Built incremental fetch (sessionId=1179162920, epoch=78) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(book-0), toForget=(), implied=()) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 1 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [INFO ](LogMapFunction                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] flink input stream -> 1,1,1587639651,pv
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Built incremental fetch (sessionId=927511445, epoch=48) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(book-0), toForget=(), implied=()) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Raising WakeupException in response to user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Sending synchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=1, metadata=''}}
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Raising WakeupException in response to user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Sending synchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=1, metadata=''}}
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Node 0 sent an incremental fetch response for session 592814464 with 1 response partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Fetch READ_UNCOMMITTED at offset 0 for partition book-0 returned fetch data (error=NONE, highWaterMark=1, lastStableOffset = 1, logStartOffset = 0, abortedTransactions = null, recordsSizeInBytes=85)
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:22)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:15)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (8/8) network resources (state: FAILED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:14)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:11)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:310)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:409)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) [FAILED]
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) network resources (state: FAILED).
2020-04-23 19:00:52 [DEBUG](TaskEventDispatcher           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] unregistering 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a
2020-04-23 19:00:52 [DEBUG](ResultPartition               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a): Releasing ReleaseOnConsumptionResultPartition 50696d2a021f10840937747beac58662@ecbe111afa485d5e6c51b8ef01f3565a [PIPELINED_BOUNDED, 1 subpartitions, 1 pending consumptions].
2020-04-23 19:00:52 [DEBUG](PipelinedSubpartition         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a): Released PipelinedSubpartition#0 [number of buffers: 0 (0 bytes), number of buffers in backlog: 0, finished? false, read view? false].
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Released partition 50696d2a021f10840937747beac58662 produced by ecbe111afa485d5e6c51b8ef01f3565a.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) [FAILED]
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map (8/8) e4cbdd7945b19ed17cae715d6c20ca54.
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Added READ_UNCOMMITTED fetch request for partition book-0 at offset 1 to node aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [DEBUG](FetchSessionHandler           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Built incremental fetch (sessionId=592814464, epoch=113) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
2020-04-23 19:00:52 [DEBUG](Fetcher                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(book-0), toForget=(), implied=()) to broker aliyun:9092 (id: 0 rack: null)
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) ecbe111afa485d5e6c51b8ef01f3565a.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Raising WakeupException in response to user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Sending synchronous auto-commit of offsets {book-0=OffsetAndMetadata{offset=1, metadata=''}}
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (e4cbdd7945b19ed17cae715d6c20ca54) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:22)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:15)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{af7354fc8313bcdb225bd0bb44e9ff26}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [aa58d9c04b3ffd199f2860a9ff0e34fc] to available slots
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:19)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:16)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (8/8) network resources (state: FAILED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) [FAILED]
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Calculating tasks to restart to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_7.
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 1 tasks should be restarted to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_7. 
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map (8/8) 6d34fcd396e69f559abbef220cee77b4.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (8/8) (6d34fcd396e69f559abbef220cee77b4) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:19)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:16)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map -> Timestamps/Watermarks (1/1) (ecbe111afa485d5e6c51b8ef01f3565a) switched from RUNNING to FAILED.
java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:14)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:11)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:310)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:409)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{da3a98ded62549242a1c9e2b32cb1e61}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Calculating tasks to restart to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_0.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Log message receive (77d397c647a53cd8ed694029397cec7d) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:22)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:15)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 3 tasks should be restarted to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_0. 
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [f70a0d2dc6fe12eb690ddf0fa1fdb0e2] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea).
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Calculating tasks to restart to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_7.
2020-04-23 19:00:52 [INFO ](RestartPipelinedRegionStrategy) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] 1 tasks should be restarted to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_7. 
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Committed offset 1 for partition book-0
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Committed offset 1 for partition book-0
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:14)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:11)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:310)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:409)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-2, groupId=topItem] Kafka consumer has been closed
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Item History Task (05a741b535c25ce2c2dfbf46b67fa073) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:19)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:16)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25).
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b).
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae).
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20).
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f).
2020-04-23 19:00:52 [DEBUG](SingleInputGate               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@24390ce3.
2020-04-23 19:00:52 [DEBUG](SingleInputGate               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Releasing org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate@7dbf880c.
2020-04-23 19:00:52 [DEBUG](ResultPartition               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] ReleaseOnConsumptionResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions]: Received consumed notification for subpartition 0.
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Received consume notification from ReleaseOnConsumptionResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2020-04-23 19:00:52 [DEBUG](ResultPartition               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Releasing ReleaseOnConsumptionResultPartition e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e [PIPELINED_BOUNDED, 1 subpartitions, 0 pending consumptions].
2020-04-23 19:00:52 [DEBUG](PipelinedSubpartition         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e): Released PipelinedSubpartition#0 [number of buffers: 0 (0 bytes), number of buffers in backlog: 0, finished? false, read view? false].
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Released partition e1b4dd0da7c192b5822716ee50551b91 produced by 217ef54de6b23a12673bdf65df55161e.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f).
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) [CANCELED]
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76).
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) network resources (state: CANCELED).
2020-04-23 19:00:52 [DEBUG](TaskEventDispatcher           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] unregistering e1b4dd0da7c192b5822716ee50551b91@217ef54de6b23a12673bdf65df55161e
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Committed offset 1 for partition book-0
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [WARN ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Error while canceling task.
org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException
	at org.apache.flink.streaming.connectors.kafka.internal.Handover.close(Handover.java:182)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.cancel(KafkaFetcher.java:177)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:763)
	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:147)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:136)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:602)
	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1355)
	at java.lang.Thread.run(Thread.java:748)
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) c59849536cef20558f4972e95ec78d65.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) [CANCELED]
2020-04-23 19:00:52 [WARN ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Error while canceling task.
org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException
	at org.apache.flink.streaming.connectors.kafka.internal.Handover.close(Handover.java:182)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.cancel(KafkaFetcher.java:177)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:763)
	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:147)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:136)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:602)
	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1355)
	at java.lang.Thread.run(Thread.java:748)
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [poison mail].
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) 217ef54de6b23a12673bdf65df55161e.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef).
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) (c59849536cef20558f4972e95ec78d65) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex KeyedProcess -> (Sink: Print to Std. Out, Sink: Unnamed) (1/1) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e).
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Attempting to cancel task Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from RUNNING to CANCELING.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Triggering cancellation of task code Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100).
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=log] Received user wakeup
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) (217ef54de6b23a12673bdf65df55161e) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Window(SlidingEventTimeWindows(3600000, 300000), EventTimeTrigger, CountAgg, WindowResult) (1/1) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{6981f5be481d6237fd29f2b595336954}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [poison mail].
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (1/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) [CANCELED]
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [717af0e4296be25acde6c7d90d85f53e] to available slots
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job TopN Job (ad36c851e62a2a17ea029f70b9e78c4a) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:14)
	at com.example.graduationproject.map.TopItemMapFunction.map(TopItemMapFunction.java:11)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:310)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:409)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [INFO ](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping checkpoint coordinator for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [INFO ](StandaloneCompletedCheckpointStore) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (2/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (1/8) 97ff9825aaa9bfe7e4770641ac5a65ea.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Received user wakeup
2020-04-23 19:00:52 [WARN ](StreamTask                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Error while canceling task.
org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException
	at org.apache.flink.streaming.connectors.kafka.internal.Handover.close(Handover.java:182)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.cancel(KafkaFetcher.java:177)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.cancel(FlinkKafkaConsumerBase.java:763)
	at org.apache.flink.streaming.api.operators.StreamSource.cancel(StreamSource.java:147)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.cancelTask(SourceStreamTask.java:136)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.cancel(StreamTask.java:602)
	at org.apache.flink.runtime.taskmanager.Task$TaskCanceler.run(Task.java:1355)
	at java.lang.Thread.run(Thread.java:748)
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-10, groupId=log] Received user wakeup
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [poison mail].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (4/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) [CANCELED]
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (97ff9825aaa9bfe7e4770641ac5a65ea) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (1/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{a3cf5499568b1ef0d1507fac81539b9a}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [3273e2c96b6c175720d2ac6a41cb9b69] to available slots
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (1/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (1/8) cf54fafc9399d0bba840fe85ad9b7ee0.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (6/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) [CANCELED]
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (3/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (1/8) (cf54fafc9399d0bba840fe85ad9b7ee0) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (1/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{76ce7f89d5684c29c1bb862b27e6e330}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [32fc9a10bd028cb75ae5bd1124fc5fb6] to available slots
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (4/8) f8f5c4467240550c200b682746d8590b.
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (7/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (5/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down Flink Mini Cluster
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job ad36c851e62a2a17ea029f70b9e78c4a reached globally terminal state FAILED.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down rest endpoint.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 1557143d4991f864843161f886586f4b.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=log] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerCoordinator           ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Sending synchronous auto-commit of offsets {}
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping the JobMaster for job TopN Job(ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect TaskExecutor 560bac02-865d-43cf-9365-b5c17bf4a4c2 because: Stopping JobMaster for job TopN Job(ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing TaskExecutor connection 560bac02-865d-43cf-9365-b5c17bf4a4c2 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationId: 717af0e4296be25acde6c7d90d85f53e, jobId: ad36c851e62a2a17ea029f70b9e78c4a).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending SlotPool.
2020-04-23 19:00:52 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Unregister TaskManager e3a1aaa9ed77405f70e42daf9caa5ef6 from the SlotManager.
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 1557143d4991f864843161f886586f4b.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:350)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (3/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) [CANCELED]
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 717af0e4296be25acde6c7d90d85f53e because: Stopping JobMaster for job TopN Job(ad36c851e62a2a17ea029f70b9e78c4a).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 717af0e4296be25acde6c7d90d85f53e.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 717af0e4296be25acde6c7d90d85f53e.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect job manager b439895615782409f4e7c8d953664998@akka://flink/user/jobmanager_1 for job ad36c851e62a2a17ea029f70b9e78c4a from the resource manager.
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 717af0e4296be25acde6c7d90d85f53e.
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SlotPool.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) [CANCELED]
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (f8f5c4467240550c200b682746d8590b) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (4/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{ad966e514ac9e992bc2202c727f22b08}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [0626db8ad338c8acae965455a1c1f8b3] to available slots
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (6/8) 1487880cbd096edeb628aa46a82071ae.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (3/8) b6663df1c73f3748851416b98074a779.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (7/8) a91a7c7188aa765787ea10c0b3fbbc76.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader null@null.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-13, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (5/8) a06777b6f6119c3401c7fb7a7d04a2f9.
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job ad36c851e62a2a17ea029f70b9e78c4a. Address: null, leader id: null.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager for job ad36c851e62a2a17ea029f70b9e78c4a with leader id b439895615782409f4e7c8d953664998 lost leadership.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (2/8) e11b3a9481cfbf8542683eda1b684d25.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (5/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) [CANCELED]
2020-04-23 19:00:52 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Discard job leader lost leadership for outdated leader b439895615782409f4e7c8d953664998 for job ad36c851e62a2a17ea029f70b9e78c4a.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (3/8) 5f3eb6adac58f67ebc22f6c20ce5451f.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (1487880cbd096edeb628aa46a82071ae) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (6/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (5/8) d484a82161c74a5241a6e1efa3bc7e1f.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{56f2fb6a0c703663ecd1673fc9a98eea}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [302fd85a4551294dea1a4b6533203048] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (5f3eb6adac58f67ebc22f6c20ce5451f) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (3/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (3/8) (b6663df1c73f3748851416b98074a779) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{d77fa885f2c98c0cd47b011fc5c6f4da}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [71c1aaf49bb6b32ade179b74dc58569a] to available slots
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (3/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{48a3eb21fc31144a752e9359c55031ab}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [9c80a0a8bea77c101ca67025ba67a41d] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (a91a7c7188aa765787ea10c0b3fbbc76) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (7/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{c955ab5f7f815ea12d6ef03192de925b}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [f975e64a3787208d80fb979ad63e9b50] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (a06777b6f6119c3401c7fb7a7d04a2f9) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (5/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{7e1aa5f1358f052e8fc1b07747942fba}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [7fdb5a165f28137eb3f2370c5c5168fb] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (e11b3a9481cfbf8542683eda1b684d25) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (2/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{b0c9292b64d962181d91f3a0fb15f594}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [a746278421e81a200e3e711bd55f79b3] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Log message receive (77d397c647a53cd8ed694029397cec7d) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:22)
	at com.example.graduationproject.map.LogMapFunction.map(LogMapFunction.java:15)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping checkpoint coordinator for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:52 [INFO ](StandaloneCompletedCheckpointStore) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (5/8) (d484a82161c74a5241a6e1efa3bc7e1f) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (5/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{3df32867f36450c1f5bc779373b28db3}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-closed:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name connections-created:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name successful-authentication:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (7/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close JobManager connection for job ad36c851e62a2a17ea029f70b9e78c4a.
org.apache.flink.util.FlinkException: Stopping JobMaster for job TopN Job(ad36c851e62a2a17ea029f70b9e78c4a).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:343)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not reconnect to the JobMaster akka://flink/user/jobmanager_1.
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (2/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (2/8) 85446e96075abdf74403e0674dc5db20.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (6/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) [CANCELED]
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-11, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-12, groupId=history] Received user wakeup
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name failed-authentication:
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [9363ffcc6be5fef95228334e4e531199] to available slots
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](ConsumerNetworkClient         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Received user wakeup
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](MailboxProcessor              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the mailbox dropped mails [Report throwable org.apache.flink.streaming.connectors.kafka.internal.Handover$ClosedException].
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-14, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (6/8) 7bf141c9e5ab52106e4c6018f1fbb84e.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (7/8) 5ad8ca58b0acc826d506e86b31fad100.
2020-04-23 19:00:52 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down Flink Mini Cluster
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down rest endpoint.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job 77d397c647a53cd8ed694029397cec7d reached globally terminal state FAILED.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-9, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent-received:
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 1ae9b6d94b76e3ffb9af61e34e38d214.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-sent:
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (2/8) (85446e96075abdf74403e0674dc5db20) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (2/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{be1a8793e0597400aa7f734a0bc7600f}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [006533f19a6cbdc6720315c99f88cd21] to available slots
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Freeing task resources for Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef).
2020-04-23 19:00:52 [DEBUG](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Release task Source: Custom Source -> Map (4/8) network resources (state: CANCELED).
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (6/8) (7bf141c9e5ab52106e4c6018f1fbb84e) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (6/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{a30ba7a292ec54f217758def1b27d538}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [95f27efe50fa05a572972e60b2461e9d] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (7/8) (5ad8ca58b0acc826d506e86b31fad100) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (7/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{634653b397ed04e4fcf8bf91902788d1}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [b6c267da26204b5268ff3b3606794913] to available slots
2020-04-23 19:00:52 [INFO ](Task                          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) [CANCELED]
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (4/8) 21df1873138a49ae09cae5ce4cb0f5ef.
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-15, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing TaskExecutor connection aecf994c-886e-4ef7-ac4b-f2532302002d because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Unregister TaskManager fa41931cb237a0d8f807e13392a773d1 from the SlotManager.
2020-04-23 19:00:52 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping the JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect TaskExecutor aecf994c-886e-4ef7-ac4b-f2532302002d because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: a746278421e81a200e3e711bd55f79b3, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending SlotPool.
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 1ae9b6d94b76e3ffb9af61e34e38d214.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:350)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SlotPool.
2020-04-23 19:00:52 [DEBUG](MutableMetricsFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Source: Custom Source -> Map (4/8) (21df1873138a49ae09cae5ce4cb0f5ef) switched from CANCELING to CANCELED.
2020-04-23 19:00:52 [DEBUG](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Ignoring transition of vertex Source: Custom Source -> Map (4/8) - execution #0 to FAILED while being CANCELED.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing slot [SlotRequestId{56158afbca7b57e85618e707b8425cf8}] because: Release multi task slot because all children have been released.
2020-04-23 19:00:52 [DEBUG](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Adding returned slot [3838da10f636b26bdc6a3152dc503b9b] to available slots
2020-04-23 19:00:52 [INFO ](ExecutionGraph                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job Item History Task (05a741b535c25ce2c2dfbf46b67fa073) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:110)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:76)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:192)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:186)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:180)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:484)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:380)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 4
	at com.example.graduationproject.util.LogToEntity.getEntity(LogToEntity.java:24)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:19)
	at com.example.graduationproject.map.UserHistoryMapFunction.map(UserHistoryMapFunction.java:16)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:41)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:641)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:616)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:596)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:730)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:708)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collect(StreamSourceContexts.java:104)
	at org.apache.flink.streaming.api.operators.StreamSourceContexts$NonTimestampContext.collectWithTimestamp(StreamSourceContexts.java:111)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:398)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.emitRecord(KafkaFetcher.java:187)
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:152)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:738)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:196)
2020-04-23 19:00:52 [INFO ](CheckpointCoordinator         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping checkpoint coordinator for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 19:00:52 [INFO ](StandaloneCompletedCheckpointStore) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down
2020-04-23 19:00:52 [INFO ](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down TaskExecutorLocalStateStoresManager.
2020-04-23 19:00:52 [DEBUG](IOManager                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down I/O manager.
2020-04-23 19:00:52 [DEBUG](MutableMetricsFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2020-04-23 19:00:52 [DEBUG](MutableMetricsFactory         ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2020-04-23 19:00:52 [DEBUG](MetricsSystemImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] UgiMetrics, User and group related metrics
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name bytes-received:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name select-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name io-time:
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node--1.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-2147483647.latency
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-sent
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.bytes-received
2020-04-23 19:00:52 [DEBUG](Metrics                       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removed sensor with name node-0.latency
2020-04-23 19:00:52 [DEBUG](KafkaConsumer                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] [Consumer clientId=consumer-16, groupId=history] Kafka consumer has been closed
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:2, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 9c80a0a8bea77c101ca67025ba67a41d, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:3, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 0626db8ad338c8acae965455a1c1f8b3, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:6, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: f975e64a3787208d80fb979ad63e9b50, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 3273e2c96b6c175720d2ac6a41cb9b69, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:7, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: aa58d9c04b3ffd199f2860a9ff0e34fc, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:5, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 302fd85a4551294dea1a4b6533203048, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:4, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 7fdb5a165f28137eb3f2370c5c5168fb, jobId: 77d397c647a53cd8ed694029397cec7d).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](MiniCluster                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down Flink Mini Cluster
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down rest endpoint.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Job 05a741b535c25ce2c2dfbf46b67fa073 reached globally terminal state FAILED.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 308338456c9928e7514112c645907f29.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:3, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 3838da10f636b26bdc6a3152dc503b9b, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing TaskExecutor connection b370fe99-e079-4822-a0ee-66aefd15310b because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Unregister TaskManager 01cccd0a8515cdcf17b605867d5a4617 from the SlotManager.
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect TaskExecutor b370fe99-e079-4822-a0ee-66aefd15310b because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [INFO ](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping the JobMaster for job Item History Task(05a741b535c25ce2c2dfbf46b67fa073).
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 32fc9a10bd028cb75ae5bd1124fc5fb6, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending SlotPool.
2020-04-23 19:00:52 [DEBUG](JobMaster                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close ResourceManager connection 308338456c9928e7514112c645907f29.
org.apache.flink.util.FlinkException: JobManager is shutting down.
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:350)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](SlotPoolImpl                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SlotPool.
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:2, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 71c1aaf49bb6b32ade179b74dc58569a, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:6, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: b6c267da26204b5268ff3b3606794913, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 006533f19a6cbdc6720315c99f88cd21, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:4, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 9363ffcc6be5fef95228334e4e531199, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:5, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 95f27efe50fa05a572972e60b2461e9d, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect job manager 9a1e8323069e92802f3de9cc71f24c7d@akka://flink/user/jobmanager_1 for job 05a741b535c25ce2c2dfbf46b67fa073 from the resource manager.
2020-04-23 19:00:52 [DEBUG](TaskSlotTableImpl             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot TaskSlot(index:7, state:ACTIVE, resource profile: ResourceProfile{managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: f70a0d2dc6fe12eb690ddf0fa1fdb0e2, jobId: 05a741b535c25ce2c2dfbf46b67fa073).
org.apache.flink.util.FlinkException: Closing task slot table
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.closeAsync(TaskSlotTableImpl.java:160)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:375)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader null@null.
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 05a741b535c25ce2c2dfbf46b67fa073. Address: null, leader id: null.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager for job 05a741b535c25ce2c2dfbf46b67fa073 with leader id 9a1e8323069e92802f3de9cc71f24c7d lost leadership.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 3838da10f636b26bdc6a3152dc503b9b because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 3838da10f636b26bdc6a3152dc503b9b.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 3838da10f636b26bdc6a3152dc503b9b.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 3838da10f636b26bdc6a3152dc503b9b.
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Disconnect job manager 8f238c0789f5be6700d2e1a5933046e3@akka://flink/user/jobmanager_1 for job 77d397c647a53cd8ed694029397cec7d from the resource manager.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 0626db8ad338c8acae965455a1c1f8b3 because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 0626db8ad338c8acae965455a1c1f8b3.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 0626db8ad338c8acae965455a1c1f8b3.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 0626db8ad338c8acae965455a1c1f8b3.
2020-04-23 19:00:52 [DEBUG](JobLeaderIdService            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Found a new job leader null@null.
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] New leader information for job 77d397c647a53cd8ed694029397cec7d. Address: null, leader id: null.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] JobManager for job 77d397c647a53cd8ed694029397cec7d with leader id 8f238c0789f5be6700d2e1a5933046e3 lost leadership.
2020-04-23 19:00:52 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Discard job leader lost leadership for outdated leader 8f238c0789f5be6700d2e1a5933046e3 for job 77d397c647a53cd8ed694029397cec7d.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 3273e2c96b6c175720d2ac6a41cb9b69 because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 3273e2c96b6c175720d2ac6a41cb9b69.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 3273e2c96b6c175720d2ac6a41cb9b69.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 3273e2c96b6c175720d2ac6a41cb9b69.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id f975e64a3787208d80fb979ad63e9b50 because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id f975e64a3787208d80fb979ad63e9b50.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for f975e64a3787208d80fb979ad63e9b50.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id f975e64a3787208d80fb979ad63e9b50.
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-b4e25467-edf3-4a62-9219-8924e7929db3
2020-04-23 19:00:52 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the network environment and its components.
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down network connection manager
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down intermediate result partition manager
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing 0 partitions because of shutdown.
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful shutdown.
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-9cf3bc7b-0700-46bd-98b4-9ff5d2b9f2f1
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 9c80a0a8bea77c101ca67025ba67a41d because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 9c80a0a8bea77c101ca67025ba67a41d.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 9c80a0a8bea77c101ca67025ba67a41d.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 9c80a0a8bea77c101ca67025ba67a41d.
2020-04-23 19:00:52 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the kvState service and its components.
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id aa58d9c04b3ffd199f2860a9ff0e34fc because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id aa58d9c04b3ffd199f2860a9ff0e34fc.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for aa58d9c04b3ffd199f2860a9ff0e34fc.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id aa58d9c04b3ffd199f2860a9ff0e34fc.
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removing cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-web-ui
2020-04-23 19:00:52 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] removed file cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-0761e993-d94d-40d2-8951-afbd876b571f
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [DEBUG](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Discard job leader lost leadership for outdated leader 9a1e8323069e92802f3de9cc71f24c7d for job 05a741b535c25ce2c2dfbf46b67fa073.
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down complete.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 302fd85a4551294dea1a4b6533203048 because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 302fd85a4551294dea1a4b6533203048.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 302fd85a4551294dea1a4b6533203048.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 302fd85a4551294dea1a4b6533203048.
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removing cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-web-ui
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 7fdb5a165f28137eb3f2370c5c5168fb because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 7fdb5a165f28137eb3f2370c5c5168fb.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 7fdb5a165f28137eb3f2370c5c5168fb.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 7fdb5a165f28137eb3f2370c5c5168fb.
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down complete.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id a746278421e81a200e3e711bd55f79b3 because: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id a746278421e81a200e3e711bd55f79b3.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for a746278421e81a200e3e711bd55f79b3.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id a746278421e81a200e3e711bd55f79b3.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 71c1aaf49bb6b32ade179b74dc58569a because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 71c1aaf49bb6b32ade179b74dc58569a.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 71c1aaf49bb6b32ade179b74dc58569a.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 71c1aaf49bb6b32ade179b74dc58569a.
2020-04-23 19:00:52 [INFO ](DispatcherResourceManagerComponent) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing components.
2020-04-23 19:00:52 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SessionDispatcherLeaderProcess.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](BackPressureRequestCoordinator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down back pressure request coordinator.
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the SlotManager.
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending the SlotManager.
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-04-23 19:00:52 [INFO ](DispatcherResourceManagerComponent) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing components.
2020-04-23 19:00:52 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SessionDispatcherLeaderProcess.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close JobManager connection for job 77d397c647a53cd8ed694029397cec7d.
org.apache.flink.util.FlinkException: Stopping JobMaster for job Log message receive(77d397c647a53cd8ed694029397cec7d).
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:343)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 95f27efe50fa05a572972e60b2461e9d because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 95f27efe50fa05a572972e60b2461e9d.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 95f27efe50fa05a572972e60b2461e9d.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 95f27efe50fa05a572972e60b2461e9d.
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not reconnect to the JobMaster akka://flink/user/jobmanager_1.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 9363ffcc6be5fef95228334e4e531199 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 9363ffcc6be5fef95228334e4e531199.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 9363ffcc6be5fef95228334e4e531199.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 9363ffcc6be5fef95228334e4e531199.
2020-04-23 19:00:52 [INFO ](BackPressureRequestCoordinator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down back pressure request coordinator.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the SlotManager.
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending the SlotManager.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id f70a0d2dc6fe12eb690ddf0fa1fdb0e2.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id b6c267da26204b5268ff3b3606794913 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id b6c267da26204b5268ff3b3606794913.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for b6c267da26204b5268ff3b3606794913.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id b6c267da26204b5268ff3b3606794913.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 32fc9a10bd028cb75ae5bd1124fc5fb6.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 32fc9a10bd028cb75ae5bd1124fc5fb6.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Free slot with allocation id 006533f19a6cbdc6720315c99f88cd21 because: The TaskExecutor is shutting down.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not free slot for allocation id 006533f19a6cbdc6720315c99f88cd21.
org.apache.flink.runtime.taskexecutor.slot.SlotNotFoundException: Could not find slot for 006533f19a6cbdc6720315c99f88cd21.
	at org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl.freeSlot(TaskSlotTableImpl.java:367)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlotInternal(TaskExecutor.java:1480)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.freeSlot(TaskExecutor.java:884)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:279)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:194)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing local state under allocation id 006533f19a6cbdc6720315c99f88cd21.
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [INFO ](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down TaskExecutorLocalStateStoresManager.
2020-04-23 19:00:52 [DEBUG](IOManager                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down I/O manager.
2020-04-23 19:00:52 [DEBUG](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Close JobManager connection for job 05a741b535c25ce2c2dfbf46b67fa073.
org.apache.flink.util.FlinkException: The TaskExecutor is shutting down.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.onStop(TaskExecutor.java:359)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:509)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:175)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2020-04-23 19:00:52 [DEBUG](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Could not reconnect to the JobMaster akka://flink/user/jobmanager_1.
2020-04-23 19:00:52 [DEBUG](KerberosName                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Kerberos krb5 configuration not found, setting default realm to empty
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-bb06c901-c69a-4533-a04a-7c5cf8194f82
2020-04-23 19:00:52 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the network environment and its components.
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down network connection manager
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down intermediate result partition manager
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing 0 partitions because of shutdown.
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful shutdown.
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-88deca4b-e956-4309-8d93-1f4af1ab01c2
2020-04-23 19:00:52 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the kvState service and its components.
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] removed file cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-2e3e598e-293f-4365-b11d-61fd3ae8b2f6
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [DEBUG](UserGroupInformation          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] hadoop login
2020-04-23 19:00:52 [DEBUG](UserGroupInformation          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] hadoop login commit
2020-04-23 19:00:52 [INFO ](TaskExecutorLocalStateStoresManager) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down TaskExecutorLocalStateStoresManager.
2020-04-23 19:00:52 [DEBUG](IOManager                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down I/O manager.
2020-04-23 19:00:52 [DEBUG](UserGroupInformation          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] using local user:NTUserPrincipal: Zzwen
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Removing cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-web-ui
2020-04-23 19:00:52 [DEBUG](UserGroupInformation          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] UGI loginUser:Zzwen (auth:SIMPLE)
2020-04-23 19:00:52 [INFO ](DispatcherRestEndpoint        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down complete.
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-io-a5bab873-3b5d-4e85-a2de-1b695e46ef53
2020-04-23 19:00:52 [INFO ](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the network environment and its components.
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down network connection manager
2020-04-23 19:00:52 [DEBUG](NettyShuffleEnvironment       ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down intermediate result partition manager
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Releasing 0 partitions because of shutdown.
2020-04-23 19:00:52 [DEBUG](ResultPartitionManager        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Successful shutdown.
2020-04-23 19:00:52 [INFO ](StandaloneResourceManager     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2020-04-23 19:00:52 [INFO ](FileChannelManagerImpl        ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] FileChannelManager removed spill file directory C:\Users\Zzwen\AppData\Local\Temp\flink-netty-shuffle-aebe7087-fb5f-4a80-8998-0a5926eda35a
2020-04-23 19:00:52 [INFO ](DispatcherResourceManagerComponent) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing components.
2020-04-23 19:00:52 [INFO ](KvStateService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down the kvState service and its components.
2020-04-23 19:00:52 [INFO ](JobLeaderService              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stop job leader service.
2020-04-23 19:00:52 [INFO ](SessionDispatcherLeaderProcess) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping SessionDispatcherLeaderProcess.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](FileCache                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] removed file cache directory C:\Users\Zzwen\AppData\Local\Temp\flink-dist-cache-8ee05535-9e40-452c-bbdd-3e085f47c49b
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Closing the SlotManager.
2020-04-23 19:00:52 [INFO ](TaskExecutor                  ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped TaskExecutor akka://flink/user/taskmanager_0.
2020-04-23 19:00:52 [INFO ](SlotManagerImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Suspending the SlotManager.
2020-04-23 19:00:52 [INFO ](BackPressureRequestCoordinator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down back pressure request coordinator.
2020-04-23 19:00:52 [INFO ](StandaloneDispatcher          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped dispatcher akka://flink/user/dispatcher.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down remote daemon.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remote daemon shut down; proceeding with flushing remote transports.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down remote daemon.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down remote daemon.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remote daemon shut down; proceeding with flushing remote transports.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remote daemon shut down; proceeding with flushing remote transports.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting shut down.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting shut down.
2020-04-23 19:00:52 [INFO ](RemoteActorRefProvider$RemotingTerminator) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Remoting shut down.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:52 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] shutting down: StandardOutLogger
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopping Akka RPC service.
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:52 [DEBUG](EventStream                   ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] shutting down: StandardOutLogger
2020-04-23 19:00:52 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped BLOB server at 0.0.0.0:56430
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:52 [INFO ](PermanentBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped BLOB server at 0.0.0.0:56665
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:52 [INFO ](TransientBlobCache            ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Shutting down BLOB cache
2020-04-23 19:00:52 [INFO ](BlobServer                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped BLOB server at 0.0.0.0:56546
2020-04-23 19:00:52 [INFO ](AkkaRpcService                ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Stopped Akka RPC service.
2020-04-23 19:00:54 [INFO ](RecoverableZooKeeper          ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Process identifier=hconnection-0x2dd893d7 connecting to ZooKeeper ensemble=aliyun:2181
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:host.name=192.168.65.1
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.version=1.8.0_191
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.vendor=Oracle Corporation
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.home=C:\Program Files\Java\jdk1.8.0_191\jre
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.class.path=C:\Program Files\Java\jdk1.8.0_191\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_191\jre\lib\rt.jar;F:\毕业设计\graduation-project\graduation-project-web\target\classes;F:\毕业设计\graduation-project\graduation-project-flink-task\target\classes;F:\Maven\maven-jar\org\apache\flink\flink-streaming-java_2.12\1.10.0\flink-streaming-java_2.12-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-core\1.10.0\flink-core-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-annotations\1.10.0\flink-annotations-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-metrics-core\1.10.0\flink-metrics-core-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-shaded-asm-7\7.1-9.0\flink-shaded-asm-7-7.1-9.0.jar;F:\Maven\maven-jar\com\esotericsoftware\kryo\kryo\2.24.0\kryo-2.24.0.jar;F:\Maven\maven-jar\com\esotericsoftware\minlog\minlog\1.2\minlog-1.2.jar;F:\Maven\maven-jar\org\apache\commons\commons-compress\1.18\commons-compress-1.18.jar;F:\Maven\maven-jar\org\apache\flink\flink-runtime_2.12\1.10.0\flink-runtime_2.12-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-java\1.10.0\flink-java-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-queryable-state-client-java\1.10.0\flink-queryable-state-client-java-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-hadoop-fs\1.10.0\flink-hadoop-fs-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-shaded-netty\4.1.39.Final-9.0\flink-shaded-netty-4.1.39.Final-9.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-shaded-jackson\2.10.1-9.0\flink-shaded-jackson-2.10.1-9.0.jar;F:\Maven\maven-jar\org\javassist\javassist\3.24.0-GA\javassist-3.24.0-GA.jar;F:\Maven\maven-jar\org\scala-lang\scala-library\2.12.7\scala-library-2.12.7.jar;F:\Maven\maven-jar\com\typesafe\akka\akka-actor_2.12\2.5.21\akka-actor_2.12-2.5.21.jar;F:\Maven\maven-jar\com\typesafe\config\1.3.3\config-1.3.3.jar;F:\Maven\maven-jar\org\scala-lang\modules\scala-java8-compat_2.12\0.8.0\scala-java8-compat_2.12-0.8.0.jar;F:\Maven\maven-jar\com\typesafe\akka\akka-stream_2.12\2.5.21\akka-stream_2.12-2.5.21.jar;F:\Maven\maven-jar\org\reactivestreams\reactive-streams\1.0.3\reactive-streams-1.0.3.jar;F:\Maven\maven-jar\com\typesafe\ssl-config-core_2.12\0.3.7\ssl-config-core_2.12-0.3.7.jar;F:\Maven\maven-jar\org\scala-lang\modules\scala-parser-combinators_2.12\1.1.1\scala-parser-combinators_2.12-1.1.1.jar;F:\Maven\maven-jar\com\typesafe\akka\akka-protobuf_2.12\2.5.21\akka-protobuf_2.12-2.5.21.jar;F:\Maven\maven-jar\com\typesafe\akka\akka-slf4j_2.12\2.5.21\akka-slf4j_2.12-2.5.21.jar;F:\Maven\maven-jar\org\clapper\grizzled-slf4j_2.12\1.3.2\grizzled-slf4j_2.12-1.3.2.jar;F:\Maven\maven-jar\com\github\scopt\scopt_2.12\3.5.0\scopt_2.12-3.5.0.jar;F:\Maven\maven-jar\com\twitter\chill_2.12\0.7.6\chill_2.12-0.7.6.jar;F:\Maven\maven-jar\com\twitter\chill-java\0.7.6\chill-java-0.7.6.jar;F:\Maven\maven-jar\org\apache\flink\flink-clients_2.12\1.10.0\flink-clients_2.12-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-optimizer_2.12\1.10.0\flink-optimizer_2.12-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-shaded-guava\18.0-9.0\flink-shaded-guava-18.0-9.0.jar;F:\Maven\maven-jar\org\apache\commons\commons-math3\3.5\commons-math3-3.5.jar;F:\Maven\maven-jar\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\Maven\maven-jar\org\apache\flink\force-shading\1.10.0\force-shading-1.10.0.jar;F:\Maven\maven-jar\org\apache\flink\flink-connector-kafka_2.11\1.7.1\flink-connector-kafka_2.11-1.7.1.jar;F:\Maven\maven-jar\org\apache\flink\flink-connector-kafka-base_2.11\1.7.1\flink-connector-kafka-base_2.11-1.7.1.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-client\1.2.12\hbase-client-1.2.12.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-annotations\1.2.12\hbase-annotations-1.2.12.jar;F:\Maven\maven-jar\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-common\1.2.12\hbase-common-1.2.12.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-protocol\1.2.12\hbase-protocol-1.2.12.jar;F:\Maven\maven-jar\commons-codec\commons-codec\1.13\commons-codec-1.13.jar;F:\Maven\maven-jar\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\Maven\maven-jar\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\Maven\maven-jar\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\Maven\maven-jar\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\Maven\maven-jar\io\netty\netty-all\4.1.48.Final\netty-all-4.1.48.Final.jar;F:\Maven\maven-jar\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\Maven\maven-jar\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\Maven\maven-jar\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\Maven\maven-jar\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\Maven\maven-jar\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\Maven\maven-jar\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\Maven\maven-jar\org\apache\httpcomponents\httpclient\4.5.12\httpclient-4.5.12.jar;F:\Maven\maven-jar\org\apache\httpcomponents\httpcore\4.4.13\httpcore-4.4.13.jar;F:\Maven\maven-jar\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\Maven\maven-jar\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\Maven\maven-jar\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\Maven\maven-jar\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-common\2.5.1\hadoop-common-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-annotations\2.5.1\hadoop-annotations-2.5.1.jar;C:\Program Files\Java\jdk1.8.0_191\lib\tools.jar;F:\Maven\maven-jar\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\Maven\maven-jar\commons-net\commons-net\3.1\commons-net-3.1.jar;F:\Maven\maven-jar\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\Maven\maven-jar\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\Maven\maven-jar\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\Maven\maven-jar\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\Maven\maven-jar\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\Maven\maven-jar\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\Maven\maven-jar\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;F:\Maven\maven-jar\com\jcraft\jsch\0.1.42\jsch-0.1.42.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.1\hadoop-mapreduce-client-core-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-yarn-common\2.5.1\hadoop-yarn-common-2.5.1.jar;F:\Maven\maven-jar\javax\xml\bind\jaxb-api\2.3.1\jaxb-api-2.3.1.jar;F:\Maven\maven-jar\javax\activation\javax.activation-api\1.2.0\javax.activation-api-1.2.0.jar;F:\Maven\maven-jar\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-server\1.2.12\hbase-server-1.2.12.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-procedure\1.2.12\hbase-procedure-1.2.12.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-common\1.2.12\hbase-common-1.2.12-tests.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-prefix-tree\1.2.12\hbase-prefix-tree-1.2.12.jar;F:\Maven\maven-jar\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\Maven\maven-jar\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-hadoop-compat\1.2.12\hbase-hadoop-compat-1.2.12.jar;F:\Maven\maven-jar\org\apache\hbase\hbase-hadoop2-compat\1.2.12\hbase-hadoop2-compat-1.2.12.jar;F:\Maven\maven-jar\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\Maven\maven-jar\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\Maven\maven-jar\asm\asm\3.1\asm-3.1.jar;F:\Maven\maven-jar\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\Maven\maven-jar\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\Maven\maven-jar\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\Maven\maven-jar\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\Maven\maven-jar\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\Maven\maven-jar\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\Maven\maven-jar\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\Maven\maven-jar\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\Maven\maven-jar\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\Maven\maven-jar\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\Maven\maven-jar\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\Maven\maven-jar\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\Maven\maven-jar\org\jamon\jamon-runtime\2.4.1\jamon-runtime-2.4.1.jar;F:\Maven\maven-jar\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-client\2.5.1\hadoop-client-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-mapreduce-client-app\2.5.1\hadoop-mapreduce-client-app-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-mapreduce-client-common\2.5.1\hadoop-mapreduce-client-common-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-yarn-client\2.5.1\hadoop-yarn-client-2.5.1.jar;F:\Maven\maven-jar\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-yarn-server-common\2.5.1\hadoop-yarn-server-common-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.5.1\hadoop-mapreduce-client-shuffle-2.5.1.jar;F:\Maven\maven-jar\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-yarn-api\2.5.1\hadoop-yarn-api-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.5.1\hadoop-mapreduce-client-jobclient-2.5.1.jar;F:\Maven\maven-jar\org\apache\hadoop\hadoop-hdfs\2.5.1\hadoop-hdfs-2.5.1.jar;F:\Maven\maven-jar\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;F:\Maven\maven-jar\junit\junit\4.12\junit-4.12.jar;F:\Maven\maven-jar\org\hamcrest\hamcrest-core\2.1\hamcrest-core-2.1.jar;F:\Maven\maven-jar\org\apache\flink\flink-connector-redis_2.10\1.1.5\flink-connector-redis_2.10-1.1.5.jar;F:\Maven\maven-jar\org\apache\commons\commons-lang3\3.9\commons-lang3-3.9.jar;F:\Maven\maven-jar\org\slf4j\slf4j-log4j12\1.7.30\slf4j-log4j12-1.7.30.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-web\2.2.6.RELEASE\spring-boot-starter-web-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter\2.2.6.RELEASE\spring-boot-starter-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot\2.2.6.RELEASE\spring-boot-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-logging\2.2.6.RELEASE\spring-boot-starter-logging-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\apache\logging\log4j\log4j-to-slf4j\2.12.1\log4j-to-slf4j-2.12.1.jar;F:\Maven\maven-jar\org\apache\logging\log4j\log4j-api\2.12.1\log4j-api-2.12.1.jar;F:\Maven\maven-jar\org\slf4j\jul-to-slf4j\1.7.30\jul-to-slf4j-1.7.30.jar;F:\Maven\maven-jar\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;F:\Maven\maven-jar\org\yaml\snakeyaml\1.25\snakeyaml-1.25.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-json\2.2.6.RELEASE\spring-boot-starter-json-2.2.6.RELEASE.jar;F:\Maven\maven-jar\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.10.3\jackson-datatype-jdk8-2.10.3.jar;F:\Maven\maven-jar\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.10.3\jackson-datatype-jsr310-2.10.3.jar;F:\Maven\maven-jar\com\fasterxml\jackson\module\jackson-module-parameter-names\2.10.3\jackson-module-parameter-names-2.10.3.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-tomcat\2.2.6.RELEASE\spring-boot-starter-tomcat-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\apache\tomcat\embed\tomcat-embed-core\9.0.33\tomcat-embed-core-9.0.33.jar;F:\Maven\maven-jar\org\apache\tomcat\embed\tomcat-embed-el\9.0.33\tomcat-embed-el-9.0.33.jar;F:\Maven\maven-jar\org\apache\tomcat\embed\tomcat-embed-websocket\9.0.33\tomcat-embed-websocket-9.0.33.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-validation\2.2.6.RELEASE\spring-boot-starter-validation-2.2.6.RELEASE.jar;F:\Maven\maven-jar\jakarta\validation\jakarta.validation-api\2.0.2\jakarta.validation-api-2.0.2.jar;F:\Maven\maven-jar\org\hibernate\validator\hibernate-validator\6.0.18.Final\hibernate-validator-6.0.18.Final.jar;F:\Maven\maven-jar\org\jboss\logging\jboss-logging\3.4.1.Final\jboss-logging-3.4.1.Final.jar;F:\Maven\maven-jar\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;F:\Maven\maven-jar\org\springframework\spring-web\5.2.5.RELEASE\spring-web-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-beans\5.2.5.RELEASE\spring-beans-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-webmvc\5.2.5.RELEASE\spring-webmvc-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-aop\5.2.5.RELEASE\spring-aop-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-expression\5.2.5.RELEASE\spring-expression-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-thymeleaf\2.2.5.RELEASE\spring-boot-starter-thymeleaf-2.2.5.RELEASE.jar;F:\Maven\maven-jar\org\thymeleaf\thymeleaf-spring5\3.0.11.RELEASE\thymeleaf-spring5-3.0.11.RELEASE.jar;F:\Maven\maven-jar\org\thymeleaf\thymeleaf\3.0.11.RELEASE\thymeleaf-3.0.11.RELEASE.jar;F:\Maven\maven-jar\org\attoparser\attoparser\2.0.5.RELEASE\attoparser-2.0.5.RELEASE.jar;F:\Maven\maven-jar\org\unbescape\unbescape\1.1.6.RELEASE\unbescape-1.1.6.RELEASE.jar;F:\Maven\maven-jar\org\thymeleaf\extras\thymeleaf-extras-java8time\3.0.4.RELEASE\thymeleaf-extras-java8time-3.0.4.RELEASE.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-data-redis\2.2.6.RELEASE\spring-boot-starter-data-redis-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\data\spring-data-redis\2.2.6.RELEASE\spring-data-redis-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\data\spring-data-keyvalue\2.2.6.RELEASE\spring-data-keyvalue-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\data\spring-data-commons\2.2.6.RELEASE\spring-data-commons-2.2.6.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-oxm\5.2.5.RELEASE\spring-oxm-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-context-support\5.2.5.RELEASE\spring-context-support-5.2.5.RELEASE.jar;F:\Maven\maven-jar\redis\clients\jedis\3.1.0\jedis-3.1.0.jar;F:\Maven\maven-jar\org\slf4j\slf4j-api\1.7.30\slf4j-api-1.7.30.jar;F:\Maven\maven-jar\org\apache\commons\commons-pool2\2.7.0\commons-pool2-2.7.0.jar;F:\Maven\maven-jar\org\springframework\kafka\spring-kafka\2.3.7.RELEASE\spring-kafka-2.3.7.RELEASE.jar;F:\Maven\maven-jar\org\apache\kafka\kafka-clients\2.3.1\kafka-clients-2.3.1.jar;F:\Maven\maven-jar\com\github\luben\zstd-jni\1.4.0-1\zstd-jni-1.4.0-1.jar;F:\Maven\maven-jar\org\lz4\lz4-java\1.6.0\lz4-java-1.6.0.jar;F:\Maven\maven-jar\org\xerial\snappy\snappy-java\1.1.7.3\snappy-java-1.1.7.3.jar;F:\Maven\maven-jar\org\springframework\retry\spring-retry\1.2.5.RELEASE\spring-retry-1.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-context\5.2.5.RELEASE\spring-context-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-messaging\5.2.5.RELEASE\spring-messaging-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-tx\5.2.5.RELEASE\spring-tx-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\mybatis\spring\boot\mybatis-spring-boot-starter\2.1.1\mybatis-spring-boot-starter-2.1.1.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-starter-jdbc\2.2.6.RELEASE\spring-boot-starter-jdbc-2.2.6.RELEASE.jar;F:\Maven\maven-jar\com\zaxxer\HikariCP\3.4.2\HikariCP-3.4.2.jar;F:\Maven\maven-jar\org\springframework\spring-jdbc\5.2.5.RELEASE\spring-jdbc-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\mybatis\spring\boot\mybatis-spring-boot-autoconfigure\2.1.1\mybatis-spring-boot-autoconfigure-2.1.1.jar;F:\Maven\maven-jar\org\mybatis\mybatis\3.5.3\mybatis-3.5.3.jar;F:\Maven\maven-jar\org\mybatis\mybatis-spring\2.0.3\mybatis-spring-2.0.3.jar;F:\Maven\maven-jar\io\jsonwebtoken\jjwt\0.9.1\jjwt-0.9.1.jar;F:\Maven\maven-jar\com\fasterxml\jackson\core\jackson-databind\2.10.3\jackson-databind-2.10.3.jar;F:\Maven\maven-jar\com\fasterxml\jackson\core\jackson-annotations\2.10.3\jackson-annotations-2.10.3.jar;F:\Maven\maven-jar\com\fasterxml\jackson\core\jackson-core\2.10.3\jackson-core-2.10.3.jar;F:\Maven\maven-jar\com\alibaba\druid-spring-boot-starter\1.1.9\druid-spring-boot-starter-1.1.9.jar;F:\Maven\maven-jar\com\alibaba\druid\1.1.9\druid-1.1.9.jar;F:\Maven\maven-jar\org\springframework\boot\spring-boot-autoconfigure\2.2.6.RELEASE\spring-boot-autoconfigure-2.2.6.RELEASE.jar;F:\Maven\maven-jar\commons-logging\commons-logging\1.1.1\commons-logging-1.1.1.jar;F:\Maven\maven-jar\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\Maven\maven-jar\mysql\mysql-connector-java\8.0.19\mysql-connector-java-8.0.19.jar;F:\Maven\maven-jar\org\projectlombok\lombok\1.18.12\lombok-1.18.12.jar;F:\Maven\maven-jar\org\hamcrest\hamcrest\2.1\hamcrest-2.1.jar;F:\Maven\maven-jar\org\objenesis\objenesis\2.6\objenesis-2.6.jar;F:\Maven\maven-jar\org\springframework\spring-core\5.2.5.RELEASE\spring-core-5.2.5.RELEASE.jar;F:\Maven\maven-jar\org\springframework\spring-jcl\5.2.5.RELEASE\spring-jcl-5.2.5.RELEASE.jar;D:\IDEA-U\IntelliJ IDEA 2019.1.1\lib\idea_rt.jar;C:\Users\Zzwen\.IntelliJIdea2019.1\system\captureAgent\debugger-agent.jar
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_191\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\SecureCRT\;"C:\Program Files\Java\jdk1.8.0_191\bin;C:\Program Files\Java\jdk1.8.0_191\jre\bin";C:\Program Files\Microsoft MPI\Bin\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;D:\GIT\Git\cmd;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\dotnet\;C:\Program Files\MySQL\MySQL Server 8.0\bin;D:\Gradle\gradle-5.3.1\bin;F:\Maven\apache-maven-3.6.1\bin\;F:\Oracle\PLSQL Developer64\PLSQL Developer\instantclient_11_2;F:\TortoiseSVN\bin;F:\SVN_Visual\bin;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\node.js\;C:\Users\Zzwen\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\Zzwen\AppData\Local\Programs\Python\Python37\;F:\TortoiseGit\bin;F:\scala\scala-2.13.1\bin;C:\Python27;F:\Erlang\erl10.7\bin;F:\rabbitMq\rabbitmq_server-3.7.7\sbin;;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;D:\SecureCRT\;D:\hadoop-2.6.5\\bin;C:\Users\Zzwen\AppData\Local\Programs\Python\Python37\Scripts\;C:\Users\Zzwen\AppData\Local\Programs\Python\Python37\;C:\Users\Zzwen\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\Zzwen\AppData\Local\Programs\Python\Python36\;C:\Users\Zzwen\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_191\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Users\Zzwen\AppData\Roaming\npm;C:\Program Files (x86)\Google\Chrome\Application;;D:\VScode\Microsoft VS Code\bin;.
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.io.tmpdir=C:\Users\Zzwen\AppData\Local\Temp\
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:java.compiler=<NA>
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:os.name=Windows 10
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:os.arch=amd64
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:os.version=10.0
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:user.name=Zzwen
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:user.home=C:\Users\Zzwen
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Client environment:user.dir=F:\毕业设计\graduation-project
2020-04-23 19:00:54 [INFO ](ZooKeeper                     ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Initiating client connection, connectString=aliyun:2181 sessionTimeout=90000 watcher=hconnection-0x2dd893d70x0, quorum=aliyun:2181, baseZNode=/hbase
2020-04-23 19:00:54 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] zookeeper.disableAutoWatchReset is false
2020-04-23 19:00:54 [INFO ](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Opening socket connection to server aliyun/39.105.201.221:2181. Will not attempt to authenticate using SASL (unknown error)
2020-04-23 19:00:54 [INFO ](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Socket connection established to aliyun/39.105.201.221:2181, initiating session
2020-04-23 19:00:54 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Session establishment request sent on aliyun/39.105.201.221:2181
2020-04-23 19:00:54 [INFO ](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Session establishment complete on server aliyun/39.105.201.221:2181, sessionid = 0x10003b7cd140036, negotiated timeout = 40000
2020-04-23 19:00:54 [DEBUG](ZooKeeperWatcher              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] hconnection-0x2dd893d70x0, quorum=aliyun:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2020-04-23 19:00:54 [DEBUG](ZooKeeperWatcher              ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] hconnection-0x2dd893d7-0x10003b7cd140036 connected
2020-04-23 19:00:54 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Reading reply sessionid:0x10003b7cd140036, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,581,0  request:: '/hbase/hbaseid,F  response:: s{331,391,1587347263091,1587349478593,2,0,0,0,67,0,331} 
2020-04-23 19:00:54 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Reading reply sessionid:0x10003b7cd140036, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,581,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030fffffff8effffff8e62233bffffffd5ffffff9350425546a2432376565323031632d646661612d343035632d383661662d383465306630393633336364,s{331,391,1587347263091,1587349478593,2,0,0,0,67,0,331} 
2020-04-23 19:00:54 [DEBUG](AbstractRpcClient             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3b865456, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2020-04-23 19:00:55 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Reading reply sessionid:0x10003b7cd140036, packet:: clientPath:null serverPath:null finished:false header:: 3,4  replyHeader:: 3,581,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a3136303030ffffffc20ffffffe8ffffff9affffffe9fffffff461ffffffc450425546a12a6616c6979756e10ffffff947d18ffffffffffffffa1ffffff9bffffffabffffff992e100183,s{364,404,1587347838666,1587349485038,11,0,0,0,53,0,364} 
2020-04-23 19:00:55 [DEBUG](ClientCnxn                    ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Reading reply sessionid:0x10003b7cd140036, packet:: clientPath:null serverPath:null finished:false header:: 4,8  replyHeader:: 4,581,0  request:: '/hbase,F  response:: v{'meta-region-server,'rs,'splitWAL,'backup-masters,'flush-table-proc,'master-maintenance,'online-snapshot,'switch,'master,'running,'draining,'namespace,'hbaseid,'table} 
2020-04-23 19:00:55 [DEBUG](RpcClientImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Use SIMPLE authentication for service ClientService, sasl=false
2020-04-23 19:00:55 [DEBUG](RpcClientImpl                 ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Connecting to aliyun/39.105.201.221:16020
2020-04-23 19:00:55 [WARN ](BookServiceImpl               ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Hbase中没有产品【1】推荐记录！
2020-04-23 19:00:55 [DEBUG](RequestResponseBodyMethodProcessor) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Using 'application/json', given [application/json, text/plain, */*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-04-23 19:00:55 [DEBUG](RequestResponseBodyMethodProcessor) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Writing [ResultDto(code=20000, msg=, data=BookVo(books=[Book(id=1, name=Python编程快速上手——让繁琐工作自动化（异步图书）, author= (truncated)...]
2020-04-23 19:00:55 [DEBUG](DispatcherServlet             ) [TxId :  , SpanId : ] [ET:,AN:,SN:,CN:,CI:] Completed 200 OK
